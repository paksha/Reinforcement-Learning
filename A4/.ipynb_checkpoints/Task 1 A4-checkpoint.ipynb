{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "from maze_env import Maze\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stable_baselines.common.env_checker import check_env\n",
    "from stable_baselines.bench import Monitor\n",
    "from stable_baselines import DQN,A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TK_SILENCE_DEPRECATION=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MazeGym(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    def __init__(self,task):\n",
    "        self.first = 0\n",
    "        self.agentXY = [0,0]\n",
    "        self.goalXY = [4,4]\n",
    "        walls,pits = self.mazeInfo(task)\n",
    "        self.env = Maze(self.agentXY, self.goalXY, walls, pits)\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        self.observation_space = spaces.Box(low=5,high=395,shape=(4,))\n",
    "        self.counter = 0\n",
    "        self.max_steps = 300\n",
    "        \n",
    "    def mazeInfo(self, task):\n",
    "        if task == 0:\n",
    "            wall_shape=np.array([[2,2],[3,6]])\n",
    "            pits=np.array([[6,3],[1,4]])\n",
    "        elif task == 1:\n",
    "            wall_shape=np.array([[6,2],[5,2],[4,2],[3,2],[2,2],[6,3],[6,4],[6,5],[2,3],[2,4],[2,5]])\n",
    "            pits=[]\n",
    "        elif task == 2:\n",
    "            wall_shape=np.array([[6,3],[6,3],[6,2],[5,2],[4,2],[3,2],[3,3],[3,4],[3,5],[3,6],[4,6],[5,6],[5,7],[7,3]])\n",
    "            pits=np.array([[1,3],[0,5], [7,7], [8,5]])\n",
    "        return wall_shape, pits\n",
    "\n",
    "    def step(self,action):\n",
    "        self.counter += 1\n",
    "        s_,r,d = self.env.step(action)\n",
    "        if (self.counter == self.max_steps):\n",
    "            self.counter = 0\n",
    "            d = True\n",
    "        return np.array(s_),r,d,{}\n",
    "\n",
    "    def reset(self):\n",
    "        state = np.array(self.env.reset(value=self.first))\n",
    "        self.first = 1\n",
    "        return state\n",
    "\n",
    "    def render(self,mode='human'):\n",
    "        self.env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/deepq/dqn.py:129: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:358: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:359: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:139: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/deepq/policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:149: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:415: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:449: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0 # represents which task we will run\n",
    "env = MazeGym(task=i)\n",
    "env = Monitor(env=env, filename=None)\n",
    "model = DQN('MlpPolicy', env, verbose=1) # pick your algorithm from stable baselines\n",
    "rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a DummyVecEnv.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/a2c/a2c.py:184: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "env2 = MazeGym(task=i)\n",
    "env2 = Monitor(env2, filename=None)\n",
    "model2 = A2C('MlpPolicy', env2, verbose=1)\n",
    "rewards2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Rewards for DQN: 0\n",
      "Length of Rewards for DQN: 50\n",
      "Length of Rewards for DQN: 117\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 100      |\n",
      "| mean 100 episode reward | -8.5     |\n",
      "| steps                   | 7149     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 200      |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 7965     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 300      |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 9100     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 400      |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 9912     |\n",
      "--------------------------------------\n",
      "Length of Rewards for DQN: 527\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 100      |\n",
      "| mean 100 episode reward | -1.8     |\n",
      "| steps                   | 1234     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 200      |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 2168     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 300      |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 3139     |\n",
      "--------------------------------------\n",
      "Length of Rewards for DQN: 920\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 100      |\n",
      "| mean 100 episode reward | -10.8    |\n",
      "| steps                   | 7862     |\n",
      "--------------------------------------\n",
      "Length of Rewards for DQN: 1074\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 100      |\n",
      "| mean 100 episode reward | -2.1     |\n",
      "| steps                   | 2242     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 200      |\n",
      "| mean 100 episode reward | -0.9     |\n",
      "| steps                   | 3649     |\n",
      "--------------------------------------\n",
      "Length of Rewards for DQN: 1369\n",
      "Length of Rewards for DQN: 1412\n",
      "Length of Rewards for DQN: 1453\n",
      "Length of Rewards for DQN: 1491\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 100      |\n",
      "| mean 100 episode reward | -9.5     |\n",
      "| steps                   | 7366     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 200      |\n",
      "| mean 100 episode reward | 0.1      |\n",
      "| steps                   | 8204     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 300      |\n",
      "| mean 100 episode reward | -1.1     |\n",
      "| steps                   | 9505     |\n",
      "--------------------------------------\n",
      "Length of Rewards for DQN: 1816\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 100      |\n",
      "| mean 100 episode reward | -9.5     |\n",
      "| steps                   | 6858     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 200      |\n",
      "| mean 100 episode reward | -0.1     |\n",
      "| steps                   | 7749     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 300      |\n",
      "| mean 100 episode reward | -0.2     |\n",
      "| steps                   | 8770     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 400      |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 9566     |\n",
      "--------------------------------------\n",
      "Length of Rewards for A2C: 0\n",
      "---------------------------------\n",
      "| explained_variance | -2.62    |\n",
      "| fps                | 12       |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.39     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.105    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 37.5     |\n",
      "| ep_reward_mean     | -11.5    |\n",
      "| explained_variance | -7.09    |\n",
      "| fps                | 156      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.39     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 1.15     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 45.1     |\n",
      "| ep_reward_mean     | -11.8    |\n",
      "| explained_variance | -2.1     |\n",
      "| fps                | 186      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.39     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 0.316    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 50       |\n",
      "| ep_reward_mean     | -12.2    |\n",
      "| explained_variance | 0.668    |\n",
      "| fps                | 200      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.39     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 0.0108   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 56.6     |\n",
      "| ep_reward_mean     | -12.5    |\n",
      "| explained_variance | -0.224   |\n",
      "| fps                | 225      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.39     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 0.0434   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 58.5     |\n",
      "| ep_reward_mean     | -11.9    |\n",
      "| explained_variance | -2.04    |\n",
      "| fps                | 238      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 0.112    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 62.5     |\n",
      "| ep_reward_mean     | -12.5    |\n",
      "| explained_variance | 0.31     |\n",
      "| fps                | 245      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 7.49     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 70       |\n",
      "| ep_reward_mean     | -13.2    |\n",
      "| explained_variance | 0.468    |\n",
      "| fps                | 269      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 12.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 68.4     |\n",
      "| ep_reward_mean     | -13.2    |\n",
      "| explained_variance | 0.145    |\n",
      "| fps                | 271      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 0.0133   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 70.3     |\n",
      "| ep_reward_mean     | -13.5    |\n",
      "| explained_variance | 0.00524  |\n",
      "| fps                | 273      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 72.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 70.6     |\n",
      "| ep_reward_mean     | -13.6    |\n",
      "| explained_variance | -61.3    |\n",
      "| fps                | 284      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 0.0198   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 76.1     |\n",
      "| ep_reward_mean     | -14      |\n",
      "| explained_variance | -259     |\n",
      "| fps                | 296      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 0.00359  |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 80       |\n",
      "| ep_reward_mean     | -14.2    |\n",
      "| explained_variance | -0.138   |\n",
      "| fps                | 303      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 86.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 77.4     |\n",
      "| ep_reward_mean     | -14      |\n",
      "| explained_variance | -654     |\n",
      "| fps                | 299      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 7.49e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 80.4     |\n",
      "| ep_reward_mean     | -14.2    |\n",
      "| explained_variance | -3.23    |\n",
      "| fps                | 308      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 1.56e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 85.2     |\n",
      "| ep_reward_mean     | -14.6    |\n",
      "| explained_variance | -0.0983  |\n",
      "| fps                | 319      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 94.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 86.2     |\n",
      "| ep_reward_mean     | -14.7    |\n",
      "| explained_variance | -4.7     |\n",
      "| fps                | 327      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 0.0001   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 90.3     |\n",
      "| ep_reward_mean     | -15      |\n",
      "| explained_variance | -3.65    |\n",
      "| fps                | 337      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 1.45e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 90        |\n",
      "| ep_reward_mean     | -15       |\n",
      "| explained_variance | -0.000228 |\n",
      "| fps                | 333       |\n",
      "| nupdates           | 1800      |\n",
      "| policy_entropy     | 1.28      |\n",
      "| total_timesteps    | 9000      |\n",
      "| value_loss         | 92.6      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 92.1     |\n",
      "| ep_reward_mean     | -15.2    |\n",
      "| explained_variance | -116     |\n",
      "| fps                | 342      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 0.000396 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 95.8     |\n",
      "| ep_reward_mean     | -15.4    |\n",
      "| explained_variance | -190     |\n",
      "| fps                | 343      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 0.00671  |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 107\n",
      "---------------------------------\n",
      "| ep_len_mean        | 95.8     |\n",
      "| ep_reward_mean     | -15.4    |\n",
      "| explained_variance | 0.565    |\n",
      "| fps                | 1246     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.0295   |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 99        |\n",
      "| ep_reward_mean     | -15.7     |\n",
      "| explained_variance | -2.11e-05 |\n",
      "| fps                | 285       |\n",
      "| nupdates           | 100       |\n",
      "| policy_entropy     | 1.31      |\n",
      "| total_timesteps    | 500       |\n",
      "| value_loss         | 94        |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 101      |\n",
      "| ep_reward_mean     | -16      |\n",
      "| explained_variance | 0.251    |\n",
      "| fps                | 322      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 4.02e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 102      |\n",
      "| ep_reward_mean     | -16      |\n",
      "| explained_variance | 2.38e-07 |\n",
      "| fps                | 337      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 2.25e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 108      |\n",
      "| ep_reward_mean     | -16.3    |\n",
      "| explained_variance | 2.98e-07 |\n",
      "| fps                | 389      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 94.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 111      |\n",
      "| ep_reward_mean     | -16.7    |\n",
      "| explained_variance | -59.6    |\n",
      "| fps                | 427      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 1.41e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 114       |\n",
      "| ep_reward_mean     | -16.9     |\n",
      "| explained_variance | -2.67e+03 |\n",
      "| fps                | 455       |\n",
      "| nupdates           | 600       |\n",
      "| policy_entropy     | 1.37      |\n",
      "| total_timesteps    | 3000      |\n",
      "| value_loss         | 7.87e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 117      |\n",
      "| ep_reward_mean     | -17.3    |\n",
      "| explained_variance | 0.353    |\n",
      "| fps                | 449      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 95.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 114      |\n",
      "| ep_reward_mean     | -17.4    |\n",
      "| explained_variance | -0.0415  |\n",
      "| fps                | 419      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 2.32e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 107      |\n",
      "| ep_reward_mean     | -16.9    |\n",
      "| explained_variance | -8.34    |\n",
      "| fps                | 348      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 0.00132  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 98.9     |\n",
      "| ep_reward_mean     | -16.2    |\n",
      "| explained_variance | -0.00176 |\n",
      "| fps                | 310      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 93.8     |\n",
      "| ep_reward_mean     | -16      |\n",
      "| explained_variance | 0.0967   |\n",
      "| fps                | 301      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 1.42e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 89.9     |\n",
      "| ep_reward_mean     | -15.8    |\n",
      "| explained_variance | -1.28    |\n",
      "| fps                | 300      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 0.000474 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 78       |\n",
      "| ep_reward_mean     | -15      |\n",
      "| explained_variance | -0.00124 |\n",
      "| fps                | 296      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 96       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 79.1     |\n",
      "| ep_reward_mean     | -15.1    |\n",
      "| explained_variance | -224     |\n",
      "| fps                | 302      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 0.000157 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| ep_len_mean        | 78.4      |\n",
      "| ep_reward_mean     | -15.1     |\n",
      "| explained_variance | -5.36e-05 |\n",
      "| fps                | 301       |\n",
      "| nupdates           | 1500      |\n",
      "| policy_entropy     | 1.26      |\n",
      "| total_timesteps    | 7500      |\n",
      "| value_loss         | 5e-06     |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 78       |\n",
      "| ep_reward_mean     | -15      |\n",
      "| explained_variance | 4.68e-05 |\n",
      "| fps                | 304      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 77       |\n",
      "| ep_reward_mean     | -15.1    |\n",
      "| explained_variance | -119     |\n",
      "| fps                | 305      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 0.00194  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 79.5     |\n",
      "| ep_reward_mean     | -15      |\n",
      "| explained_variance | -411     |\n",
      "| fps                | 312      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 0.00451  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 78       |\n",
      "| ep_reward_mean     | -15      |\n",
      "| explained_variance | -0.0924  |\n",
      "| fps                | 312      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 92.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 72       |\n",
      "| ep_reward_mean     | -14.5    |\n",
      "| explained_variance | -0.105   |\n",
      "| fps                | 316      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 1.97e-06 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 229\n",
      "---------------------------------\n",
      "| ep_len_mean        | 72       |\n",
      "| ep_reward_mean     | -14.5    |\n",
      "| explained_variance | -0.0393  |\n",
      "| fps                | 1295     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 1.13e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 70.7     |\n",
      "| ep_reward_mean     | -14.4    |\n",
      "| explained_variance | 0.00154  |\n",
      "| fps                | 514      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 0.000851 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 74.4     |\n",
      "| ep_reward_mean     | -14.6    |\n",
      "| explained_variance | 0.000564 |\n",
      "| fps                | 514      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 97.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 76.3     |\n",
      "| ep_reward_mean     | -14.7    |\n",
      "| explained_variance | -19.4    |\n",
      "| fps                | 519      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 0.000491 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 76.8     |\n",
      "| ep_reward_mean     | -14.8    |\n",
      "| explained_variance | -22.3    |\n",
      "| fps                | 396      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 3.98e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 81       |\n",
      "| ep_reward_mean     | -15.1    |\n",
      "| explained_variance | -0.0886  |\n",
      "| fps                | 391      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 98.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 85       |\n",
      "| ep_reward_mean     | -15.4    |\n",
      "| explained_variance | -98.3    |\n",
      "| fps                | 398      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 0.000155 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 87.7     |\n",
      "| ep_reward_mean     | -15.6    |\n",
      "| explained_variance | 0.0216   |\n",
      "| fps                | 402      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 2.06e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 92.9     |\n",
      "| ep_reward_mean     | -16      |\n",
      "| explained_variance | -0.0308  |\n",
      "| fps                | 414      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 95.4      |\n",
      "| ep_reward_mean     | -16.1     |\n",
      "| explained_variance | -2.87e+03 |\n",
      "| fps                | 408       |\n",
      "| nupdates           | 900       |\n",
      "| policy_entropy     | 1.33      |\n",
      "| total_timesteps    | 4500      |\n",
      "| value_loss         | 0.00103   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 98.5      |\n",
      "| ep_reward_mean     | -16.4     |\n",
      "| explained_variance | -1.27e+03 |\n",
      "| fps                | 397       |\n",
      "| nupdates           | 1000      |\n",
      "| policy_entropy     | 1.28      |\n",
      "| total_timesteps    | 5000      |\n",
      "| value_loss         | 0.000339  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 99.3     |\n",
      "| ep_reward_mean     | -16.2    |\n",
      "| explained_variance | -0.00654 |\n",
      "| fps                | 379      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 58.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 91.6     |\n",
      "| ep_reward_mean     | -15.6    |\n",
      "| explained_variance | -80.1    |\n",
      "| fps                | 339      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 0.000104 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 90.1     |\n",
      "| ep_reward_mean     | -15.5    |\n",
      "| explained_variance | -6.76    |\n",
      "| fps                | 341      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 1.3e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 93.8     |\n",
      "| ep_reward_mean     | -15.7    |\n",
      "| explained_variance | 0.000513 |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 92.5     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 96        |\n",
      "| ep_reward_mean     | -15.9     |\n",
      "| explained_variance | -1.66e+03 |\n",
      "| fps                | 355       |\n",
      "| nupdates           | 1500      |\n",
      "| policy_entropy     | 1.31      |\n",
      "| total_timesteps    | 7500      |\n",
      "| value_loss         | 3.28e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 94.7     |\n",
      "| ep_reward_mean     | -15.7    |\n",
      "| explained_variance | -355     |\n",
      "| fps                | 345      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 0.00014  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 92.2     |\n",
      "| ep_reward_mean     | -15.7    |\n",
      "| explained_variance | -0.0449  |\n",
      "| fps                | 343      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 93.8     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 93       |\n",
      "| ep_reward_mean     | -15.8    |\n",
      "| explained_variance | -60.9    |\n",
      "| fps                | 351      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 6.45e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 91        |\n",
      "| ep_reward_mean     | -15.7     |\n",
      "| explained_variance | -2.15e+03 |\n",
      "| fps                | 349       |\n",
      "| nupdates           | 1900      |\n",
      "| policy_entropy     | 1.32      |\n",
      "| total_timesteps    | 9500      |\n",
      "| value_loss         | 0.000341  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 87       |\n",
      "| ep_reward_mean     | -15.5    |\n",
      "| explained_variance | 0.0277   |\n",
      "| fps                | 345      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 95.7     |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 338\n",
      "---------------------------------\n",
      "| ep_len_mean        | 87       |\n",
      "| ep_reward_mean     | -15.5    |\n",
      "| explained_variance | -921     |\n",
      "| fps                | 1275     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000831 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 82.4     |\n",
      "| ep_reward_mean     | -15      |\n",
      "| explained_variance | -1.2e+04 |\n",
      "| fps                | 179      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 0.000358 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 79.6     |\n",
      "| ep_reward_mean     | -14.7    |\n",
      "| explained_variance | -63.9    |\n",
      "| fps                | 242      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 2.37e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 75.9     |\n",
      "| ep_reward_mean     | -14.4    |\n",
      "| explained_variance | 0.0325   |\n",
      "| fps                | 253      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 94.6     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 73.6      |\n",
      "| ep_reward_mean     | -14.2     |\n",
      "| explained_variance | -1.16e+06 |\n",
      "| fps                | 275       |\n",
      "| nupdates           | 400       |\n",
      "| policy_entropy     | 1.31      |\n",
      "| total_timesteps    | 2000      |\n",
      "| value_loss         | 7.39e-05  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 75        |\n",
      "| ep_reward_mean     | -14.2     |\n",
      "| explained_variance | -3.26e+03 |\n",
      "| fps                | 276       |\n",
      "| nupdates           | 500       |\n",
      "| policy_entropy     | 1.21      |\n",
      "| total_timesteps    | 2500      |\n",
      "| value_loss         | 0.00029   |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 76.7     |\n",
      "| ep_reward_mean     | -14.4    |\n",
      "| explained_variance | 0.000287 |\n",
      "| fps                | 283      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 78       |\n",
      "| ep_reward_mean     | -14.5    |\n",
      "| explained_variance | -29.5    |\n",
      "| fps                | 309      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 0.00042  |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 82.5      |\n",
      "| ep_reward_mean     | -14.9     |\n",
      "| explained_variance | -7.83e+03 |\n",
      "| fps                | 311       |\n",
      "| nupdates           | 800       |\n",
      "| policy_entropy     | 1.22      |\n",
      "| total_timesteps    | 4000      |\n",
      "| value_loss         | 0.000149  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 86.1     |\n",
      "| ep_reward_mean     | -15.2    |\n",
      "| explained_variance | -0.00614 |\n",
      "| fps                | 317      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 19.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 88.1     |\n",
      "| ep_reward_mean     | -15.6    |\n",
      "| explained_variance | -102     |\n",
      "| fps                | 321      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 2.27e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 78.4      |\n",
      "| ep_reward_mean     | -14.9     |\n",
      "| explained_variance | -2.36e+04 |\n",
      "| fps                | 303       |\n",
      "| nupdates           | 1100      |\n",
      "| policy_entropy     | 1.27      |\n",
      "| total_timesteps    | 5500      |\n",
      "| value_loss         | 0.00035   |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 78       |\n",
      "| ep_reward_mean     | -14.9    |\n",
      "| explained_variance | 0.000339 |\n",
      "| fps                | 295      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 95.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 79.2     |\n",
      "| ep_reward_mean     | -14.9    |\n",
      "| explained_variance | -1.43    |\n",
      "| fps                | 306      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 6.01e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 74.1     |\n",
      "| ep_reward_mean     | -14.6    |\n",
      "| explained_variance | -284     |\n",
      "| fps                | 296      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 0.000257 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 76.5     |\n",
      "| ep_reward_mean     | -14.7    |\n",
      "| explained_variance | -8.5e-05 |\n",
      "| fps                | 298      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 95.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 77.4     |\n",
      "| ep_reward_mean     | -14.9    |\n",
      "| explained_variance | -135     |\n",
      "| fps                | 298      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 0.000105 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 77       |\n",
      "| ep_reward_mean     | -15      |\n",
      "| explained_variance | -699     |\n",
      "| fps                | 295      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 5.83e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 75        |\n",
      "| ep_reward_mean     | -14.9     |\n",
      "| explained_variance | -0.000157 |\n",
      "| fps                | 288       |\n",
      "| nupdates           | 1800      |\n",
      "| policy_entropy     | 1.37      |\n",
      "| total_timesteps    | 9000      |\n",
      "| value_loss         | 95        |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 69       |\n",
      "| ep_reward_mean     | -14.6    |\n",
      "| explained_variance | -0.00755 |\n",
      "| fps                | 283      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 2.35e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 66.7     |\n",
      "| ep_reward_mean     | -14.6    |\n",
      "| explained_variance | -23.6    |\n",
      "| fps                | 278      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 0.000144 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Rewards for A2C: 482\n",
      "---------------------------------\n",
      "| ep_len_mean        | 66.7     |\n",
      "| ep_reward_mean     | -14.6    |\n",
      "| explained_variance | 0.411    |\n",
      "| fps                | 1242     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 1.18e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 65.5     |\n",
      "| ep_reward_mean     | -14.5    |\n",
      "| explained_variance | 0.0059   |\n",
      "| fps                | 318      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 94.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 62.8     |\n",
      "| ep_reward_mean     | -14.4    |\n",
      "| explained_variance | -6.09    |\n",
      "| fps                | 285      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 6.07e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 62.5     |\n",
      "| ep_reward_mean     | -14.2    |\n",
      "| explained_variance | -487     |\n",
      "| fps                | 297      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 0.000151 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 67.4     |\n",
      "| ep_reward_mean     | -14.5    |\n",
      "| explained_variance | -0.027   |\n",
      "| fps                | 349      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 95.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 69.4     |\n",
      "| ep_reward_mean     | -14.6    |\n",
      "| explained_variance | -228     |\n",
      "| fps                | 388      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 4.66e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 74.7     |\n",
      "| ep_reward_mean     | -15.1    |\n",
      "| explained_variance | -121     |\n",
      "| fps                | 420      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 0.000313 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 79.3     |\n",
      "| ep_reward_mean     | -15.3    |\n",
      "| explained_variance | -0.00132 |\n",
      "| fps                | 436      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 57.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 80.9     |\n",
      "| ep_reward_mean     | -15.5    |\n",
      "| explained_variance | -13.4    |\n",
      "| fps                | 447      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 9.51e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 81       |\n",
      "| ep_reward_mean     | -15.5    |\n",
      "| explained_variance | -807     |\n",
      "| fps                | 438      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 0.000671 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 84        |\n",
      "| ep_reward_mean     | -15.7     |\n",
      "| explained_variance | -8.62e-05 |\n",
      "| fps                | 437       |\n",
      "| nupdates           | 1000      |\n",
      "| policy_entropy     | 1.37      |\n",
      "| total_timesteps    | 5000      |\n",
      "| value_loss         | 95.5      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 85.7      |\n",
      "| ep_reward_mean     | -15.8     |\n",
      "| explained_variance | -2.85e+03 |\n",
      "| fps                | 445       |\n",
      "| nupdates           | 1100      |\n",
      "| policy_entropy     | 1.33      |\n",
      "| total_timesteps    | 5500      |\n",
      "| value_loss         | 9.78e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 90.4     |\n",
      "| ep_reward_mean     | -16      |\n",
      "| explained_variance | -142     |\n",
      "| fps                | 450      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.15     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 0.000105 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 94.5     |\n",
      "| ep_reward_mean     | -16.3    |\n",
      "| explained_variance | 0.00597  |\n",
      "| fps                | 455      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 96       |\n",
      "| ep_reward_mean     | -16.5    |\n",
      "| explained_variance | -85.9    |\n",
      "| fps                | 466      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 0.000128 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 99       |\n",
      "| ep_reward_mean     | -16.7    |\n",
      "| explained_variance | -6.9     |\n",
      "| fps                | 471      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 2.13e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 103      |\n",
      "| ep_reward_mean     | -16.9    |\n",
      "| explained_variance | 0.00454  |\n",
      "| fps                | 473      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 105      |\n",
      "| ep_reward_mean     | -17      |\n",
      "| explained_variance | 0.785    |\n",
      "| fps                | 471      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 2.3e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 105      |\n",
      "| ep_reward_mean     | -17      |\n",
      "| explained_variance | -13.2    |\n",
      "| fps                | 459      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 0.00013  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 108      |\n",
      "| ep_reward_mean     | -17      |\n",
      "| explained_variance | -0.00745 |\n",
      "| fps                | 446      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 93.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 111      |\n",
      "| ep_reward_mean     | -17.2    |\n",
      "| explained_variance | -0.00185 |\n",
      "| fps                | 445      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 0.000317 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 561\n",
      "---------------------------------\n",
      "| ep_len_mean        | 111      |\n",
      "| ep_reward_mean     | -17.2    |\n",
      "| explained_variance | -419     |\n",
      "| fps                | 930      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.00034  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 112      |\n",
      "| ep_reward_mean     | -17.2    |\n",
      "| explained_variance | 0.0813   |\n",
      "| fps                | 438      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 7.48e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 118      |\n",
      "| ep_reward_mean     | -17.5    |\n",
      "| explained_variance | 0.00941  |\n",
      "| fps                | 471      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 121      |\n",
      "| ep_reward_mean     | -17.9    |\n",
      "| explained_variance | 0.0346   |\n",
      "| fps                | 459      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 4.85e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 122      |\n",
      "| ep_reward_mean     | -17.8    |\n",
      "| explained_variance | 0.0274   |\n",
      "| fps                | 428      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 1.82e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 126      |\n",
      "| ep_reward_mean     | -18.1    |\n",
      "| explained_variance | 0.00185  |\n",
      "| fps                | 428      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 127      |\n",
      "| ep_reward_mean     | -18.2    |\n",
      "| explained_variance | -41.1    |\n",
      "| fps                | 442      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 4.57e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 129      |\n",
      "| ep_reward_mean     | -18.3    |\n",
      "| explained_variance | -519     |\n",
      "| fps                | 438      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 4.26e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 132       |\n",
      "| ep_reward_mean     | -18.2     |\n",
      "| explained_variance | -1.54e-05 |\n",
      "| fps                | 428       |\n",
      "| nupdates           | 800       |\n",
      "| policy_entropy     | 1.38      |\n",
      "| total_timesteps    | 4000      |\n",
      "| value_loss         | 91.6      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 133      |\n",
      "| ep_reward_mean     | -18.3    |\n",
      "| explained_variance | -12.8    |\n",
      "| fps                | 422      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 9.58e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 138      |\n",
      "| ep_reward_mean     | -18.7    |\n",
      "| explained_variance | -169     |\n",
      "| fps                | 439      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 0.000362 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 123      |\n",
      "| ep_reward_mean     | -17.5    |\n",
      "| explained_variance | 0.000196 |\n",
      "| fps                | 406      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 122       |\n",
      "| ep_reward_mean     | -17.4     |\n",
      "| explained_variance | -1.14e+04 |\n",
      "| fps                | 409       |\n",
      "| nupdates           | 1200      |\n",
      "| policy_entropy     | 1.34      |\n",
      "| total_timesteps    | 6000      |\n",
      "| value_loss         | 2.6e-05   |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 121      |\n",
      "| ep_reward_mean     | -17.4    |\n",
      "| explained_variance | -36.9    |\n",
      "| fps                | 401      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 1.29e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 120      |\n",
      "| ep_reward_mean     | -17.3    |\n",
      "| explained_variance | 4.17e-07 |\n",
      "| fps                | 404      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 95.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 118      |\n",
      "| ep_reward_mean     | -17.2    |\n",
      "| explained_variance | 0.842    |\n",
      "| fps                | 407      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 1.51e-09 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 116       |\n",
      "| ep_reward_mean     | -17       |\n",
      "| explained_variance | -9.54e-07 |\n",
      "| fps                | 409       |\n",
      "| nupdates           | 1600      |\n",
      "| policy_entropy     | 1.27      |\n",
      "| total_timesteps    | 8000      |\n",
      "| value_loss         | 2.74e-06  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 117      |\n",
      "| ep_reward_mean     | -17.1    |\n",
      "| explained_variance | -0.0373  |\n",
      "| fps                | 415      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.19     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 92.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 109      |\n",
      "| ep_reward_mean     | -16.7    |\n",
      "| explained_variance | -117     |\n",
      "| fps                | 405      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 1.52e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 107      |\n",
      "| ep_reward_mean     | -16.6    |\n",
      "| explained_variance | -101     |\n",
      "| fps                | 396      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 7.9e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 108      |\n",
      "| ep_reward_mean     | -16.6    |\n",
      "| explained_variance | 0.000325 |\n",
      "| fps                | 400      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 93.8     |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 651\n",
      "---------------------------------\n",
      "| ep_len_mean        | 108      |\n",
      "| ep_reward_mean     | -16.6    |\n",
      "| explained_variance | -50.8    |\n",
      "| fps                | 1259     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.00196  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 109      |\n",
      "| ep_reward_mean     | -16.8    |\n",
      "| explained_variance | -8.61    |\n",
      "| fps                | 440      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 7.28e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 111      |\n",
      "| ep_reward_mean     | -17.2    |\n",
      "| explained_variance | -1.6     |\n",
      "| fps                | 372      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 0.00157  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 111      |\n",
      "| ep_reward_mean     | -17.2    |\n",
      "| explained_variance | 2.38e-05 |\n",
      "| fps                | 389      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 110      |\n",
      "| ep_reward_mean     | -17.2    |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 419      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 0.000145 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 108      |\n",
      "| ep_reward_mean     | -16.9    |\n",
      "| explained_variance | -227     |\n",
      "| fps                | 397      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 6.74e-05 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 102      |\n",
      "| ep_reward_mean     | -16.5    |\n",
      "| explained_variance | -0.0663  |\n",
      "| fps                | 363      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 102      |\n",
      "| ep_reward_mean     | -16.6    |\n",
      "| explained_variance | 0.279    |\n",
      "| fps                | 372      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 1.29e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 102      |\n",
      "| ep_reward_mean     | -16.5    |\n",
      "| explained_variance | -0.226   |\n",
      "| fps                | 386      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 0.00169  |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 105       |\n",
      "| ep_reward_mean     | -17       |\n",
      "| explained_variance | -3.58e-07 |\n",
      "| fps                | 391       |\n",
      "| nupdates           | 900       |\n",
      "| policy_entropy     | 1.33      |\n",
      "| total_timesteps    | 4500      |\n",
      "| value_loss         | 94.8      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 104      |\n",
      "| ep_reward_mean     | -16.9    |\n",
      "| explained_variance | -99.4    |\n",
      "| fps                | 383      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 8.54e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 103      |\n",
      "| ep_reward_mean     | -16.8    |\n",
      "| explained_variance | 0.275    |\n",
      "| fps                | 382      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 1.2e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 106      |\n",
      "| ep_reward_mean     | -17      |\n",
      "| explained_variance | 0.0515   |\n",
      "| fps                | 392      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 93.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 108      |\n",
      "| ep_reward_mean     | -17.3    |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 400      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 2.12e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 110       |\n",
      "| ep_reward_mean     | -17.4     |\n",
      "| explained_variance | -1.29e+03 |\n",
      "| fps                | 403       |\n",
      "| nupdates           | 1400      |\n",
      "| policy_entropy     | 1.31      |\n",
      "| total_timesteps    | 7000      |\n",
      "| value_loss         | 3.11e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 110      |\n",
      "| ep_reward_mean     | -17.3    |\n",
      "| explained_variance | 0.0011   |\n",
      "| fps                | 400      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 107      |\n",
      "| ep_reward_mean     | -17.1    |\n",
      "| explained_variance | -297     |\n",
      "| fps                | 395      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 9.1e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 109      |\n",
      "| ep_reward_mean     | -17.2    |\n",
      "| explained_variance | 0.452    |\n",
      "| fps                | 402      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 4.98e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 105      |\n",
      "| ep_reward_mean     | -17      |\n",
      "| explained_variance | -0.0752  |\n",
      "| fps                | 396      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.18     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 106      |\n",
      "| ep_reward_mean     | -17      |\n",
      "| explained_variance | -16.9    |\n",
      "| fps                | 394      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 0.000211 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 108      |\n",
      "| ep_reward_mean     | -17.2    |\n",
      "| explained_variance | -93.1    |\n",
      "| fps                | 396      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 1.79e-05 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 743\n",
      "---------------------------------\n",
      "| ep_len_mean        | 108      |\n",
      "| ep_reward_mean     | -17.2    |\n",
      "| explained_variance | 0.00546  |\n",
      "| fps                | 759      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 9.38e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 111      |\n",
      "| ep_reward_mean     | -17.3    |\n",
      "| explained_variance | -0.0267  |\n",
      "| fps                | 366      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 95.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 108      |\n",
      "| ep_reward_mean     | -17.2    |\n",
      "| explained_variance | -1.93    |\n",
      "| fps                | 432      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 2.03e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 113      |\n",
      "| ep_reward_mean     | -17.5    |\n",
      "| explained_variance | -9.96    |\n",
      "| fps                | 489      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 1.31e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 112      |\n",
      "| ep_reward_mean     | -17.3    |\n",
      "| explained_variance | 0.115    |\n",
      "| fps                | 433      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 95.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 110      |\n",
      "| ep_reward_mean     | -17.2    |\n",
      "| explained_variance | -0.0118  |\n",
      "| fps                | 406      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 6.62e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 107      |\n",
      "| ep_reward_mean     | -17      |\n",
      "| explained_variance | 0.00216  |\n",
      "| fps                | 399      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 3.15e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 107      |\n",
      "| ep_reward_mean     | -17      |\n",
      "| explained_variance | 0.0471   |\n",
      "| fps                | 371      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 108       |\n",
      "| ep_reward_mean     | -17.1     |\n",
      "| explained_variance | -1.33e+03 |\n",
      "| fps                | 364       |\n",
      "| nupdates           | 800       |\n",
      "| policy_entropy     | 1.34      |\n",
      "| total_timesteps    | 4000      |\n",
      "| value_loss         | 6.59e-05  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 111      |\n",
      "| ep_reward_mean     | -17.2    |\n",
      "| explained_variance | -11.2    |\n",
      "| fps                | 384      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 0.000186 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 110      |\n",
      "| ep_reward_mean     | -17.2    |\n",
      "| explained_variance | 3.3e-05  |\n",
      "| fps                | 389      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 93.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 110      |\n",
      "| ep_reward_mean     | -17.1    |\n",
      "| explained_variance | 0.0682   |\n",
      "| fps                | 405      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 5.02e-07 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 109       |\n",
      "| ep_reward_mean     | -17.1     |\n",
      "| explained_variance | -2.11e+04 |\n",
      "| fps                | 386       |\n",
      "| nupdates           | 1200      |\n",
      "| policy_entropy     | 1.38      |\n",
      "| total_timesteps    | 6000      |\n",
      "| value_loss         | 0.000212  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 108      |\n",
      "| ep_reward_mean     | -17.1    |\n",
      "| explained_variance | -0.0415  |\n",
      "| fps                | 385      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 93.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 109      |\n",
      "| ep_reward_mean     | -17.1    |\n",
      "| explained_variance | -67.5    |\n",
      "| fps                | 392      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 0.000201 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 105      |\n",
      "| ep_reward_mean     | -16.8    |\n",
      "| explained_variance | -14.6    |\n",
      "| fps                | 391      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 6.64e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 108      |\n",
      "| ep_reward_mean     | -17      |\n",
      "| explained_variance | 4.17e-07 |\n",
      "| fps                | 398      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 107      |\n",
      "| ep_reward_mean     | -17      |\n",
      "| explained_variance | -365     |\n",
      "| fps                | 400      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 6.38e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 111      |\n",
      "| ep_reward_mean     | -17.3    |\n",
      "| explained_variance | -4.17    |\n",
      "| fps                | 406      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 4.75e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 108      |\n",
      "| ep_reward_mean     | -17.1    |\n",
      "| explained_variance | 0.0682   |\n",
      "| fps                | 397      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.18     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 95.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 108      |\n",
      "| ep_reward_mean     | -17      |\n",
      "| explained_variance | -48.9    |\n",
      "| fps                | 392      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 0.000159 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 836\n",
      "---------------------------------\n",
      "| ep_len_mean        | 108      |\n",
      "| ep_reward_mean     | -17      |\n",
      "| explained_variance | -22.1    |\n",
      "| fps                | 1377     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 1.29e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 107      |\n",
      "| ep_reward_mean     | -16.9    |\n",
      "| explained_variance | -2.63    |\n",
      "| fps                | 365      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 1.98e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 110      |\n",
      "| ep_reward_mean     | -17      |\n",
      "| explained_variance | 0.00632  |\n",
      "| fps                | 433      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 93.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 103      |\n",
      "| ep_reward_mean     | -16.7    |\n",
      "| explained_variance | -5.92    |\n",
      "| fps                | 354      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 2.73e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 103      |\n",
      "| ep_reward_mean     | -16.5    |\n",
      "| explained_variance | -1.47    |\n",
      "| fps                | 403      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 5.78e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 105      |\n",
      "| ep_reward_mean     | -16.7    |\n",
      "| explained_variance | 0.00543  |\n",
      "| fps                | 411      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.19     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 38.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 108      |\n",
      "| ep_reward_mean     | -17      |\n",
      "| explained_variance | -292     |\n",
      "| fps                | 457      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 2.77e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 110       |\n",
      "| ep_reward_mean     | -17.1     |\n",
      "| explained_variance | -4.45e+04 |\n",
      "| fps                | 433       |\n",
      "| nupdates           | 700       |\n",
      "| policy_entropy     | 1.28      |\n",
      "| total_timesteps    | 3500      |\n",
      "| value_loss         | 0.000122  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 113      |\n",
      "| ep_reward_mean     | -17.3    |\n",
      "| explained_variance | 0.000192 |\n",
      "| fps                | 457      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 96.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 114      |\n",
      "| ep_reward_mean     | -17.4    |\n",
      "| explained_variance | -9.03    |\n",
      "| fps                | 456      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 3.9e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 117      |\n",
      "| ep_reward_mean     | -17.6    |\n",
      "| explained_variance | -25.2    |\n",
      "| fps                | 455      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 1.09e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 120      |\n",
      "| ep_reward_mean     | -17.7    |\n",
      "| explained_variance | 4.11e-06 |\n",
      "| fps                | 470      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 93.7     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 123      |\n",
      "| ep_reward_mean     | -18      |\n",
      "| explained_variance | -16.2    |\n",
      "| fps                | 475      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 3.38e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 125       |\n",
      "| ep_reward_mean     | -18.1     |\n",
      "| explained_variance | -1.37e+03 |\n",
      "| fps                | 481       |\n",
      "| nupdates           | 1300      |\n",
      "| policy_entropy     | 1.36      |\n",
      "| total_timesteps    | 6500      |\n",
      "| value_loss         | 7.23e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 122      |\n",
      "| ep_reward_mean     | -17.9    |\n",
      "| explained_variance | -0.00867 |\n",
      "| fps                | 472      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 94.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 123      |\n",
      "| ep_reward_mean     | -18      |\n",
      "| explained_variance | -138     |\n",
      "| fps                | 483      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 2.08e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 123      |\n",
      "| ep_reward_mean     | -17.9    |\n",
      "| explained_variance | -18.8    |\n",
      "| fps                | 482      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 3.19e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 126      |\n",
      "| ep_reward_mean     | -18.2    |\n",
      "| explained_variance | -0.00295 |\n",
      "| fps                | 473      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 124      |\n",
      "| ep_reward_mean     | -18.1    |\n",
      "| explained_variance | -15.2    |\n",
      "| fps                | 457      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 0.00023  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 121      |\n",
      "| ep_reward_mean     | -17.8    |\n",
      "| explained_variance | -164     |\n",
      "| fps                | 456      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 0.000668 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 120      |\n",
      "| ep_reward_mean     | -17.8    |\n",
      "| explained_variance | 0.0175   |\n",
      "| fps                | 448      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 916\n",
      "---------------------------------\n",
      "| ep_len_mean        | 120      |\n",
      "| ep_reward_mean     | -17.8    |\n",
      "| explained_variance | -20.4    |\n",
      "| fps                | 1036     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000535 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 117       |\n",
      "| ep_reward_mean     | -17.6     |\n",
      "| explained_variance | -1.47e+03 |\n",
      "| fps                | 322       |\n",
      "| nupdates           | 100       |\n",
      "| policy_entropy     | 1.37      |\n",
      "| total_timesteps    | 500       |\n",
      "| value_loss         | 0.00059   |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 114      |\n",
      "| ep_reward_mean     | -17.4    |\n",
      "| explained_variance | -176     |\n",
      "| fps                | 284      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 2.71e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 117      |\n",
      "| ep_reward_mean     | -17.6    |\n",
      "| explained_variance | 0.00131  |\n",
      "| fps                | 336      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 118      |\n",
      "| ep_reward_mean     | -17.8    |\n",
      "| explained_variance | -110     |\n",
      "| fps                | 358      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 3.82e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 120      |\n",
      "| ep_reward_mean     | -17.9    |\n",
      "| explained_variance | -42.8    |\n",
      "| fps                | 372      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 7.92e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 118      |\n",
      "| ep_reward_mean     | -17.7    |\n",
      "| explained_variance | -0.0214  |\n",
      "| fps                | 364      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 121      |\n",
      "| ep_reward_mean     | -18      |\n",
      "| explained_variance | -153     |\n",
      "| fps                | 374      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 5.36e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 120      |\n",
      "| ep_reward_mean     | -17.9    |\n",
      "| explained_variance | -7.45    |\n",
      "| fps                | 391      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 8.48e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 120      |\n",
      "| ep_reward_mean     | -17.8    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 403      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 118      |\n",
      "| ep_reward_mean     | -17.9    |\n",
      "| explained_variance | 0.0182   |\n",
      "| fps                | 414      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 2.28e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 120      |\n",
      "| ep_reward_mean     | -17.8    |\n",
      "| explained_variance | -2.55    |\n",
      "| fps                | 429      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 4.59e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 123      |\n",
      "| ep_reward_mean     | -18.1    |\n",
      "| explained_variance | -0.00364 |\n",
      "| fps                | 429      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 94.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 120      |\n",
      "| ep_reward_mean     | -17.9    |\n",
      "| explained_variance | -638     |\n",
      "| fps                | 429      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 1.67e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 117      |\n",
      "| ep_reward_mean     | -17.7    |\n",
      "| explained_variance | -0.0849  |\n",
      "| fps                | 419      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 3.78e-06 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 105      |\n",
      "| ep_reward_mean     | -16.9    |\n",
      "| explained_variance | -0.0162  |\n",
      "| fps                | 384      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 93.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 103      |\n",
      "| ep_reward_mean     | -16.8    |\n",
      "| explained_variance | -992     |\n",
      "| fps                | 390      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 1.18e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 99.5     |\n",
      "| ep_reward_mean     | -16.5    |\n",
      "| explained_variance | -1.07    |\n",
      "| fps                | 378      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 5.89e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 98.4     |\n",
      "| ep_reward_mean     | -16.4    |\n",
      "| explained_variance | -0.00117 |\n",
      "| fps                | 365      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 99       |\n",
      "| ep_reward_mean     | -16.6    |\n",
      "| explained_variance | -48.6    |\n",
      "| fps                | 375      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 2.55e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 97.5     |\n",
      "| ep_reward_mean     | -16.4    |\n",
      "| explained_variance | -473     |\n",
      "| fps                | 366      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 3.02e-05 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1018\n",
      "---------------------------------\n",
      "| ep_len_mean        | 97.5     |\n",
      "| ep_reward_mean     | -16.4    |\n",
      "| explained_variance | -34.5    |\n",
      "| fps                | 1261     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 5.92e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 99.4     |\n",
      "| ep_reward_mean     | -16.4    |\n",
      "| explained_variance | -0.101   |\n",
      "| fps                | 374      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 99.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 101      |\n",
      "| ep_reward_mean     | -16.6    |\n",
      "| explained_variance | -263     |\n",
      "| fps                | 486      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 1.91e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 102      |\n",
      "| ep_reward_mean     | -16.7    |\n",
      "| explained_variance | 0.437    |\n",
      "| fps                | 394      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 3.14e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 102      |\n",
      "| ep_reward_mean     | -16.7    |\n",
      "| explained_variance | 0.00558  |\n",
      "| fps                | 408      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 99.8     |\n",
      "| ep_reward_mean     | -16.6    |\n",
      "| explained_variance | -49.8    |\n",
      "| fps                | 415      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 1.1e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 101      |\n",
      "| ep_reward_mean     | -16.6    |\n",
      "| explained_variance | -9.45    |\n",
      "| fps                | 420      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 1.47e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 102      |\n",
      "| ep_reward_mean     | -16.7    |\n",
      "| explained_variance | 0.00181  |\n",
      "| fps                | 403      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 96.7     |\n",
      "| ep_reward_mean     | -16.2    |\n",
      "| explained_variance | -233     |\n",
      "| fps                | 399      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 7.42e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 93.4     |\n",
      "| ep_reward_mean     | -16.1    |\n",
      "| explained_variance | -0.854   |\n",
      "| fps                | 389      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 2.03e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 90       |\n",
      "| ep_reward_mean     | -15.9    |\n",
      "| explained_variance | -0.0204  |\n",
      "| fps                | 389      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 87.5     |\n",
      "| ep_reward_mean     | -15.6    |\n",
      "| explained_variance | -105     |\n",
      "| fps                | 387      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 4.84e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 90.7     |\n",
      "| ep_reward_mean     | -15.8    |\n",
      "| explained_variance | -0.574   |\n",
      "| fps                | 390      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 1.84e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 94.3     |\n",
      "| ep_reward_mean     | -16.1    |\n",
      "| explained_variance | 0.00247  |\n",
      "| fps                | 392      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 92       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 96.8     |\n",
      "| ep_reward_mean     | -16.3    |\n",
      "| explained_variance | -23.5    |\n",
      "| fps                | 404      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 2.2e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 102      |\n",
      "| ep_reward_mean     | -16.7    |\n",
      "| explained_variance | -26.8    |\n",
      "| fps                | 410      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 1.2e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 106      |\n",
      "| ep_reward_mean     | -16.9    |\n",
      "| explained_variance | -0.0191  |\n",
      "| fps                | 415      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 108      |\n",
      "| ep_reward_mean     | -17.1    |\n",
      "| explained_variance | -233     |\n",
      "| fps                | 430      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 3.17e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 107      |\n",
      "| ep_reward_mean     | -17      |\n",
      "| explained_variance | -10.1    |\n",
      "| fps                | 425      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 5.04e-05 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 111      |\n",
      "| ep_reward_mean     | -17.2    |\n",
      "| explained_variance | 0.00988  |\n",
      "| fps                | 430      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 93.9     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 113       |\n",
      "| ep_reward_mean     | -17.4     |\n",
      "| explained_variance | -1.14e+05 |\n",
      "| fps                | 430       |\n",
      "| nupdates           | 2000      |\n",
      "| policy_entropy     | 1.35      |\n",
      "| total_timesteps    | 10000     |\n",
      "| value_loss         | 0.000174  |\n",
      "----------------------------------\n",
      "Length of Rewards for A2C: 1100\n",
      "---------------------------------\n",
      "| ep_len_mean        | 114      |\n",
      "| ep_reward_mean     | -17.4    |\n",
      "| explained_variance | 0.529    |\n",
      "| fps                | 24       |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000233 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 115      |\n",
      "| ep_reward_mean     | -17.5    |\n",
      "| explained_variance | -557     |\n",
      "| fps                | 319      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 1.95e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 117      |\n",
      "| ep_reward_mean     | -17.7    |\n",
      "| explained_variance | 0.000262 |\n",
      "| fps                | 368      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 116       |\n",
      "| ep_reward_mean     | -17.6     |\n",
      "| explained_variance | -2.63e+03 |\n",
      "| fps                | 431       |\n",
      "| nupdates           | 300       |\n",
      "| policy_entropy     | 0.96      |\n",
      "| total_timesteps    | 1500      |\n",
      "| value_loss         | 0.000133  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 120      |\n",
      "| ep_reward_mean     | -17.9    |\n",
      "| explained_variance | -57.1    |\n",
      "| fps                | 432      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 7.57e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 123      |\n",
      "| ep_reward_mean     | -18      |\n",
      "| explained_variance | 0.000986 |\n",
      "| fps                | 449      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 93.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 126      |\n",
      "| ep_reward_mean     | -18.3    |\n",
      "| explained_variance | 0.482    |\n",
      "| fps                | 494      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 1.9e-07  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 124      |\n",
      "| ep_reward_mean     | -18.2    |\n",
      "| explained_variance | -41.4    |\n",
      "| fps                | 461      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 1.91e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 125      |\n",
      "| ep_reward_mean     | -18.3    |\n",
      "| explained_variance | 0.00835  |\n",
      "| fps                | 429      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 93.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 121      |\n",
      "| ep_reward_mean     | -18.1    |\n",
      "| explained_variance | -23.7    |\n",
      "| fps                | 423      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 9.68e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 118       |\n",
      "| ep_reward_mean     | -17.9     |\n",
      "| explained_variance | -3.64e+04 |\n",
      "| fps                | 391       |\n",
      "| nupdates           | 1000      |\n",
      "| policy_entropy     | 1.35      |\n",
      "| total_timesteps    | 5000      |\n",
      "| value_loss         | 0.000242  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 117      |\n",
      "| ep_reward_mean     | -17.7    |\n",
      "| explained_variance | 1.19e-07 |\n",
      "| fps                | 383      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 115      |\n",
      "| ep_reward_mean     | -17.7    |\n",
      "| explained_variance | -2.12    |\n",
      "| fps                | 363      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 0.000462 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 112       |\n",
      "| ep_reward_mean     | -17.5     |\n",
      "| explained_variance | -1.45e+03 |\n",
      "| fps                | 349       |\n",
      "| nupdates           | 1300      |\n",
      "| policy_entropy     | 1.32      |\n",
      "| total_timesteps    | 6500      |\n",
      "| value_loss         | 3.97e-08  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 105      |\n",
      "| ep_reward_mean     | -16.9    |\n",
      "| explained_variance | -0.00107 |\n",
      "| fps                | 344      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 19.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 88.7     |\n",
      "| ep_reward_mean     | -16      |\n",
      "| explained_variance | -0.597   |\n",
      "| fps                | 324      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 5.6e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 84.2     |\n",
      "| ep_reward_mean     | -15.6    |\n",
      "| explained_variance | -4.84    |\n",
      "| fps                | 324      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 2.32e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 87       |\n",
      "| ep_reward_mean     | -15.8    |\n",
      "| explained_variance | 0.0289   |\n",
      "| fps                | 332      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 93.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 88       |\n",
      "| ep_reward_mean     | -15.8    |\n",
      "| explained_variance | -9.95    |\n",
      "| fps                | 342      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 1.76e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 92       |\n",
      "| ep_reward_mean     | -16.1    |\n",
      "| explained_variance | -0.204   |\n",
      "| fps                | 347      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 0.00377  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 84       |\n",
      "| ep_reward_mean     | -15.6    |\n",
      "| explained_variance | -0.098   |\n",
      "| fps                | 341      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1213\n",
      "---------------------------------\n",
      "| ep_len_mean        | 84       |\n",
      "| ep_reward_mean     | -15.6    |\n",
      "| explained_variance | -21.3    |\n",
      "| fps                | 1224     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000299 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 81.6     |\n",
      "| ep_reward_mean     | -15.5    |\n",
      "| explained_variance | -308     |\n",
      "| fps                | 377      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 8.3e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 78.1     |\n",
      "| ep_reward_mean     | -15.1    |\n",
      "| explained_variance | -1.81    |\n",
      "| fps                | 445      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 1.42e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 81       |\n",
      "| ep_reward_mean     | -15.4    |\n",
      "| explained_variance | -0.00301 |\n",
      "| fps                | 474      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 82.6      |\n",
      "| ep_reward_mean     | -15.5     |\n",
      "| explained_variance | -4.01e+03 |\n",
      "| fps                | 467       |\n",
      "| nupdates           | 400       |\n",
      "| policy_entropy     | 1.36      |\n",
      "| total_timesteps    | 2000      |\n",
      "| value_loss         | 3.16e-06  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 85.3     |\n",
      "| ep_reward_mean     | -15.6    |\n",
      "| explained_variance | -0.767   |\n",
      "| fps                | 479      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 4.2e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 87.9     |\n",
      "| ep_reward_mean     | -15.8    |\n",
      "| explained_variance | 8.4e-06  |\n",
      "| fps                | 472      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 94.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 90.8     |\n",
      "| ep_reward_mean     | -15.9    |\n",
      "| explained_variance | -47.9    |\n",
      "| fps                | 510      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 2.4e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 94.8     |\n",
      "| ep_reward_mean     | -16.2    |\n",
      "| explained_variance | -1.24    |\n",
      "| fps                | 528      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 1.3e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 97.6     |\n",
      "| ep_reward_mean     | -16.4    |\n",
      "| explained_variance | 0.0463   |\n",
      "| fps                | 516      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 98       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 100      |\n",
      "| ep_reward_mean     | -16.6    |\n",
      "| explained_variance | -50.7    |\n",
      "| fps                | 543      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 6.08e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 104      |\n",
      "| ep_reward_mean     | -16.9    |\n",
      "| explained_variance | -5.06    |\n",
      "| fps                | 532      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 1.36e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 106      |\n",
      "| ep_reward_mean     | -17      |\n",
      "| explained_variance | -0.00688 |\n",
      "| fps                | 514      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 107      |\n",
      "| ep_reward_mean     | -17.1    |\n",
      "| explained_variance | -28.7    |\n",
      "| fps                | 500      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 9.5e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 110      |\n",
      "| ep_reward_mean     | -17.3    |\n",
      "| explained_variance | -14.1    |\n",
      "| fps                | 503      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 3.9e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 114      |\n",
      "| ep_reward_mean     | -17.6    |\n",
      "| explained_variance | -0.00038 |\n",
      "| fps                | 498      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 115      |\n",
      "| ep_reward_mean     | -17.6    |\n",
      "| explained_variance | -17.8    |\n",
      "| fps                | 506      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 4.07e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 120      |\n",
      "| ep_reward_mean     | -17.9    |\n",
      "| explained_variance | -0.0175  |\n",
      "| fps                | 508      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 2.35e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 123      |\n",
      "| ep_reward_mean     | -18.2    |\n",
      "| explained_variance | 0.0112   |\n",
      "| fps                | 493      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 94.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 123      |\n",
      "| ep_reward_mean     | -18.2    |\n",
      "| explained_variance | -213     |\n",
      "| fps                | 485      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.11     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 7.15e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 126      |\n",
      "| ep_reward_mean     | -18.4    |\n",
      "| explained_variance | -1.07    |\n",
      "| fps                | 487      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 1.68e-05 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1283\n",
      "---------------------------------\n",
      "| ep_len_mean        | 126      |\n",
      "| ep_reward_mean     | -18.4    |\n",
      "| explained_variance | -3.95    |\n",
      "| fps                | 947      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 1.94e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 131      |\n",
      "| ep_reward_mean     | -18.7    |\n",
      "| explained_variance | 0.00367  |\n",
      "| fps                | 431      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 75.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 134      |\n",
      "| ep_reward_mean     | -18.9    |\n",
      "| explained_variance | -0.002   |\n",
      "| fps                | 531      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 4.08e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 137      |\n",
      "| ep_reward_mean     | -19.1    |\n",
      "| explained_variance | 0.305    |\n",
      "| fps                | 530      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 9.36e-06 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 141      |\n",
      "| ep_reward_mean     | -19.4    |\n",
      "| explained_variance | -0.0666  |\n",
      "| fps                | 508      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 95.6     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 138       |\n",
      "| ep_reward_mean     | -19.2     |\n",
      "| explained_variance | -6.16e+04 |\n",
      "| fps                | 510       |\n",
      "| nupdates           | 500       |\n",
      "| policy_entropy     | 1.37      |\n",
      "| total_timesteps    | 2500      |\n",
      "| value_loss         | 1.4e-05   |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 138      |\n",
      "| ep_reward_mean     | -19.2    |\n",
      "| explained_variance | -11.2    |\n",
      "| fps                | 514      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 5.83e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 140      |\n",
      "| ep_reward_mean     | -19.3    |\n",
      "| explained_variance | 0.00713  |\n",
      "| fps                | 501      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 94.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 142      |\n",
      "| ep_reward_mean     | -19.4    |\n",
      "| explained_variance | -47.1    |\n",
      "| fps                | 532      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 1.56e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 144      |\n",
      "| ep_reward_mean     | -19.6    |\n",
      "| explained_variance | -6.41    |\n",
      "| fps                | 484      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 3.78e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 146      |\n",
      "| ep_reward_mean     | -19.7    |\n",
      "| explained_variance | -0.00793 |\n",
      "| fps                | 489      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 147      |\n",
      "| ep_reward_mean     | -19.8    |\n",
      "| explained_variance | 0.493    |\n",
      "| fps                | 501      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 6.97e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 144      |\n",
      "| ep_reward_mean     | -19.6    |\n",
      "| explained_variance | -147     |\n",
      "| fps                | 479      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.12     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 9e-05    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 142      |\n",
      "| ep_reward_mean     | -19.4    |\n",
      "| explained_variance | 0.0324   |\n",
      "| fps                | 468      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 94.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 138      |\n",
      "| ep_reward_mean     | -19.2    |\n",
      "| explained_variance | -2.93    |\n",
      "| fps                | 460      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.17     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 5.81e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 138      |\n",
      "| ep_reward_mean     | -19.2    |\n",
      "| explained_variance | -10.1    |\n",
      "| fps                | 470      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 1.22e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 137      |\n",
      "| ep_reward_mean     | -19.1    |\n",
      "| explained_variance | -0.019   |\n",
      "| fps                | 468      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 95.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 138      |\n",
      "| ep_reward_mean     | -19.2    |\n",
      "| explained_variance | -269     |\n",
      "| fps                | 482      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 5.78e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 136      |\n",
      "| ep_reward_mean     | -19.1    |\n",
      "| explained_variance | -156     |\n",
      "| fps                | 474      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 4.28e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 136      |\n",
      "| ep_reward_mean     | -19      |\n",
      "| explained_variance | -0.00034 |\n",
      "| fps                | 473      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 138      |\n",
      "| ep_reward_mean     | -19.2    |\n",
      "| explained_variance | -8.52    |\n",
      "| fps                | 486      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 6.44e-06 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1352\n",
      "---------------------------------\n",
      "| ep_len_mean        | 138      |\n",
      "| ep_reward_mean     | -19.2    |\n",
      "| explained_variance | -0.00363 |\n",
      "| fps                | 1253     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 1.4e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 141      |\n",
      "| ep_reward_mean     | -19.4    |\n",
      "| explained_variance | -0.595   |\n",
      "| fps                | 433      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 3.11e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 141      |\n",
      "| ep_reward_mean     | -19.4    |\n",
      "| explained_variance | -0.02    |\n",
      "| fps                | 441      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 131      |\n",
      "| ep_reward_mean     | -18.8    |\n",
      "| explained_variance | -135     |\n",
      "| fps                | 356      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 6.95e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 131      |\n",
      "| ep_reward_mean     | -18.7    |\n",
      "| explained_variance | -0.198   |\n",
      "| fps                | 347      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 1.15e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 126      |\n",
      "| ep_reward_mean     | -18.4    |\n",
      "| explained_variance | 0.00793  |\n",
      "| fps                | 316      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 94.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 124      |\n",
      "| ep_reward_mean     | -18.1    |\n",
      "| explained_variance | 0.0667   |\n",
      "| fps                | 339      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 3.22e-06 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 118      |\n",
      "| ep_reward_mean     | -17.9    |\n",
      "| explained_variance | -0.0271  |\n",
      "| fps                | 330      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 0.00163  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 114      |\n",
      "| ep_reward_mean     | -17.6    |\n",
      "| explained_variance | 0.038    |\n",
      "| fps                | 324      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 94.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 103      |\n",
      "| ep_reward_mean     | -16.8    |\n",
      "| explained_variance | -58.7    |\n",
      "| fps                | 306      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 3.37e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 103       |\n",
      "| ep_reward_mean     | -16.8     |\n",
      "| explained_variance | -2.29e+03 |\n",
      "| fps                | 312       |\n",
      "| nupdates           | 1000      |\n",
      "| policy_entropy     | 1.22      |\n",
      "| total_timesteps    | 5000      |\n",
      "| value_loss         | 0.000819  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 104      |\n",
      "| ep_reward_mean     | -16.8    |\n",
      "| explained_variance | 0.0152   |\n",
      "| fps                | 325      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 93.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 99.8     |\n",
      "| ep_reward_mean     | -16.5    |\n",
      "| explained_variance | -70.9    |\n",
      "| fps                | 325      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 0.00014  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 97.7     |\n",
      "| ep_reward_mean     | -16.4    |\n",
      "| explained_variance | -69.6    |\n",
      "| fps                | 322      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 2.31e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 102      |\n",
      "| ep_reward_mean     | -16.7    |\n",
      "| explained_variance | -0.00352 |\n",
      "| fps                | 329      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 93.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 99       |\n",
      "| ep_reward_mean     | -16.6    |\n",
      "| explained_variance | -0.668   |\n",
      "| fps                | 341      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 1.25e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 101      |\n",
      "| ep_reward_mean     | -16.6    |\n",
      "| explained_variance | -1.57    |\n",
      "| fps                | 349      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 3.13e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 102      |\n",
      "| ep_reward_mean     | -16.8    |\n",
      "| explained_variance | -0.0231  |\n",
      "| fps                | 360      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 99.2     |\n",
      "| ep_reward_mean     | -16.5    |\n",
      "| explained_variance | -11.4    |\n",
      "| fps                | 366      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 5.72e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 102      |\n",
      "| ep_reward_mean     | -16.7    |\n",
      "| explained_variance | -745     |\n",
      "| fps                | 370      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 7.82e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 105      |\n",
      "| ep_reward_mean     | -17      |\n",
      "| explained_variance | 0.00152  |\n",
      "| fps                | 379      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 93.5     |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1451\n",
      "---------------------------------\n",
      "| ep_len_mean        | 105      |\n",
      "| ep_reward_mean     | -17      |\n",
      "| explained_variance | -54      |\n",
      "| fps                | 1274     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000963 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 93.5     |\n",
      "| ep_reward_mean     | -16.2    |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 196      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 6.65e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 96.3     |\n",
      "| ep_reward_mean     | -16.3    |\n",
      "| explained_variance | -0.0992  |\n",
      "| fps                | 272      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 9.2e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 99.9     |\n",
      "| ep_reward_mean     | -16.5    |\n",
      "| explained_variance | -0.00813 |\n",
      "| fps                | 328      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 94.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 102      |\n",
      "| ep_reward_mean     | -16.8    |\n",
      "| explained_variance | -23.8    |\n",
      "| fps                | 395      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 2.95e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 102      |\n",
      "| ep_reward_mean     | -16.8    |\n",
      "| explained_variance | -3.9     |\n",
      "| fps                | 379      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 1.52e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 106      |\n",
      "| ep_reward_mean     | -17      |\n",
      "| explained_variance | 0.00556  |\n",
      "| fps                | 407      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 109      |\n",
      "| ep_reward_mean     | -17.2    |\n",
      "| explained_variance | -4.39    |\n",
      "| fps                | 433      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 4.17e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 114      |\n",
      "| ep_reward_mean     | -17.6    |\n",
      "| explained_variance | -21.4    |\n",
      "| fps                | 443      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 1.53e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 117      |\n",
      "| ep_reward_mean     | -17.8    |\n",
      "| explained_variance | -0.00433 |\n",
      "| fps                | 463      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 118      |\n",
      "| ep_reward_mean     | -17.7    |\n",
      "| explained_variance | -143     |\n",
      "| fps                | 478      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 0.00016  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 120      |\n",
      "| ep_reward_mean     | -18      |\n",
      "| explained_variance | 0.636    |\n",
      "| fps                | 475      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 1.04e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 123      |\n",
      "| ep_reward_mean     | -18.2    |\n",
      "| explained_variance | -0.0213  |\n",
      "| fps                | 473      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 123      |\n",
      "| ep_reward_mean     | -18.2    |\n",
      "| explained_variance | -5.32    |\n",
      "| fps                | 464      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 1.74e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 126      |\n",
      "| ep_reward_mean     | -18.3    |\n",
      "| explained_variance | -9.48    |\n",
      "| fps                | 462      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 6.57e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 131      |\n",
      "| ep_reward_mean     | -18.7    |\n",
      "| explained_variance | 1.4e-05  |\n",
      "| fps                | 467      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 133      |\n",
      "| ep_reward_mean     | -18.8    |\n",
      "| explained_variance | -72.4    |\n",
      "| fps                | 471      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 1.13e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 135       |\n",
      "| ep_reward_mean     | -19       |\n",
      "| explained_variance | -0.000608 |\n",
      "| fps                | 464       |\n",
      "| nupdates           | 1700      |\n",
      "| policy_entropy     | 1.36      |\n",
      "| total_timesteps    | 8500      |\n",
      "| value_loss         | 1.51e-06  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 134      |\n",
      "| ep_reward_mean     | -18.9    |\n",
      "| explained_variance | -0.0149  |\n",
      "| fps                | 459      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 136      |\n",
      "| ep_reward_mean     | -19      |\n",
      "| explained_variance | -15      |\n",
      "| fps                | 467      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 5.85e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 138      |\n",
      "| ep_reward_mean     | -19.1    |\n",
      "| explained_variance | -2.07    |\n",
      "| fps                | 466      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 2.67e-06 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1526\n",
      "---------------------------------\n",
      "| ep_len_mean        | 138      |\n",
      "| ep_reward_mean     | -19.1    |\n",
      "| explained_variance | 7.15e-07 |\n",
      "| fps                | 1081     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 1.16e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 144      |\n",
      "| ep_reward_mean     | -19.6    |\n",
      "| explained_variance | -0.00378 |\n",
      "| fps                | 542      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 142      |\n",
      "| ep_reward_mean     | -19.5    |\n",
      "| explained_variance | -450     |\n",
      "| fps                | 545      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 7.29e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 140      |\n",
      "| ep_reward_mean     | -19.2    |\n",
      "| explained_variance | -31.7    |\n",
      "| fps                | 449      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 4.19e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 135      |\n",
      "| ep_reward_mean     | -18.9    |\n",
      "| explained_variance | -0.0154  |\n",
      "| fps                | 448      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 132      |\n",
      "| ep_reward_mean     | -18.6    |\n",
      "| explained_variance | -15.4    |\n",
      "| fps                | 447      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 2.03e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 132      |\n",
      "| ep_reward_mean     | -18.7    |\n",
      "| explained_variance | -14      |\n",
      "| fps                | 448      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 8.82e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 134      |\n",
      "| ep_reward_mean     | -18.8    |\n",
      "| explained_variance | -0.00565 |\n",
      "| fps                | 459      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 136      |\n",
      "| ep_reward_mean     | -18.9    |\n",
      "| explained_variance | -95.2    |\n",
      "| fps                | 482      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 0.000196 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 140      |\n",
      "| ep_reward_mean     | -19.2    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 458      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 1.19e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 142      |\n",
      "| ep_reward_mean     | -19.3    |\n",
      "| explained_variance | 0.00258  |\n",
      "| fps                | 457      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 141      |\n",
      "| ep_reward_mean     | -19.3    |\n",
      "| explained_variance | -10.6    |\n",
      "| fps                | 464      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 1.94e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 137      |\n",
      "| ep_reward_mean     | -19      |\n",
      "| explained_variance | 0.491    |\n",
      "| fps                | 455      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 0.000109 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 132      |\n",
      "| ep_reward_mean     | -18.7    |\n",
      "| explained_variance | 0.00862  |\n",
      "| fps                | 436      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 128      |\n",
      "| ep_reward_mean     | -18.3    |\n",
      "| explained_variance | 0.0424   |\n",
      "| fps                | 436      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.39     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 1.19e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 123      |\n",
      "| ep_reward_mean     | -18      |\n",
      "| explained_variance | -0.0204  |\n",
      "| fps                | 437      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 1.63e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 126      |\n",
      "| ep_reward_mean     | -18.2    |\n",
      "| explained_variance | 0.00347  |\n",
      "| fps                | 443      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 125      |\n",
      "| ep_reward_mean     | -18.2    |\n",
      "| explained_variance | -868     |\n",
      "| fps                | 443      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 0.000301 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 127      |\n",
      "| ep_reward_mean     | -18.3    |\n",
      "| explained_variance | -1.69    |\n",
      "| fps                | 439      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 1.09e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 123      |\n",
      "| ep_reward_mean     | -18      |\n",
      "| explained_variance | -0.00704 |\n",
      "| fps                | 435      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 124      |\n",
      "| ep_reward_mean     | -18      |\n",
      "| explained_variance | -111     |\n",
      "| fps                | 440      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 1.56e-05 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1608\n",
      "---------------------------------\n",
      "| ep_len_mean        | 124      |\n",
      "| ep_reward_mean     | -18      |\n",
      "| explained_variance | -50.4    |\n",
      "| fps                | 1322     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 5.91e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 121       |\n",
      "| ep_reward_mean     | -17.7     |\n",
      "| explained_variance | -1.46e+03 |\n",
      "| fps                | 375       |\n",
      "| nupdates           | 100       |\n",
      "| policy_entropy     | 1.37      |\n",
      "| total_timesteps    | 500       |\n",
      "| value_loss         | 4.96e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 123      |\n",
      "| ep_reward_mean     | -18      |\n",
      "| explained_variance | -0.0108  |\n",
      "| fps                | 445      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 125      |\n",
      "| ep_reward_mean     | -18.1    |\n",
      "| explained_variance | -140     |\n",
      "| fps                | 472      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 1.2e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 126      |\n",
      "| ep_reward_mean     | -18.2    |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 489      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 0.000139 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 129      |\n",
      "| ep_reward_mean     | -18.4    |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 519      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 0.000439 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 130       |\n",
      "| ep_reward_mean     | -18.5     |\n",
      "| explained_variance | -1.38e+03 |\n",
      "| fps                | 540       |\n",
      "| nupdates           | 600       |\n",
      "| policy_entropy     | 1.3       |\n",
      "| total_timesteps    | 3000      |\n",
      "| value_loss         | 1.58e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 130      |\n",
      "| ep_reward_mean     | -18.6    |\n",
      "| explained_variance | 0.000291 |\n",
      "| fps                | 540      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 1.87e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 131      |\n",
      "| ep_reward_mean     | -18.6    |\n",
      "| explained_variance | 0.00421  |\n",
      "| fps                | 539      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 130      |\n",
      "| ep_reward_mean     | -18.5    |\n",
      "| explained_variance | -1.8e+03 |\n",
      "| fps                | 541      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 8.15e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 135      |\n",
      "| ep_reward_mean     | -19      |\n",
      "| explained_variance | -1.06    |\n",
      "| fps                | 541      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 1.93e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 134      |\n",
      "| ep_reward_mean     | -18.9    |\n",
      "| explained_variance | -0.0623  |\n",
      "| fps                | 520      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.16     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 133      |\n",
      "| ep_reward_mean     | -18.7    |\n",
      "| explained_variance | -0.0849  |\n",
      "| fps                | 514      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 3.41e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 133      |\n",
      "| ep_reward_mean     | -18.8    |\n",
      "| explained_variance | -0.00184 |\n",
      "| fps                | 508      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 1.07e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 133       |\n",
      "| ep_reward_mean     | -18.8     |\n",
      "| explained_variance | -5.36e-06 |\n",
      "| fps                | 511       |\n",
      "| nupdates           | 1400      |\n",
      "| policy_entropy     | 1.31      |\n",
      "| total_timesteps    | 7000      |\n",
      "| value_loss         | 94.3      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 131      |\n",
      "| ep_reward_mean     | -18.7    |\n",
      "| explained_variance | -0.216   |\n",
      "| fps                | 512      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 1.75e-07 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 135      |\n",
      "| ep_reward_mean     | -19      |\n",
      "| explained_variance | 0.00047  |\n",
      "| fps                | 507      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 7.3e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 135      |\n",
      "| ep_reward_mean     | -19      |\n",
      "| explained_variance | 0.00343  |\n",
      "| fps                | 503      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 138      |\n",
      "| ep_reward_mean     | -19.2    |\n",
      "| explained_variance | -135     |\n",
      "| fps                | 510      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 0.000167 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 138      |\n",
      "| ep_reward_mean     | -19.1    |\n",
      "| explained_variance | -0.019   |\n",
      "| fps                | 517      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 2.01e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 141      |\n",
      "| ep_reward_mean     | -19.3    |\n",
      "| explained_variance | 0.0964   |\n",
      "| fps                | 518      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 94.9     |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1672\n",
      "---------------------------------\n",
      "| ep_len_mean        | 141      |\n",
      "| ep_reward_mean     | -19.3    |\n",
      "| explained_variance | -6.41    |\n",
      "| fps                | 1248     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 3.55e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 144      |\n",
      "| ep_reward_mean     | -19.6    |\n",
      "| explained_variance | -2.4e+03 |\n",
      "| fps                | 913      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 1.12e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 147      |\n",
      "| ep_reward_mean     | -19.7    |\n",
      "| explained_variance | -0.577   |\n",
      "| fps                | 676      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 2.99e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 150      |\n",
      "| ep_reward_mean     | -20      |\n",
      "| explained_variance | 0.000869 |\n",
      "| fps                | 579      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 95.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 153      |\n",
      "| ep_reward_mean     | -20.3    |\n",
      "| explained_variance | -72.8    |\n",
      "| fps                | 645      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 6.22e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 152      |\n",
      "| ep_reward_mean     | -20.2    |\n",
      "| explained_variance | -163     |\n",
      "| fps                | 560      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 0.000118 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 147      |\n",
      "| ep_reward_mean     | -19.8    |\n",
      "| explained_variance | -0.0355  |\n",
      "| fps                | 501      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 150      |\n",
      "| ep_reward_mean     | -20.1    |\n",
      "| explained_variance | 0.734    |\n",
      "| fps                | 521      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 6.08e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 153      |\n",
      "| ep_reward_mean     | -20.3    |\n",
      "| explained_variance | -38      |\n",
      "| fps                | 539      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 3.84e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 156      |\n",
      "| ep_reward_mean     | -20.5    |\n",
      "| explained_variance | 0.00813  |\n",
      "| fps                | 539      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 157      |\n",
      "| ep_reward_mean     | -20.7    |\n",
      "| explained_variance | -83.1    |\n",
      "| fps                | 528      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 1.06e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 153      |\n",
      "| ep_reward_mean     | -20.3    |\n",
      "| explained_variance | -23.3    |\n",
      "| fps                | 499      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 5.61e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 154      |\n",
      "| ep_reward_mean     | -20.4    |\n",
      "| explained_variance | -0.00218 |\n",
      "| fps                | 486      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 95.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 154      |\n",
      "| ep_reward_mean     | -20.4    |\n",
      "| explained_variance | -33.8    |\n",
      "| fps                | 490      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 2.55e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 153      |\n",
      "| ep_reward_mean     | -20.4    |\n",
      "| explained_variance | -477     |\n",
      "| fps                | 494      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.17     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 0.000289 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 153      |\n",
      "| ep_reward_mean     | -20.3    |\n",
      "| explained_variance | -0.0217  |\n",
      "| fps                | 495      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 93.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 151      |\n",
      "| ep_reward_mean     | -20.1    |\n",
      "| explained_variance | -42.6    |\n",
      "| fps                | 498      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 2.22e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 147      |\n",
      "| ep_reward_mean     | -19.8    |\n",
      "| explained_variance | 0.399    |\n",
      "| fps                | 496      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 7.12e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 148      |\n",
      "| ep_reward_mean     | -19.8    |\n",
      "| explained_variance | 0.000143 |\n",
      "| fps                | 498      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 147       |\n",
      "| ep_reward_mean     | -19.8     |\n",
      "| explained_variance | -1.03e+03 |\n",
      "| fps                | 501       |\n",
      "| nupdates           | 1900      |\n",
      "| policy_entropy     | 1.31      |\n",
      "| total_timesteps    | 9500      |\n",
      "| value_loss         | 3.13e-05  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 144      |\n",
      "| ep_reward_mean     | -19.7    |\n",
      "| explained_variance | -23.4    |\n",
      "| fps                | 483      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 0.000194 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1743\n",
      "---------------------------------\n",
      "| ep_len_mean        | 144      |\n",
      "| ep_reward_mean     | -19.7    |\n",
      "| explained_variance | -0.0256  |\n",
      "| fps                | 1583     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.0141   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 142      |\n",
      "| ep_reward_mean     | -19.5    |\n",
      "| explained_variance | 0.00488  |\n",
      "| fps                | 329      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 99.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 142      |\n",
      "| ep_reward_mean     | -19.5    |\n",
      "| explained_variance | -141     |\n",
      "| fps                | 374      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 7.45e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 137      |\n",
      "| ep_reward_mean     | -19.1    |\n",
      "| explained_variance | -16.8    |\n",
      "| fps                | 357      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 4.84e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 135      |\n",
      "| ep_reward_mean     | -19      |\n",
      "| explained_variance | 0.0112   |\n",
      "| fps                | 350      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 130      |\n",
      "| ep_reward_mean     | -18.7    |\n",
      "| explained_variance | 0.389    |\n",
      "| fps                | 365      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 8.65e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 121      |\n",
      "| ep_reward_mean     | -18      |\n",
      "| explained_variance | -27.5    |\n",
      "| fps                | 358      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 2.83e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 123      |\n",
      "| ep_reward_mean     | -18.2    |\n",
      "| explained_variance | 0.00424  |\n",
      "| fps                | 385      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 122       |\n",
      "| ep_reward_mean     | -18.2     |\n",
      "| explained_variance | -4.38e+03 |\n",
      "| fps                | 391       |\n",
      "| nupdates           | 800       |\n",
      "| policy_entropy     | 1.34      |\n",
      "| total_timesteps    | 4000      |\n",
      "| value_loss         | 9.35e-06  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 117       |\n",
      "| ep_reward_mean     | -17.9     |\n",
      "| explained_variance | -0.000754 |\n",
      "| fps                | 376       |\n",
      "| nupdates           | 900       |\n",
      "| policy_entropy     | 1.3       |\n",
      "| total_timesteps    | 4500      |\n",
      "| value_loss         | 4.58e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 117      |\n",
      "| ep_reward_mean     | -17.9    |\n",
      "| explained_variance | 0.000676 |\n",
      "| fps                | 371      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 96.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 113      |\n",
      "| ep_reward_mean     | -17.7    |\n",
      "| explained_variance | -0.122   |\n",
      "| fps                | 376      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 0.000374 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 110      |\n",
      "| ep_reward_mean     | -17.4    |\n",
      "| explained_variance | -31.1    |\n",
      "| fps                | 375      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 1.47e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 112       |\n",
      "| ep_reward_mean     | -17.5     |\n",
      "| explained_variance | -5.72e-05 |\n",
      "| fps                | 379       |\n",
      "| nupdates           | 1300      |\n",
      "| policy_entropy     | 1.38      |\n",
      "| total_timesteps    | 6500      |\n",
      "| value_loss         | 94.3      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 112      |\n",
      "| ep_reward_mean     | -17.6    |\n",
      "| explained_variance | -116     |\n",
      "| fps                | 383      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 2.11e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 108      |\n",
      "| ep_reward_mean     | -17.3    |\n",
      "| explained_variance | -128     |\n",
      "| fps                | 375      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 3.95e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 96.6     |\n",
      "| ep_reward_mean     | -16.4    |\n",
      "| explained_variance | 0.000539 |\n",
      "| fps                | 358      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 94.5     |\n",
      "| ep_reward_mean     | -16.5    |\n",
      "| explained_variance | -7.27    |\n",
      "| fps                | 358      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 5.34e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 93.8     |\n",
      "| ep_reward_mean     | -16.3    |\n",
      "| explained_variance | 0.00983  |\n",
      "| fps                | 359      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 1.51e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 93       |\n",
      "| ep_reward_mean     | -16.2    |\n",
      "| explained_variance | 0.0181   |\n",
      "| fps                | 352      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 89.8     |\n",
      "| ep_reward_mean     | -16      |\n",
      "| explained_variance | -0.997   |\n",
      "| fps                | 351      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 1.36e-07 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1852\n",
      "---------------------------------\n",
      "| ep_len_mean        | 89.8     |\n",
      "| ep_reward_mean     | -16      |\n",
      "| explained_variance | -9.65    |\n",
      "| fps                | 1327     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 1.32e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 88       |\n",
      "| ep_reward_mean     | -15.8    |\n",
      "| explained_variance | -3.85    |\n",
      "| fps                | 256      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 5.32e-06 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 90       |\n",
      "| ep_reward_mean     | -16      |\n",
      "| explained_variance | 8.23e-06 |\n",
      "| fps                | 303      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 93.8     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 87.9      |\n",
      "| ep_reward_mean     | -15.9     |\n",
      "| explained_variance | -8.91e+04 |\n",
      "| fps                | 297       |\n",
      "| nupdates           | 300       |\n",
      "| policy_entropy     | 1.37      |\n",
      "| total_timesteps    | 1500      |\n",
      "| value_loss         | 3.21e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 82.7     |\n",
      "| ep_reward_mean     | -15.5    |\n",
      "| explained_variance | -0.318   |\n",
      "| fps                | 304      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 2.75e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 82.8     |\n",
      "| ep_reward_mean     | -15.4    |\n",
      "| explained_variance | 5.96e-07 |\n",
      "| fps                | 300      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 84        |\n",
      "| ep_reward_mean     | -15.5     |\n",
      "| explained_variance | -5.98e-05 |\n",
      "| fps                | 323       |\n",
      "| nupdates           | 600       |\n",
      "| policy_entropy     | 1.37      |\n",
      "| total_timesteps    | 3000      |\n",
      "| value_loss         | 1.03e-06  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 85.9     |\n",
      "| ep_reward_mean     | -15.6    |\n",
      "| explained_variance | -18.4    |\n",
      "| fps                | 337      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 1.98e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 90       |\n",
      "| ep_reward_mean     | -15.9    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 361      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 93.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 90       |\n",
      "| ep_reward_mean     | -15.9    |\n",
      "| explained_variance | -199     |\n",
      "| fps                | 369      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 2.26e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 90.8     |\n",
      "| ep_reward_mean     | -16      |\n",
      "| explained_variance | -182     |\n",
      "| fps                | 375      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 0.000668 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 90       |\n",
      "| ep_reward_mean     | -15.9    |\n",
      "| explained_variance | 1e-05    |\n",
      "| fps                | 375      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 89.6     |\n",
      "| ep_reward_mean     | -15.8    |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 374      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 0.00428  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 89.6     |\n",
      "| ep_reward_mean     | -15.8    |\n",
      "| explained_variance | -508     |\n",
      "| fps                | 366      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 0.000712 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 90.3     |\n",
      "| ep_reward_mean     | -15.8    |\n",
      "| explained_variance | 0.00138  |\n",
      "| fps                | 354      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 89.2     |\n",
      "| ep_reward_mean     | -15.8    |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 352      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 2.1e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 93       |\n",
      "| ep_reward_mean     | -16.2    |\n",
      "| explained_variance | -62.8    |\n",
      "| fps                | 360      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 2.81e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 93        |\n",
      "| ep_reward_mean     | -16.2     |\n",
      "| explained_variance | -0.000183 |\n",
      "| fps                | 357       |\n",
      "| nupdates           | 1700      |\n",
      "| policy_entropy     | 1.35      |\n",
      "| total_timesteps    | 8500      |\n",
      "| value_loss         | 96        |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 93.2     |\n",
      "| ep_reward_mean     | -16.2    |\n",
      "| explained_variance | -16.7    |\n",
      "| fps                | 360      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 1.4e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 96       |\n",
      "| ep_reward_mean     | -16.4    |\n",
      "| explained_variance | -0.00335 |\n",
      "| fps                | 368      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 5.7e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 99.5     |\n",
      "| ep_reward_mean     | -16.5    |\n",
      "| explained_variance | 0.00824  |\n",
      "| fps                | 369      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 94.6     |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1953\n",
      "---------------------------------\n",
      "| ep_len_mean        | 99.5     |\n",
      "| ep_reward_mean     | -16.5    |\n",
      "| explained_variance | -342     |\n",
      "| fps                | 861      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.00121  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 103      |\n",
      "| ep_reward_mean     | -16.9    |\n",
      "| explained_variance | -9.14    |\n",
      "| fps                | 559      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 5.1e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 105      |\n",
      "| ep_reward_mean     | -17      |\n",
      "| explained_variance | -3.78    |\n",
      "| fps                | 444      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 1.5e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 104      |\n",
      "| ep_reward_mean     | -16.9    |\n",
      "| explained_variance | 0.0174   |\n",
      "| fps                | 394      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 105      |\n",
      "| ep_reward_mean     | -17      |\n",
      "| explained_variance | -31.1    |\n",
      "| fps                | 388      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 1.06e-05 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 104      |\n",
      "| ep_reward_mean     | -16.9    |\n",
      "| explained_variance | 0.00572  |\n",
      "| fps                | 362      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 1.1e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 108      |\n",
      "| ep_reward_mean     | -17.1    |\n",
      "| explained_variance | -0.0272  |\n",
      "| fps                | 366      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 99        |\n",
      "| ep_reward_mean     | -16.6     |\n",
      "| explained_variance | -5.11e+03 |\n",
      "| fps                | 332       |\n",
      "| nupdates           | 700       |\n",
      "| policy_entropy     | 1.26      |\n",
      "| total_timesteps    | 3500      |\n",
      "| value_loss         | 3.88e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 93       |\n",
      "| ep_reward_mean     | -16.2    |\n",
      "| explained_variance | -0.001   |\n",
      "| fps                | 325      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 6.44e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 95.2      |\n",
      "| ep_reward_mean     | -16.3     |\n",
      "| explained_variance | -5.72e-06 |\n",
      "| fps                | 339       |\n",
      "| nupdates           | 900       |\n",
      "| policy_entropy     | 1.34      |\n",
      "| total_timesteps    | 4500      |\n",
      "| value_loss         | 95.4      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 93.1     |\n",
      "| ep_reward_mean     | -16.2    |\n",
      "| explained_variance | -59.8    |\n",
      "| fps                | 342      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 2.95e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 93.7     |\n",
      "| ep_reward_mean     | -16.2    |\n",
      "| explained_variance | 0.000826 |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 5.52e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 92.7     |\n",
      "| ep_reward_mean     | -16.3    |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 323      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 1.38e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 88.3     |\n",
      "| ep_reward_mean     | -16      |\n",
      "| explained_variance | 0.4      |\n",
      "| fps                | 307      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 1.98e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 84       |\n",
      "| ep_reward_mean     | -15.7    |\n",
      "| explained_variance | 0.00195  |\n",
      "| fps                | 303      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 1.53e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 78.4     |\n",
      "| ep_reward_mean     | -15.2    |\n",
      "| explained_variance | 0.0123   |\n",
      "| fps                | 299      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 94.6     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 79.4      |\n",
      "| ep_reward_mean     | -15.4     |\n",
      "| explained_variance | -6.69e-05 |\n",
      "| fps                | 308       |\n",
      "| nupdates           | 1600      |\n",
      "| policy_entropy     | 1.38      |\n",
      "| total_timesteps    | 8000      |\n",
      "| value_loss         | 2.16e-07  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 75.5     |\n",
      "| ep_reward_mean     | -15.1    |\n",
      "| explained_variance | 0.00328  |\n",
      "| fps                | 309      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 7.2e-09  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 75.8     |\n",
      "| ep_reward_mean     | -15.1    |\n",
      "| explained_variance | 0.0444   |\n",
      "| fps                | 310      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 95.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 76.5     |\n",
      "| ep_reward_mean     | -15.3    |\n",
      "| explained_variance | 0.489    |\n",
      "| fps                | 312      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 2e-08    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 78.9     |\n",
      "| ep_reward_mean     | -15.3    |\n",
      "| explained_variance | -17.2    |\n",
      "| fps                | 321      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 4.05e-05 |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "while (len(rewards) < 2000):\n",
    "    print(\"Length of Rewards for DQN: {}\".format(len(rewards)))\n",
    "    model.learn(total_timesteps=10000)\n",
    "    rewards = env.get_episode_rewards()\n",
    "\n",
    "while (len(rewards2) < 2000):\n",
    "    print(\"Length of Rewards for A2C: {}\".format(len(rewards2)))\n",
    "    model2.learn(total_timesteps=10000)\n",
    "    rewards2 = env2.get_episode_rewards()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = rewards[:2000]\n",
    "rewards2 = rewards2[:2000]\n",
    "episodes = len(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.title(\"Task {}\".format(i+1))\n",
    "plt.plot(list(range(episodes)),rewards, label='DQN')\n",
    "plt.plot(list(range(episodes)),rewards2, label='A2C')\n",
    "plt.legend()\n",
    "plt.savefig(\"Task 1 A4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.title(\"Task {}\".format(i+1))\n",
    "plt.plot(list(range(episodes)[1900:]),rewards[1900:], label='DQN')\n",
    "plt.plot(list(range(episodes)[1900:]),rewards2[1900:], label='A2C')\n",
    "plt.ylim(bottom=-20,top=2)\n",
    "plt.legend()\n",
    "plt.savefig(\"Task 1 A4 Last 100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30000000000000004\n",
      "0.10000000000000009\n"
     ]
    }
   ],
   "source": [
    "print(max(rewards))\n",
    "print(max(rewards2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.312490999999997\n",
      "53.102419000000324\n"
     ]
    }
   ],
   "source": [
    "print(np.var(rewards[1900:]))\n",
    "print(np.var(rewards2[1900:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
