{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "from maze_env import Maze\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stable_baselines.common.env_checker import check_env\n",
    "from stable_baselines.bench import Monitor\n",
    "from stable_baselines import DQN,A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TK_SILENCE_DEPRECATION=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MazeGym(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    def __init__(self,task):\n",
    "        self.first = 0\n",
    "        self.agentXY = [0,0]\n",
    "        self.goalXY = [4,4]\n",
    "        walls,pits = self.mazeInfo(task)\n",
    "        self.env = Maze(self.agentXY, self.goalXY, walls, pits)\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        self.observation_space = spaces.Box(low=5,high=395,shape=(4,))\n",
    "        self.counter = 0\n",
    "        self.max_steps = 300\n",
    "    \n",
    "    def mazeInfo(self, task):\n",
    "        if task == 0:\n",
    "            wall_shape=np.array([[2,2],[3,6]])\n",
    "            pits=np.array([[6,3],[1,4]])\n",
    "        elif task == 1:\n",
    "            wall_shape=np.array([[6,2],[5,2],[4,2],[3,2],[2,2],[6,3],[6,4],[6,5],[2,3],[2,4],[2,5]])\n",
    "            pits=[]\n",
    "        elif task == 2:\n",
    "            wall_shape=np.array([[6,3],[6,3],[6,2],[5,2],[4,2],[3,2],[3,3],[3,4],[3,5],[3,6],[4,6],[5,6],[5,7],[7,3]])\n",
    "            pits=np.array([[1,3],[0,5], [7,7], [8,5]])\n",
    "        return wall_shape, pits\n",
    "\n",
    "    def step(self,action):\n",
    "        self.counter += 1\n",
    "        s_,r,d = self.env.step(action)\n",
    "        if (self.counter == self.max_steps):\n",
    "            self.counter = 0\n",
    "            d = True\n",
    "        return np.array(s_),r,d,{}\n",
    "\n",
    "    def reset(self):\n",
    "        state = np.array(self.env.reset(value=self.first))\n",
    "        self.first = 1\n",
    "        return state\n",
    "\n",
    "    def render(self,mode='human'):\n",
    "        self.env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/deepq/dqn.py:129: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:358: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:359: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:139: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/deepq/policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:149: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:415: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:449: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 1 # represents which task we will run\n",
    "env = MazeGym(task=i)\n",
    "env = Monitor(env=env, filename=None)\n",
    "model = DQN('MlpPolicy', env, verbose=1, learning_rate=0.005) # pick your algorithm from stable baselines\n",
    "rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a DummyVecEnv.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/a2c/a2c.py:184: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "env2 = MazeGym(task=i)\n",
    "env2 = Monitor(env2, filename=None)\n",
    "model2 = A2C('MlpPolicy', env2, verbose=1)\n",
    "rewards2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Rewards for DQN: 0\n",
      "Length of Rewards for DQN: 33\n",
      "Length of Rewards for DQN: 66\n",
      "Length of Rewards for DQN: 101\n",
      "Length of Rewards for DQN: 134\n",
      "Length of Rewards for DQN: 168\n",
      "Length of Rewards for DQN: 203\n",
      "Length of Rewards for DQN: 236\n",
      "Length of Rewards for DQN: 269\n",
      "Length of Rewards for DQN: 305\n",
      "Length of Rewards for DQN: 339\n",
      "Length of Rewards for DQN: 372\n",
      "Length of Rewards for DQN: 406\n",
      "Length of Rewards for DQN: 440\n",
      "Length of Rewards for DQN: 474\n",
      "Length of Rewards for DQN: 509\n",
      "Length of Rewards for DQN: 542\n",
      "Length of Rewards for DQN: 575\n",
      "Length of Rewards for DQN: 613\n",
      "Length of Rewards for DQN: 646\n",
      "Length of Rewards for DQN: 679\n",
      "Length of Rewards for DQN: 714\n",
      "Length of Rewards for DQN: 747\n",
      "Length of Rewards for DQN: 780\n",
      "Length of Rewards for DQN: 814\n",
      "Length of Rewards for DQN: 847\n",
      "Length of Rewards for DQN: 880\n",
      "Length of Rewards for DQN: 914\n",
      "Length of Rewards for DQN: 948\n",
      "Length of Rewards for DQN: 981\n",
      "Length of Rewards for DQN: 1015\n",
      "Length of Rewards for DQN: 1048\n",
      "Length of Rewards for DQN: 1084\n",
      "Length of Rewards for DQN: 1118\n",
      "Length of Rewards for DQN: 1151\n",
      "Length of Rewards for DQN: 1184\n",
      "Length of Rewards for DQN: 1219\n",
      "Length of Rewards for DQN: 1253\n",
      "Length of Rewards for DQN: 1288\n",
      "Length of Rewards for DQN: 1322\n",
      "Length of Rewards for DQN: 1356\n",
      "Length of Rewards for DQN: 1389\n",
      "Length of Rewards for DQN: 1427\n",
      "Length of Rewards for DQN: 1462\n",
      "Length of Rewards for DQN: 1495\n",
      "Length of Rewards for DQN: 1529\n",
      "Length of Rewards for DQN: 1562\n",
      "Length of Rewards for DQN: 1597\n",
      "Length of Rewards for DQN: 1632\n",
      "Length of Rewards for DQN: 1665\n",
      "Length of Rewards for DQN: 1699\n",
      "Length of Rewards for DQN: 1733\n",
      "Length of Rewards for DQN: 1766\n",
      "Length of Rewards for DQN: 1801\n",
      "Length of Rewards for DQN: 1835\n",
      "Length of Rewards for DQN: 1869\n",
      "Length of Rewards for DQN: 1903\n",
      "Length of Rewards for DQN: 1937\n",
      "Length of Rewards for DQN: 1970\n",
      "Length of Rewards for A2C: 0\n",
      "---------------------------------\n",
      "| explained_variance | 0.356    |\n",
      "| fps                | 13       |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.39     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.0169   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -33      |\n",
      "| explained_variance | 0.0821   |\n",
      "| fps                | 562      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.39     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 0.0384   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 225      |\n",
      "| ep_reward_mean     | -24.5    |\n",
      "| explained_variance | -6.43    |\n",
      "| fps                | 554      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.39     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 0.196    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 214      |\n",
      "| ep_reward_mean     | -23.1    |\n",
      "| explained_variance | 0.112    |\n",
      "| fps                | 555      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.39     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 0.722    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 225      |\n",
      "| ep_reward_mean     | -24.7    |\n",
      "| explained_variance | 0.035    |\n",
      "| fps                | 628      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.39     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 0.0342   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 223      |\n",
      "| ep_reward_mean     | -24.4    |\n",
      "| explained_variance | -12.9    |\n",
      "| fps                | 611      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 0.254    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 214      |\n",
      "| ep_reward_mean     | -23.6    |\n",
      "| explained_variance | -0.331   |\n",
      "| fps                | 601      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.39     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 4.69     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 206      |\n",
      "| ep_reward_mean     | -22.6    |\n",
      "| explained_variance | -0.0347  |\n",
      "| fps                | 614      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 0.0357   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 217      |\n",
      "| ep_reward_mean     | -23.5    |\n",
      "| explained_variance | 0.409    |\n",
      "| fps                | 623      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 0.0235   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 205      |\n",
      "| ep_reward_mean     | -22.2    |\n",
      "| explained_variance | -4.46    |\n",
      "| fps                | 598      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 57.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 209      |\n",
      "| ep_reward_mean     | -22.6    |\n",
      "| explained_variance | 0.00932  |\n",
      "| fps                | 623      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 0.000186 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 216      |\n",
      "| ep_reward_mean     | -23.3    |\n",
      "| explained_variance | 0.268    |\n",
      "| fps                | 629      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 1.5e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 222      |\n",
      "| ep_reward_mean     | -23.8    |\n",
      "| explained_variance | 0.000336 |\n",
      "| fps                | 635      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 95       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 225      |\n",
      "| ep_reward_mean     | -24      |\n",
      "| explained_variance | -69.4    |\n",
      "| fps                | 656      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 6.23e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 230      |\n",
      "| ep_reward_mean     | -24.5    |\n",
      "| explained_variance | -178     |\n",
      "| fps                | 660      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 0.000453 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 234      |\n",
      "| ep_reward_mean     | -24.8    |\n",
      "| explained_variance | 0.00108  |\n",
      "| fps                | 664      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 95.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 236      |\n",
      "| ep_reward_mean     | -25      |\n",
      "| explained_variance | -0.0109  |\n",
      "| fps                | 679      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 6.39e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 240      |\n",
      "| ep_reward_mean     | -25.3    |\n",
      "| explained_variance | 0.24     |\n",
      "| fps                | 680      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 5.44e-07 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 243       |\n",
      "| ep_reward_mean     | -25.6     |\n",
      "| explained_variance | -0.000772 |\n",
      "| fps                | 682       |\n",
      "| nupdates           | 1800      |\n",
      "| policy_entropy     | 1.37      |\n",
      "| total_timesteps    | 9000      |\n",
      "| value_loss         | 94.1      |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 245      |\n",
      "| ep_reward_mean     | -25.7    |\n",
      "| explained_variance | 0.0419   |\n",
      "| fps                | 695      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 7.67e-07 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 248       |\n",
      "| ep_reward_mean     | -26       |\n",
      "| explained_variance | -2.38e+03 |\n",
      "| fps                | 695       |\n",
      "| nupdates           | 2000      |\n",
      "| policy_entropy     | 1.32      |\n",
      "| total_timesteps    | 10000     |\n",
      "| value_loss         | 2.85e-05  |\n",
      "----------------------------------\n",
      "Length of Rewards for A2C: 40\n",
      "---------------------------------\n",
      "| ep_len_mean        | 248      |\n",
      "| ep_reward_mean     | -26      |\n",
      "| explained_variance | -696     |\n",
      "| fps                | 1236     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 9.27e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 250       |\n",
      "| ep_reward_mean     | -26.2     |\n",
      "| explained_variance | -0.000506 |\n",
      "| fps                | 696       |\n",
      "| nupdates           | 100       |\n",
      "| policy_entropy     | 1.36      |\n",
      "| total_timesteps    | 500       |\n",
      "| value_loss         | 95.2      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 251      |\n",
      "| ep_reward_mean     | -26.3    |\n",
      "| explained_variance | 5.96e-07 |\n",
      "| fps                | 807      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 2.95e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 253      |\n",
      "| ep_reward_mean     | -26.4    |\n",
      "| explained_variance | 4.17e-07 |\n",
      "| fps                | 775      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 4.84e-07 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 255       |\n",
      "| ep_reward_mean     | -26.6     |\n",
      "| explained_variance | -1.54e-05 |\n",
      "| fps                | 761       |\n",
      "| nupdates           | 400       |\n",
      "| policy_entropy     | 1.36      |\n",
      "| total_timesteps    | 2000      |\n",
      "| value_loss         | 94.5      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 256       |\n",
      "| ep_reward_mean     | -26.7     |\n",
      "| explained_variance | -0.000139 |\n",
      "| fps                | 803       |\n",
      "| nupdates           | 500       |\n",
      "| policy_entropy     | 1.37      |\n",
      "| total_timesteps    | 2500      |\n",
      "| value_loss         | 2.07e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 258      |\n",
      "| ep_reward_mean     | -26.9    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 790      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 9.41e-07 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 260       |\n",
      "| ep_reward_mean     | -27       |\n",
      "| explained_variance | -1.54e-05 |\n",
      "| fps                | 778       |\n",
      "| nupdates           | 700       |\n",
      "| policy_entropy     | 1.36      |\n",
      "| total_timesteps    | 3500      |\n",
      "| value_loss         | 98.3      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 260      |\n",
      "| ep_reward_mean     | -27.1    |\n",
      "| explained_variance | -0.00151 |\n",
      "| fps                | 794      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 6.48e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 262      |\n",
      "| ep_reward_mean     | -27.2    |\n",
      "| explained_variance | 0.000813 |\n",
      "| fps                | 781      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 9.66e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 263       |\n",
      "| ep_reward_mean     | -27.3     |\n",
      "| explained_variance | -1.94e-05 |\n",
      "| fps                | 772       |\n",
      "| nupdates           | 1000      |\n",
      "| policy_entropy     | 1.38      |\n",
      "| total_timesteps    | 5000      |\n",
      "| value_loss         | 96.2      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 264       |\n",
      "| ep_reward_mean     | -27.4     |\n",
      "| explained_variance | -1.12e+04 |\n",
      "| fps                | 791       |\n",
      "| nupdates           | 1100      |\n",
      "| policy_entropy     | 1.3       |\n",
      "| total_timesteps    | 5500      |\n",
      "| value_loss         | 0.000144  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 265      |\n",
      "| ep_reward_mean     | -27.5    |\n",
      "| explained_variance | -0.106   |\n",
      "| fps                | 785      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 5.05e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 266      |\n",
      "| ep_reward_mean     | -27.6    |\n",
      "| explained_variance | 0.232    |\n",
      "| fps                | 781      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.14     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 98.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 267      |\n",
      "| ep_reward_mean     | -27.6    |\n",
      "| explained_variance | -446     |\n",
      "| fps                | 793      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 0.000551 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 264      |\n",
      "| ep_reward_mean     | -27.3    |\n",
      "| explained_variance | -2.51    |\n",
      "| fps                | 771      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 5.87e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 250      |\n",
      "| ep_reward_mean     | -25.9    |\n",
      "| explained_variance | -0.0486  |\n",
      "| fps                | 711      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 106      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 251      |\n",
      "| ep_reward_mean     | -25.9    |\n",
      "| explained_variance | -0.0603  |\n",
      "| fps                | 721      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 1e-06    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 249      |\n",
      "| ep_reward_mean     | -25.8    |\n",
      "| explained_variance | -0.00189 |\n",
      "| fps                | 708      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 4.61e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 250       |\n",
      "| ep_reward_mean     | -25.9     |\n",
      "| explained_variance | -1.94e-05 |\n",
      "| fps                | 709       |\n",
      "| nupdates           | 1900      |\n",
      "| policy_entropy     | 1.33      |\n",
      "| total_timesteps    | 9500      |\n",
      "| value_loss         | 97.1      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 251      |\n",
      "| ep_reward_mean     | -26      |\n",
      "| explained_variance | 0.0214   |\n",
      "| fps                | 717      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 2.25e-07 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 79\n",
      "---------------------------------\n",
      "| ep_len_mean        | 251      |\n",
      "| ep_reward_mean     | -26      |\n",
      "| explained_variance | -0.00866 |\n",
      "| fps                | 1545     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 1.97e-07 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| ep_len_mean        | 252       |\n",
      "| ep_reward_mean     | -26.1     |\n",
      "| explained_variance | -5.91e-05 |\n",
      "| fps                | 716       |\n",
      "| nupdates           | 100       |\n",
      "| policy_entropy     | 1.37      |\n",
      "| total_timesteps    | 500       |\n",
      "| value_loss         | 5.25e-06  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 253       |\n",
      "| ep_reward_mean     | -26.2     |\n",
      "| explained_variance | -4.27e-05 |\n",
      "| fps                | 724       |\n",
      "| nupdates           | 200       |\n",
      "| policy_entropy     | 1.36      |\n",
      "| total_timesteps    | 1000      |\n",
      "| value_loss         | 95        |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 254      |\n",
      "| ep_reward_mean     | -26.2    |\n",
      "| explained_variance | -0.119   |\n",
      "| fps                | 795      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 7.1e-10  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 255      |\n",
      "| ep_reward_mean     | -26.3    |\n",
      "| explained_variance | -95.8    |\n",
      "| fps                | 776      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 0.000228 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 256       |\n",
      "| ep_reward_mean     | -26.4     |\n",
      "| explained_variance | -7.62e-05 |\n",
      "| fps                | 764       |\n",
      "| nupdates           | 500       |\n",
      "| policy_entropy     | 1.32      |\n",
      "| total_timesteps    | 2500      |\n",
      "| value_loss         | 93.5      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 256      |\n",
      "| ep_reward_mean     | -26.5    |\n",
      "| explained_variance | -237     |\n",
      "| fps                | 799      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 0.000281 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 257      |\n",
      "| ep_reward_mean     | -26.6    |\n",
      "| explained_variance | -200     |\n",
      "| fps                | 777      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 2.72e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 258      |\n",
      "| ep_reward_mean     | -26.7    |\n",
      "| explained_variance | -0.131   |\n",
      "| fps                | 770      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 93.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 259      |\n",
      "| ep_reward_mean     | -26.7    |\n",
      "| explained_variance | -2.02    |\n",
      "| fps                | 790      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 1.23e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 259      |\n",
      "| ep_reward_mean     | -26.8    |\n",
      "| explained_variance | -111     |\n",
      "| fps                | 780      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 2.64e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 260      |\n",
      "| ep_reward_mean     | -26.8    |\n",
      "| explained_variance | 0.000605 |\n",
      "| fps                | 777      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 261      |\n",
      "| ep_reward_mean     | -26.9    |\n",
      "| explained_variance | 0.00439  |\n",
      "| fps                | 793      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 6.05e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 261      |\n",
      "| ep_reward_mean     | -26.9    |\n",
      "| explained_variance | -0.00251 |\n",
      "| fps                | 784      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 3.19e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 261      |\n",
      "| ep_reward_mean     | -26.9    |\n",
      "| explained_variance | 2.98e-07 |\n",
      "| fps                | 780      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.19     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 264      |\n",
      "| ep_reward_mean     | -27.2    |\n",
      "| explained_variance | -9       |\n",
      "| fps                | 792      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 0.00249  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 266      |\n",
      "| ep_reward_mean     | -27.4    |\n",
      "| explained_variance | 8.27e-05 |\n",
      "| fps                | 788      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 0.0319   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 267      |\n",
      "| ep_reward_mean     | -27.4    |\n",
      "| explained_variance | 7.33e-05 |\n",
      "| fps                | 783      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 97.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 267      |\n",
      "| ep_reward_mean     | -27.3    |\n",
      "| explained_variance | 0.000267 |\n",
      "| fps                | 795      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 2.27e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 269      |\n",
      "| ep_reward_mean     | -27.6    |\n",
      "| explained_variance | 1.07e-05 |\n",
      "| fps                | 790      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 8.5e-06  |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 272       |\n",
      "| ep_reward_mean     | -27.8     |\n",
      "| explained_variance | -6.22e-05 |\n",
      "| fps                | 787       |\n",
      "| nupdates           | 2000      |\n",
      "| policy_entropy     | 1.37      |\n",
      "| total_timesteps    | 10000     |\n",
      "| value_loss         | 94.9      |\n",
      "----------------------------------\n",
      "Length of Rewards for A2C: 113\n",
      "---------------------------------\n",
      "| ep_len_mean        | 272      |\n",
      "| ep_reward_mean     | -27.8    |\n",
      "| explained_variance | -0.414   |\n",
      "| fps                | 926      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000849 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 273      |\n",
      "| ep_reward_mean     | -27.9    |\n",
      "| explained_variance | -0.00458 |\n",
      "| fps                | 1033     |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 7.14e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 276      |\n",
      "| ep_reward_mean     | -28.2    |\n",
      "| explained_variance | 0.493    |\n",
      "| fps                | 855      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 2.75e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 276      |\n",
      "| ep_reward_mean     | -28.2    |\n",
      "| explained_variance | 2.77e-05 |\n",
      "| fps                | 800      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 95.1     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 277      |\n",
      "| ep_reward_mean     | -28.3    |\n",
      "| explained_variance | -0.188   |\n",
      "| fps                | 851      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 5.53e-09 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | 0.00866  |\n",
      "| fps                | 826      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.39     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 2.87e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | 0.0269   |\n",
      "| fps                | 808      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | -30.7    |\n",
      "| fps                | 831      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 1.18e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | 0.00568  |\n",
      "| fps                | 814      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 5.01e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | 4.17e-07 |\n",
      "| fps                | 805      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 94.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | -0.00264 |\n",
      "| fps                | 820      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 1.45e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | -19.5    |\n",
      "| fps                | 811      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 3.9e-05  |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 282       |\n",
      "| ep_reward_mean     | -28.7     |\n",
      "| explained_variance | -7.63e-06 |\n",
      "| fps                | 804       |\n",
      "| nupdates           | 1200      |\n",
      "| policy_entropy     | 1.32      |\n",
      "| total_timesteps    | 6000      |\n",
      "| value_loss         | 94.3      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 282       |\n",
      "| ep_reward_mean     | -28.7     |\n",
      "| explained_variance | -2.56e+04 |\n",
      "| fps                | 818       |\n",
      "| nupdates           | 1300      |\n",
      "| policy_entropy     | 1.32      |\n",
      "| total_timesteps    | 6500      |\n",
      "| value_loss         | 7.2e-05   |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | 0.0023   |\n",
      "| fps                | 809      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 4.93e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 282       |\n",
      "| ep_reward_mean     | -28.7     |\n",
      "| explained_variance | -3.58e-07 |\n",
      "| fps                | 803       |\n",
      "| nupdates           | 1500      |\n",
      "| policy_entropy     | 1.38      |\n",
      "| total_timesteps    | 7500      |\n",
      "| value_loss         | 94.8      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | -0.00937 |\n",
      "| fps                | 815      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 2.32e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | 0.00693  |\n",
      "| fps                | 810      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 3.02e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | -4.3e-05 |\n",
      "| fps                | 806      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | -0.00466 |\n",
      "| fps                | 808      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 6.96e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | -0.0149  |\n",
      "| fps                | 802      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 0.000308 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 146\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | -317     |\n",
      "| fps                | 1494     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 4.12e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | 7.69e-05 |\n",
      "| fps                | 711      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.19     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 282       |\n",
      "| ep_reward_mean     | -28.7     |\n",
      "| explained_variance | -0.000875 |\n",
      "| fps                | 831       |\n",
      "| nupdates           | 200       |\n",
      "| policy_entropy     | 1.26      |\n",
      "| total_timesteps    | 1000      |\n",
      "| value_loss         | 2.65e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | -1       |\n",
      "| fps                | 790      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 2.47e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | 4.54e-05 |\n",
      "| fps                | 763      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | 0.0701   |\n",
      "| fps                | 807      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 2.72e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | 0.0465   |\n",
      "| fps                | 787      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 5.51e-07 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | 3.1e-06  |\n",
      "| fps                | 776      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.16     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 90.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | 0.0544   |\n",
      "| fps                | 794      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 4.06e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | -228     |\n",
      "| fps                | 782      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 0.000779 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 282       |\n",
      "| ep_reward_mean     | -28.7     |\n",
      "| explained_variance | -3.49e-05 |\n",
      "| fps                | 773       |\n",
      "| nupdates           | 1000      |\n",
      "| policy_entropy     | 1.35      |\n",
      "| total_timesteps    | 5000      |\n",
      "| value_loss         | 96        |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | -1.36    |\n",
      "| fps                | 792      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 4.69e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -29      |\n",
      "| explained_variance | 4.77e-07 |\n",
      "| fps                | 786      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 1.64e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.3    |\n",
      "| explained_variance | 2.98e-07 |\n",
      "| fps                | 781      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.19     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 97.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.6    |\n",
      "| explained_variance | 0.000222 |\n",
      "| fps                | 795      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 3.37e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -0.0259  |\n",
      "| fps                | 789      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 2.7e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.2    |\n",
      "| explained_variance | -0.00441 |\n",
      "| fps                | 786      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 94.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.2    |\n",
      "| explained_variance | 0.107    |\n",
      "| fps                | 798      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 1.22e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.5    |\n",
      "| explained_variance | -340     |\n",
      "| fps                | 794      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 0.0582   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.5    |\n",
      "| explained_variance | 1.77e-05 |\n",
      "| fps                | 791      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.04     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 95.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.00686 |\n",
      "| fps                | 801      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.12     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 7.08e-07 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 179\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.00319  |\n",
      "| fps                | 1525     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.13     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 6.31e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.00033 |\n",
      "| fps                | 716      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.13     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 3.38e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -3.58e-06 |\n",
      "| fps                | 719       |\n",
      "| nupdates           | 200       |\n",
      "| policy_entropy     | 1.29      |\n",
      "| total_timesteps    | 1000      |\n",
      "| value_loss         | 94.7      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.00945  |\n",
      "| fps                | 802      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 6.49e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.00371 |\n",
      "| fps                | 780      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 2.11e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -3.58e-06 |\n",
      "| fps                | 771       |\n",
      "| nupdates           | 500       |\n",
      "| policy_entropy     | 1.36      |\n",
      "| total_timesteps    | 2500      |\n",
      "| value_loss         | 94        |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 805      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 1.37e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.00167  |\n",
      "| fps                | 791      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 5.16e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0154  |\n",
      "| fps                | 786      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.14     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 95       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 2.21e-05 |\n",
      "| fps                | 810      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 1.15e-06 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.124    |\n",
      "| fps                | 801      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 5.79e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0345  |\n",
      "| fps                | 792      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 94.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | 0.00748  |\n",
      "| fps                | 785      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 5.83e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -0.00259 |\n",
      "| fps                | 782      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 3.88e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 297       |\n",
      "| ep_reward_mean     | -30.1     |\n",
      "| explained_variance | -0.000237 |\n",
      "| fps                | 778       |\n",
      "| nupdates           | 1400      |\n",
      "| policy_entropy     | 1.34      |\n",
      "| total_timesteps    | 7000      |\n",
      "| value_loss         | 94.6      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -0.00172 |\n",
      "| fps                | 791      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 5.52e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | 0.00362  |\n",
      "| fps                | 788      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 7e-06    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 786      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 95.5     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 297       |\n",
      "| ep_reward_mean     | -30.1     |\n",
      "| explained_variance | -0.000633 |\n",
      "| fps                | 796       |\n",
      "| nupdates           | 1800      |\n",
      "| policy_entropy     | 1.29      |\n",
      "| total_timesteps    | 9000      |\n",
      "| value_loss         | 4.17e-06  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -0.00178 |\n",
      "| fps                | 793      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 4.59e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | 0.00565  |\n",
      "| fps                | 789      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 93.8     |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 214\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -10.4    |\n",
      "| fps                | 1349     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000231 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 297       |\n",
      "| ep_reward_mean     | -30.1     |\n",
      "| explained_variance | -0.000728 |\n",
      "| fps                | 1012      |\n",
      "| nupdates           | 100       |\n",
      "| policy_entropy     | 1.38      |\n",
      "| total_timesteps    | 500       |\n",
      "| value_loss         | 3.87e-08  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | 0.00284  |\n",
      "| fps                | 848      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 1.81e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | 4.11e-06 |\n",
      "| fps                | 813      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 94.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -0.0216  |\n",
      "| fps                | 864      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 9.2e-08  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | 0.00184  |\n",
      "| fps                | 833      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 4.32e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 297       |\n",
      "| ep_reward_mean     | -30.1     |\n",
      "| explained_variance | -2.03e-06 |\n",
      "| fps                | 813       |\n",
      "| nupdates           | 600       |\n",
      "| policy_entropy     | 1.37      |\n",
      "| total_timesteps    | 3000      |\n",
      "| value_loss         | 94.1      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 297       |\n",
      "| ep_reward_mean     | -30.1     |\n",
      "| explained_variance | -0.000672 |\n",
      "| fps                | 835       |\n",
      "| nupdates           | 700       |\n",
      "| policy_entropy     | 1.33      |\n",
      "| total_timesteps    | 3500      |\n",
      "| value_loss         | 2.34e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -0.00316 |\n",
      "| fps                | 818      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 1.46e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 297       |\n",
      "| ep_reward_mean     | -30.1     |\n",
      "| explained_variance | -2.11e-05 |\n",
      "| fps                | 810       |\n",
      "| nupdates           | 900       |\n",
      "| policy_entropy     | 1.35      |\n",
      "| total_timesteps    | 4500      |\n",
      "| value_loss         | 91        |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | 0.0831   |\n",
      "| fps                | 828      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 8.79e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.4    |\n",
      "| explained_variance | -124     |\n",
      "| fps                | 772      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 0.00191  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -28.8    |\n",
      "| explained_variance | 0.0346   |\n",
      "| fps                | 729      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 101      |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 276      |\n",
      "| ep_reward_mean     | -27.9    |\n",
      "| explained_variance | -3.25    |\n",
      "| fps                | 695      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.39     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 2.09e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 268      |\n",
      "| ep_reward_mean     | -27.1    |\n",
      "| explained_variance | -2.6e+03 |\n",
      "| fps                | 656      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 0.00112  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 267      |\n",
      "| ep_reward_mean     | -27      |\n",
      "| explained_variance | -0.0956  |\n",
      "| fps                | 657      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 92.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 264      |\n",
      "| ep_reward_mean     | -26.7    |\n",
      "| explained_variance | -19.8    |\n",
      "| fps                | 660      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 1.5e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 261      |\n",
      "| ep_reward_mean     | -26.4    |\n",
      "| explained_variance | -184     |\n",
      "| fps                | 651      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 0.00022  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 261      |\n",
      "| ep_reward_mean     | -26.4    |\n",
      "| explained_variance | 0.295    |\n",
      "| fps                | 653      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 95.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 258      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | -9.24    |\n",
      "| fps                | 656      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 5.98e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 258      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | -0.0116  |\n",
      "| fps                | 658      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 2.26e-05 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 260\n",
      "---------------------------------\n",
      "| ep_len_mean        | 258      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | 0.0262   |\n",
      "| fps                | 1551     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 2.01e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 258      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | 0.00969  |\n",
      "| fps                | 721      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 93       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 258      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | 0.0174   |\n",
      "| fps                | 848      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 3.37e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 258      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | -0.396   |\n",
      "| fps                | 801      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 5.89e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 258      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | -0.0121  |\n",
      "| fps                | 775      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 258      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | -171     |\n",
      "| fps                | 806      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 0.000159 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 258      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | -144     |\n",
      "| fps                | 788      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 0.00023  |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 258       |\n",
      "| ep_reward_mean     | -26.1     |\n",
      "| explained_variance | -3.58e-06 |\n",
      "| fps                | 778       |\n",
      "| nupdates           | 700       |\n",
      "| policy_entropy     | 1.38      |\n",
      "| total_timesteps    | 3500      |\n",
      "| value_loss         | 94.6      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 258      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | -1.02    |\n",
      "| fps                | 800      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 1.75e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 258      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | -0.0123  |\n",
      "| fps                | 789      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 9.3e-06  |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 258       |\n",
      "| ep_reward_mean     | -26.1     |\n",
      "| explained_variance | -0.000316 |\n",
      "| fps                | 779       |\n",
      "| nupdates           | 1000      |\n",
      "| policy_entropy     | 1.34      |\n",
      "| total_timesteps    | 5000      |\n",
      "| value_loss         | 95.5      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 258       |\n",
      "| ep_reward_mean     | -26.1     |\n",
      "| explained_variance | -7.81e+03 |\n",
      "| fps                | 793       |\n",
      "| nupdates           | 1100      |\n",
      "| policy_entropy     | 1.32      |\n",
      "| total_timesteps    | 5500      |\n",
      "| value_loss         | 0.000389  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 258      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | -98      |\n",
      "| fps                | 783      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 9.78e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 258      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | 0.00119  |\n",
      "| fps                | 776      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 255      |\n",
      "| ep_reward_mean     | -25.8    |\n",
      "| explained_variance | 0.00385  |\n",
      "| fps                | 770      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 2.58e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 255      |\n",
      "| ep_reward_mean     | -25.8    |\n",
      "| explained_variance | -721     |\n",
      "| fps                | 767      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 3.37e-05 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 255      |\n",
      "| ep_reward_mean     | -25.8    |\n",
      "| explained_variance | 0.000184 |\n",
      "| fps                | 764      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 255      |\n",
      "| ep_reward_mean     | -25.8    |\n",
      "| explained_variance | -3.21    |\n",
      "| fps                | 775      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 4.95e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 255      |\n",
      "| ep_reward_mean     | -25.8    |\n",
      "| explained_variance | -354     |\n",
      "| fps                | 771      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 0.000398 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 255      |\n",
      "| ep_reward_mean     | -25.8    |\n",
      "| explained_variance | 8.4e-06  |\n",
      "| fps                | 768      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 93.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 255      |\n",
      "| ep_reward_mean     | -25.8    |\n",
      "| explained_variance | 0.152    |\n",
      "| fps                | 776      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 7.42e-06 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 294\n",
      "---------------------------------\n",
      "| ep_len_mean        | 255      |\n",
      "| ep_reward_mean     | -25.8    |\n",
      "| explained_variance | 0.108    |\n",
      "| fps                | 1301     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 6.82e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 255      |\n",
      "| ep_reward_mean     | -25.8    |\n",
      "| explained_variance | -128     |\n",
      "| fps                | 668      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 0.000176 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 255      |\n",
      "| ep_reward_mean     | -25.8    |\n",
      "| explained_variance | -3.1e-06 |\n",
      "| fps                | 683      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 255      |\n",
      "| ep_reward_mean     | -25.9    |\n",
      "| explained_variance | -12      |\n",
      "| fps                | 756      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 6.44e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 258      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | -5.3e-05 |\n",
      "| fps                | 739      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 1.73e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 258      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | -0.0116  |\n",
      "| fps                | 728      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 94.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 258      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | -13.5    |\n",
      "| fps                | 759      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 0.000119 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 258      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | 0.429    |\n",
      "| fps                | 750      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 1.04e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 258      |\n",
      "| ep_reward_mean     | -26.2    |\n",
      "| explained_variance | -0.00226 |\n",
      "| fps                | 747      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 92.4     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 258       |\n",
      "| ep_reward_mean     | -26.2     |\n",
      "| explained_variance | -1.28e+03 |\n",
      "| fps                | 772       |\n",
      "| nupdates           | 900       |\n",
      "| policy_entropy     | 1.24      |\n",
      "| total_timesteps    | 4500      |\n",
      "| value_loss         | 0.00117   |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 258      |\n",
      "| ep_reward_mean     | -26.2    |\n",
      "| explained_variance | -2.21    |\n",
      "| fps                | 767      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 3.15e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 258      |\n",
      "| ep_reward_mean     | -26.2    |\n",
      "| explained_variance | -0.00843 |\n",
      "| fps                | 764      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 95.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 258      |\n",
      "| ep_reward_mean     | -26.2    |\n",
      "| explained_variance | 0.0156   |\n",
      "| fps                | 778      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 1.83e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 255      |\n",
      "| ep_reward_mean     | -25.9    |\n",
      "| explained_variance | -2.83    |\n",
      "| fps                | 756      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 9.29e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 255      |\n",
      "| ep_reward_mean     | -25.9    |\n",
      "| explained_variance | -0.00276 |\n",
      "| fps                | 755      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 95       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 255      |\n",
      "| ep_reward_mean     | -25.9    |\n",
      "| explained_variance | -11.4    |\n",
      "| fps                | 769      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.18     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 7.33e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 255      |\n",
      "| ep_reward_mean     | -25.9    |\n",
      "| explained_variance | -1e-05   |\n",
      "| fps                | 765      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 1e-05    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 255      |\n",
      "| ep_reward_mean     | -25.9    |\n",
      "| explained_variance | -0.0148  |\n",
      "| fps                | 764      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 98.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 255      |\n",
      "| ep_reward_mean     | -25.9    |\n",
      "| explained_variance | -1.88    |\n",
      "| fps                | 774      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 0.00222  |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 255      |\n",
      "| ep_reward_mean     | -25.9    |\n",
      "| explained_variance | -10.4    |\n",
      "| fps                | 771      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 1.76e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 255      |\n",
      "| ep_reward_mean     | -25.9    |\n",
      "| explained_variance | -0.00017 |\n",
      "| fps                | 769      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 329\n",
      "---------------------------------\n",
      "| ep_len_mean        | 255      |\n",
      "| ep_reward_mean     | -25.9    |\n",
      "| explained_variance | -45.8    |\n",
      "| fps                | 1391     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000421 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 255      |\n",
      "| ep_reward_mean     | -25.9    |\n",
      "| explained_variance | -389     |\n",
      "| fps                | 1056     |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 0.00162  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 258      |\n",
      "| ep_reward_mean     | -26.2    |\n",
      "| explained_variance | 0.615    |\n",
      "| fps                | 873      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 7.57e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 261      |\n",
      "| ep_reward_mean     | -26.5    |\n",
      "| explained_variance | 0.0331   |\n",
      "| fps                | 822      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 95.5     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 261       |\n",
      "| ep_reward_mean     | -26.5     |\n",
      "| explained_variance | -1.43e+04 |\n",
      "| fps                | 865       |\n",
      "| nupdates           | 400       |\n",
      "| policy_entropy     | 1.28      |\n",
      "| total_timesteps    | 2000      |\n",
      "| value_loss         | 0.000136  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 265      |\n",
      "| ep_reward_mean     | -26.9    |\n",
      "| explained_variance | -124     |\n",
      "| fps                | 834      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 0.000104 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 270      |\n",
      "| ep_reward_mean     | -27.4    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 814      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 93.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 271      |\n",
      "| ep_reward_mean     | -27.5    |\n",
      "| explained_variance | -40.4    |\n",
      "| fps                | 840      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 1.61e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 276      |\n",
      "| ep_reward_mean     | -28      |\n",
      "| explained_variance | -685     |\n",
      "| fps                | 828      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 0.000662 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 277       |\n",
      "| ep_reward_mean     | -28.1     |\n",
      "| explained_variance | -1.79e-06 |\n",
      "| fps                | 814       |\n",
      "| nupdates           | 900       |\n",
      "| policy_entropy     | 1.33      |\n",
      "| total_timesteps    | 4500      |\n",
      "| value_loss         | 95.6      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 279      |\n",
      "| ep_reward_mean     | -28.4    |\n",
      "| explained_variance | -294     |\n",
      "| fps                | 831      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 2.21e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 284      |\n",
      "| ep_reward_mean     | -28.8    |\n",
      "| explained_variance | -6.34    |\n",
      "| fps                | 818      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 7.8e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -28.9    |\n",
      "| explained_variance | 0.0111   |\n",
      "| fps                | 812      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 95.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -28.9    |\n",
      "| explained_variance | -0.00193 |\n",
      "| fps                | 828      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 1.76e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 289      |\n",
      "| ep_reward_mean     | -29.3    |\n",
      "| explained_variance | -135     |\n",
      "| fps                | 819      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 0.000114 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | 0.0584   |\n",
      "| fps                | 813      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 95.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -57.3    |\n",
      "| fps                | 825      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 6.52e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 293      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | -0.00162 |\n",
      "| fps                | 819      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 2.54e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 294       |\n",
      "| ep_reward_mean     | -29.8     |\n",
      "| explained_variance | -2.12e-05 |\n",
      "| fps                | 815       |\n",
      "| nupdates           | 1800      |\n",
      "| policy_entropy     | 1.37      |\n",
      "| total_timesteps    | 9000      |\n",
      "| value_loss         | 93.4      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 294       |\n",
      "| ep_reward_mean     | -29.8     |\n",
      "| explained_variance | -6.94e+03 |\n",
      "| fps                | 824       |\n",
      "| nupdates           | 1900      |\n",
      "| policy_entropy     | 1.36      |\n",
      "| total_timesteps    | 9500      |\n",
      "| value_loss         | 2.12e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | -91.7    |\n",
      "| fps                | 819      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 0.000188 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 362\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | -22.4    |\n",
      "| fps                | 1539     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 1.27e-05 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| ep_len_mean        | 294       |\n",
      "| ep_reward_mean     | -29.8     |\n",
      "| explained_variance | -2.87e-05 |\n",
      "| fps                | 728       |\n",
      "| nupdates           | 100       |\n",
      "| policy_entropy     | 1.33      |\n",
      "| total_timesteps    | 500       |\n",
      "| value_loss         | 93.1      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | -12.4    |\n",
      "| fps                | 853      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 4.59e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | -36.5    |\n",
      "| fps                | 804      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 8.44e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | 0.000124 |\n",
      "| fps                | 727      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 93.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -2.43    |\n",
      "| fps                | 765      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 2.38e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -0.0369  |\n",
      "| fps                | 757      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 1.88e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | 0.00491  |\n",
      "| fps                | 752      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 96.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 290      |\n",
      "| ep_reward_mean     | -29.4    |\n",
      "| explained_variance | -29.6    |\n",
      "| fps                | 750      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 0.00469  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.2    |\n",
      "| explained_variance | 0.28     |\n",
      "| fps                | 747      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 5.62e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -28.9    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 722      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 95.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 286      |\n",
      "| ep_reward_mean     | -29      |\n",
      "| explained_variance | -0.00584 |\n",
      "| fps                | 740      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 1.3e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.2    |\n",
      "| explained_variance | -0.0669  |\n",
      "| fps                | 738      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 2.22e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.2    |\n",
      "| explained_variance | -0.0255  |\n",
      "| fps                | 738      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 288       |\n",
      "| ep_reward_mean     | -29.2     |\n",
      "| explained_variance | -2.83e+03 |\n",
      "| fps                | 753       |\n",
      "| nupdates           | 1400      |\n",
      "| policy_entropy     | 1.34      |\n",
      "| total_timesteps    | 7000      |\n",
      "| value_loss         | 0.000157  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -28.9    |\n",
      "| explained_variance | -59.9    |\n",
      "| fps                | 737      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 4.63e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -28.9    |\n",
      "| explained_variance | 0.00275  |\n",
      "| fps                | 738      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 96.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -28.9    |\n",
      "| explained_variance | -0.00117 |\n",
      "| fps                | 751      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 2.79e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -28.9    |\n",
      "| explained_variance | -17.2    |\n",
      "| fps                | 750      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 0.000111 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -28.9    |\n",
      "| explained_variance | -0.00456 |\n",
      "| fps                | 748      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 93.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -28.9    |\n",
      "| explained_variance | -28.5    |\n",
      "| fps                | 757      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 2.93e-05 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 399\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -28.9    |\n",
      "| explained_variance | -147     |\n",
      "| fps                | 903      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000122 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -28.9    |\n",
      "| explained_variance | 0.0076   |\n",
      "| fps                | 671      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 6.19e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -28.9    |\n",
      "| explained_variance | -0.0466  |\n",
      "| fps                | 686      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -28.9    |\n",
      "| explained_variance | -275     |\n",
      "| fps                | 760      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 1.72e-05 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -28.9    |\n",
      "| explained_variance | -4.24    |\n",
      "| fps                | 753      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 5.34e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -28.9    |\n",
      "| explained_variance | 7.75e-07 |\n",
      "| fps                | 753      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 93.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -28.9    |\n",
      "| explained_variance | -1.62    |\n",
      "| fps                | 790      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 3.35e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -28.9    |\n",
      "| explained_variance | -8.12    |\n",
      "| fps                | 780      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 0.000271 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -28.9    |\n",
      "| explained_variance | 0.00429  |\n",
      "| fps                | 773      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -28.8    |\n",
      "| explained_variance | -74.5    |\n",
      "| fps                | 793      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 0.000214 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 286      |\n",
      "| ep_reward_mean     | -29      |\n",
      "| explained_variance | -6.71    |\n",
      "| fps                | 782      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 5.69e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.1    |\n",
      "| explained_variance | 0.0195   |\n",
      "| fps                | 774      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 94.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.1    |\n",
      "| explained_variance | 9.42e-06 |\n",
      "| fps                | 787      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 2.63e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.1    |\n",
      "| explained_variance | -60      |\n",
      "| fps                | 779      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 2.54e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.1    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 773      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 93.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.1    |\n",
      "| explained_variance | 2.38e-07 |\n",
      "| fps                | 783      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 5.54e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.1    |\n",
      "| explained_variance | -25.2    |\n",
      "| fps                | 777      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.16     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 0.000178 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.1    |\n",
      "| explained_variance | -0.00151 |\n",
      "| fps                | 772      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 288       |\n",
      "| ep_reward_mean     | -29.1     |\n",
      "| explained_variance | -2.75e+03 |\n",
      "| fps                | 780       |\n",
      "| nupdates           | 1800      |\n",
      "| policy_entropy     | 1.36      |\n",
      "| total_timesteps    | 9000      |\n",
      "| value_loss         | 0.000311  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.1    |\n",
      "| explained_variance | -115     |\n",
      "| fps                | 775      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 1.14e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.1    |\n",
      "| explained_variance | 0.0471   |\n",
      "| fps                | 771      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 433\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.1    |\n",
      "| explained_variance | -31      |\n",
      "| fps                | 735      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000205 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.1    |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 970      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.13     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 4.3e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.1    |\n",
      "| explained_variance | 0.00142  |\n",
      "| fps                | 794      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 3.16e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.1    |\n",
      "| explained_variance | 2.98e-07 |\n",
      "| fps                | 758      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.1    |\n",
      "| explained_variance | -0.00663 |\n",
      "| fps                | 800      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 1.59e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.1    |\n",
      "| explained_variance | -125     |\n",
      "| fps                | 774      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 1.66e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.1    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 762      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 93.8     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.1    |\n",
      "| explained_variance | 1.96e-05 |\n",
      "| fps                | 792      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 8.21e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.1    |\n",
      "| explained_variance | -78.8    |\n",
      "| fps                | 779      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 0.000128 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.1    |\n",
      "| explained_variance | 0.000167 |\n",
      "| fps                | 768      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.19     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.1    |\n",
      "| explained_variance | -0.00645 |\n",
      "| fps                | 788      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 9.96e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.1    |\n",
      "| explained_variance | -1.2e+05 |\n",
      "| fps                | 781      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 6.55e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 288       |\n",
      "| ep_reward_mean     | -29.1     |\n",
      "| explained_variance | -5.72e-06 |\n",
      "| fps                | 773       |\n",
      "| nupdates           | 1200      |\n",
      "| policy_entropy     | 1.34      |\n",
      "| total_timesteps    | 6000      |\n",
      "| value_loss         | 95.5      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.1    |\n",
      "| explained_variance | 0.000185 |\n",
      "| fps                | 786      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 1.2e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.1    |\n",
      "| explained_variance | -96.6    |\n",
      "| fps                | 778      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 6.24e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.1    |\n",
      "| explained_variance | -0.0299  |\n",
      "| fps                | 771      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 95.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.1    |\n",
      "| explained_variance | -3.56    |\n",
      "| fps                | 782      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 4.63e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -28.8    |\n",
      "| explained_variance | -5.03    |\n",
      "| fps                | 763      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 1.09e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 285       |\n",
      "| ep_reward_mean     | -28.8     |\n",
      "| explained_variance | -0.000344 |\n",
      "| fps                | 759       |\n",
      "| nupdates           | 1800      |\n",
      "| policy_entropy     | 1.2       |\n",
      "| total_timesteps    | 9000      |\n",
      "| value_loss         | 93.8      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -28.8    |\n",
      "| explained_variance | -2.49    |\n",
      "| fps                | 767      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 3.71e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -28.8    |\n",
      "| explained_variance | -1.2     |\n",
      "| fps                | 763      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 1.86e-07 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 467\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -28.8    |\n",
      "| explained_variance | -0.653   |\n",
      "| fps                | 1362     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 6.17e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -28.9    |\n",
      "| explained_variance | 0.187    |\n",
      "| fps                | 546      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 96.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -28.9    |\n",
      "| explained_variance | 1.47e-05 |\n",
      "| fps                | 703      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 6.6e-07  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -28.9    |\n",
      "| explained_variance | -361     |\n",
      "| fps                | 707      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 0.00013  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -28.9    |\n",
      "| explained_variance | -0.00464 |\n",
      "| fps                | 716      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 95.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -28.9    |\n",
      "| explained_variance | 0.00314  |\n",
      "| fps                | 763      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 1.25e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 288       |\n",
      "| ep_reward_mean     | -29.2     |\n",
      "| explained_variance | -2.34e+04 |\n",
      "| fps                | 757       |\n",
      "| nupdates           | 600       |\n",
      "| policy_entropy     | 1.18      |\n",
      "| total_timesteps    | 3000      |\n",
      "| value_loss         | 0.0189    |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.2    |\n",
      "| explained_variance | -0.146   |\n",
      "| fps                | 755      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 95.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 289      |\n",
      "| ep_reward_mean     | -29.2    |\n",
      "| explained_variance | -0.00732 |\n",
      "| fps                | 782      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 8e-06    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -15.1    |\n",
      "| fps                | 775      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 3.65e-05 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | 0.0171   |\n",
      "| fps                | 771      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 94.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -0.481   |\n",
      "| fps                | 787      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 1.42e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | 0.458    |\n",
      "| fps                | 782      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 2.05e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | 0.0548   |\n",
      "| fps                | 778      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 94.9     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 294       |\n",
      "| ep_reward_mean     | -29.8     |\n",
      "| explained_variance | -4.15e+03 |\n",
      "| fps                | 791       |\n",
      "| nupdates           | 1400      |\n",
      "| policy_entropy     | 1.3       |\n",
      "| total_timesteps    | 7000      |\n",
      "| value_loss         | 8.07e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 292      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -21.5    |\n",
      "| fps                | 770      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 0.000548 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -0.046   |\n",
      "| fps                | 765      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 97.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -1.33    |\n",
      "| fps                | 775      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 6.68e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 291       |\n",
      "| ep_reward_mean     | -29.5     |\n",
      "| explained_variance | -0.000286 |\n",
      "| fps                | 770       |\n",
      "| nupdates           | 1800      |\n",
      "| policy_entropy     | 1.35      |\n",
      "| total_timesteps    | 9000      |\n",
      "| value_loss         | 2.38e-06  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -0.079   |\n",
      "| fps                | 769      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.08     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 87.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -37.9    |\n",
      "| fps                | 779      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 4.85e-06 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 502\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -0.0306  |\n",
      "| fps                | 1525     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 7.42e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -11.3    |\n",
      "| fps                | 717      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 1.8e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | 0.0316   |\n",
      "| fps                | 723      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 97.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -0.0763  |\n",
      "| fps                | 811      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 9.01e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | 0.0773   |\n",
      "| fps                | 786      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 2.79e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -0.00481 |\n",
      "| fps                | 775      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -0.00431 |\n",
      "| fps                | 812      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 7.47e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 291       |\n",
      "| ep_reward_mean     | -29.5     |\n",
      "| explained_variance | -0.000195 |\n",
      "| fps                | 800       |\n",
      "| nupdates           | 700       |\n",
      "| policy_entropy     | 1.3       |\n",
      "| total_timesteps    | 3500      |\n",
      "| value_loss         | 4.26e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | 2.31e-05 |\n",
      "| fps                | 790      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 93.2     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 291       |\n",
      "| ep_reward_mean     | -29.5     |\n",
      "| explained_variance | -1.56e+03 |\n",
      "| fps                | 808       |\n",
      "| nupdates           | 900       |\n",
      "| policy_entropy     | 1.29      |\n",
      "| total_timesteps    | 4500      |\n",
      "| value_loss         | 0.000307  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 291       |\n",
      "| ep_reward_mean     | -29.5     |\n",
      "| explained_variance | -3.33e+03 |\n",
      "| fps                | 795       |\n",
      "| nupdates           | 1000      |\n",
      "| policy_entropy     | 1.31      |\n",
      "| total_timesteps    | 5000      |\n",
      "| value_loss         | 2.41e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -0.0688  |\n",
      "| fps                | 788      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 93.1     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 291       |\n",
      "| ep_reward_mean     | -29.5     |\n",
      "| explained_variance | -1.76e+04 |\n",
      "| fps                | 802       |\n",
      "| nupdates           | 1200      |\n",
      "| policy_entropy     | 1.27      |\n",
      "| total_timesteps    | 6000      |\n",
      "| value_loss         | 2.22e-06  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| ep_len_mean        | 291       |\n",
      "| ep_reward_mean     | -29.5     |\n",
      "| explained_variance | -1.34e+04 |\n",
      "| fps                | 793       |\n",
      "| nupdates           | 1300      |\n",
      "| policy_entropy     | 1.32      |\n",
      "| total_timesteps    | 6500      |\n",
      "| value_loss         | 0.000293  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 291       |\n",
      "| ep_reward_mean     | -29.5     |\n",
      "| explained_variance | -0.000155 |\n",
      "| fps                | 789       |\n",
      "| nupdates           | 1400      |\n",
      "| policy_entropy     | 1.33      |\n",
      "| total_timesteps    | 7000      |\n",
      "| value_loss         | 99.2      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | 0.00652  |\n",
      "| fps                | 801      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 2.44e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -0.015   |\n",
      "| fps                | 794      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 1.08e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | 7.75e-07 |\n",
      "| fps                | 789      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.39     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -13      |\n",
      "| fps                | 799      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 2.42e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -6.9     |\n",
      "| fps                | 793      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 2.15e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | 0.00321  |\n",
      "| fps                | 789      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 536\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -10.7    |\n",
      "| fps                | 743      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000107 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -0.8     |\n",
      "| fps                | 1037     |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 7.83e-08 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 291       |\n",
      "| ep_reward_mean     | -29.5     |\n",
      "| explained_variance | -0.000458 |\n",
      "| fps                | 852       |\n",
      "| nupdates           | 200       |\n",
      "| policy_entropy     | 1.37      |\n",
      "| total_timesteps    | 1000      |\n",
      "| value_loss         | 1.12e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 807      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 93.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -0.011   |\n",
      "| fps                | 846      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 1.62e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -0.0822  |\n",
      "| fps                | 803      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 2.96e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.2    |\n",
      "| explained_variance | 3.35e-05 |\n",
      "| fps                | 745      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 93.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.2    |\n",
      "| explained_variance | -114     |\n",
      "| fps                | 778      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 4.94e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.2    |\n",
      "| explained_variance | 0.247    |\n",
      "| fps                | 770      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 3.34e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.2    |\n",
      "| explained_variance | 1.19e-07 |\n",
      "| fps                | 769      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.2    |\n",
      "| explained_variance | -0.00989 |\n",
      "| fps                | 788      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 3.75e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.2    |\n",
      "| explained_variance | -0.115   |\n",
      "| fps                | 782      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 8.05e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.2    |\n",
      "| explained_variance | -0.0237  |\n",
      "| fps                | 778      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.2    |\n",
      "| explained_variance | -9.18    |\n",
      "| fps                | 794      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 7.95e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.2    |\n",
      "| explained_variance | 0.000332 |\n",
      "| fps                | 791      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 1.5e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | 0.0457   |\n",
      "| fps                | 788      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 95.7     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -6.07    |\n",
      "| fps                | 800      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 3.85e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -23.4    |\n",
      "| fps                | 796      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 6.86e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | 2.98e-07 |\n",
      "| fps                | 791      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 95.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -0.0113  |\n",
      "| fps                | 799      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 1.71e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | 0.0122   |\n",
      "| fps                | 793      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 3.66e-06 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 570\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | 0.00279  |\n",
      "| fps                | 1319     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 3.2e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | 0.000137 |\n",
      "| fps                | 687      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | -19.5    |\n",
      "| fps                | 800      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 4.29e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | -198     |\n",
      "| fps                | 758      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 9.46e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | 0.357    |\n",
      "| fps                | 738      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.14     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 95.4     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 294       |\n",
      "| ep_reward_mean     | -29.8     |\n",
      "| explained_variance | -1.19e+03 |\n",
      "| fps                | 774       |\n",
      "| nupdates           | 500       |\n",
      "| policy_entropy     | 1.16      |\n",
      "| total_timesteps    | 2500      |\n",
      "| value_loss         | 0.000729  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | -262     |\n",
      "| fps                | 759      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.19     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 0.00028  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | -0.0653  |\n",
      "| fps                | 750      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 97.4     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 294       |\n",
      "| ep_reward_mean     | -29.8     |\n",
      "| explained_variance | -1.19e-07 |\n",
      "| fps                | 771       |\n",
      "| nupdates           | 800       |\n",
      "| policy_entropy     | 1.21      |\n",
      "| total_timesteps    | 4000      |\n",
      "| value_loss         | 0.000111  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | -0.00591 |\n",
      "| fps                | 761      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 1.33e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | -3.5e-05 |\n",
      "| fps                | 757      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | -0.00185 |\n",
      "| fps                | 777      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 9.78e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | -0.508   |\n",
      "| fps                | 774      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 4.07e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | -0.0593  |\n",
      "| fps                | 770      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 94.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | -0.0111  |\n",
      "| fps                | 784      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 1.33e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | 0.0259   |\n",
      "| fps                | 780      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 4.17e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | 0.00882  |\n",
      "| fps                | 777      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 93.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | 0.00148  |\n",
      "| fps                | 788      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 7.43e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -0.00698 |\n",
      "| fps                | 783      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 1.24e-06 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| ep_len_mean        | 297       |\n",
      "| ep_reward_mean     | -30.1     |\n",
      "| explained_variance | -8.76e-05 |\n",
      "| fps                | 779       |\n",
      "| nupdates           | 1900      |\n",
      "| policy_entropy     | 1.35      |\n",
      "| total_timesteps    | 9500      |\n",
      "| value_loss         | 94        |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | 0.232    |\n",
      "| fps                | 786      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 0.000541 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 603\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -28.1    |\n",
      "| fps                | 1401     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000465 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 700      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 3.36e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | 4.17e-07 |\n",
      "| fps                | 714      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 95.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -1.98    |\n",
      "| fps                | 788      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 1.47e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -526     |\n",
      "| fps                | 764      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 9.61e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | 4.77e-07 |\n",
      "| fps                | 751      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | 0.019    |\n",
      "| fps                | 780      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 1.57e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -47.6    |\n",
      "| fps                | 765      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 2.12e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 297       |\n",
      "| ep_reward_mean     | -30.1     |\n",
      "| explained_variance | -6.89e-05 |\n",
      "| fps                | 755       |\n",
      "| nupdates           | 800       |\n",
      "| policy_entropy     | 1.38      |\n",
      "| total_timesteps    | 4000      |\n",
      "| value_loss         | 94.1      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -0.00643 |\n",
      "| fps                | 775      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 2.47e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 297       |\n",
      "| ep_reward_mean     | -30.1     |\n",
      "| explained_variance | -0.000842 |\n",
      "| fps                | 772       |\n",
      "| nupdates           | 1000      |\n",
      "| policy_entropy     | 1.37      |\n",
      "| total_timesteps    | 5000      |\n",
      "| value_loss         | 4.66e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | 0.0284   |\n",
      "| fps                | 769      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 95.5     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 297       |\n",
      "| ep_reward_mean     | -30.1     |\n",
      "| explained_variance | -2.48e+03 |\n",
      "| fps                | 786       |\n",
      "| nupdates           | 1200      |\n",
      "| policy_entropy     | 1.25      |\n",
      "| total_timesteps    | 6000      |\n",
      "| value_loss         | 0.000945  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -0.0284  |\n",
      "| fps                | 781      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 1.75e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -0.0557  |\n",
      "| fps                | 775      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 96.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -0.0147  |\n",
      "| fps                | 786      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 2.48e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -0.085   |\n",
      "| fps                | 780      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 1.45e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -0.0459  |\n",
      "| fps                | 774      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 94.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -216     |\n",
      "| fps                | 783      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 2.16e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -2.77    |\n",
      "| fps                | 778      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 1.29e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -0.0006  |\n",
      "| fps                | 773      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 637\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -28.9    |\n",
      "| fps                | 751      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.00027  |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | 0.0297   |\n",
      "| fps                | 975      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 2.27e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -14.3    |\n",
      "| fps                | 811      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 0.00187  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -0.00316 |\n",
      "| fps                | 771      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 96.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -0.0167  |\n",
      "| fps                | 811      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 3.89e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -0.0116  |\n",
      "| fps                | 784      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 4.19e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.000742 |\n",
      "| fps                | 767      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -7.94    |\n",
      "| fps                | 791      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 0.000196 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0142  |\n",
      "| fps                | 776      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 5e-06    |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.5     |\n",
      "| explained_variance | -0.000132 |\n",
      "| fps                | 767       |\n",
      "| nupdates           | 900       |\n",
      "| policy_entropy     | 1.36      |\n",
      "| total_timesteps    | 4500      |\n",
      "| value_loss         | 95.8      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 7.33e-06 |\n",
      "| fps                | 783      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 4.51e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.000805 |\n",
      "| fps                | 772      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 9.97e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 8.23e-06 |\n",
      "| fps                | 761      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 95.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -121     |\n",
      "| fps                | 768      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 0.000189 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -8.35e+03 |\n",
      "| fps                | 758       |\n",
      "| nupdates           | 1400      |\n",
      "| policy_entropy     | 1.18      |\n",
      "| total_timesteps    | 7000      |\n",
      "| value_loss         | 0.00271   |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.00292 |\n",
      "| fps                | 753      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -939     |\n",
      "| fps                | 764      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 4.21e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -1.47    |\n",
      "| fps                | 759      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 3.63e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0261  |\n",
      "| fps                | 755      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.00223 |\n",
      "| fps                | 764      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 0.000267 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.00311  |\n",
      "| fps                | 760      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 5.05e-06 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 670\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.00305  |\n",
      "| fps                | 1238     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 4.4e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0423  |\n",
      "| fps                | 703      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 96.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -108     |\n",
      "| fps                | 812      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 7.56e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0121  |\n",
      "| fps                | 769      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 3.33e-06 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.00699  |\n",
      "| fps                | 749      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 88.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.474    |\n",
      "| fps                | 785      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 1.3e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.00535  |\n",
      "| fps                | 768      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 6.85e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0532   |\n",
      "| fps                | 758      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 95.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -92.9    |\n",
      "| fps                | 779      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 2.19e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -1.73    |\n",
      "| fps                | 768      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 1.3e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.00996  |\n",
      "| fps                | 761      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0342  |\n",
      "| fps                | 776      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 1.46e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -461     |\n",
      "| fps                | 769      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 9.48e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0248   |\n",
      "| fps                | 765      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -12.7    |\n",
      "| fps                | 781      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 1.1e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -6.24    |\n",
      "| fps                | 778      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 6.15e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0142  |\n",
      "| fps                | 775      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 93.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -9       |\n",
      "| fps                | 786      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 1.77e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -11      |\n",
      "| fps                | 781      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 1.77e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0039  |\n",
      "| fps                | 776      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -259     |\n",
      "| fps                | 784      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 2.45e-05 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 703\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.11    |\n",
      "| fps                | 1336     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 8.26e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -59.2    |\n",
      "| fps                | 695      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 0.000172 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0193  |\n",
      "| fps                | 710      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 98       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -3.09    |\n",
      "| fps                | 800      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 9.93e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -210     |\n",
      "| fps                | 784      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 5.78e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.132    |\n",
      "| fps                | 774      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 95.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -9.12    |\n",
      "| fps                | 805      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 6.23e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.535   |\n",
      "| fps                | 788      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 7.28e-06 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.000244 |\n",
      "| fps                | 776      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -28.7    |\n",
      "| fps                | 796      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 1.4e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -21.1    |\n",
      "| fps                | 791      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 0.000118 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0551   |\n",
      "| fps                | 787      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -24      |\n",
      "| fps                | 802      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 2.89e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -16.7    |\n",
      "| fps                | 794      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 8.94e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.00179  |\n",
      "| fps                | 790      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -2.13    |\n",
      "| fps                | 803      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 0.000181 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -15.2    |\n",
      "| fps                | 798      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 3.79e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0236  |\n",
      "| fps                | 794      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 92.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.00109 |\n",
      "| fps                | 805      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 5.58e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -306     |\n",
      "| fps                | 800      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 0.000449 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -3.55e-05 |\n",
      "| fps                | 797       |\n",
      "| nupdates           | 2000      |\n",
      "| policy_entropy     | 1.2       |\n",
      "| total_timesteps    | 10000     |\n",
      "| value_loss         | 93.4      |\n",
      "----------------------------------\n",
      "Length of Rewards for A2C: 737\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -34.3    |\n",
      "| fps                | 784      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000674 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -1.86e+03 |\n",
      "| fps                | 1033      |\n",
      "| nupdates           | 100       |\n",
      "| policy_entropy     | 1.35      |\n",
      "| total_timesteps    | 500       |\n",
      "| value_loss         | 0.00162   |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -16.9    |\n",
      "| fps                | 857      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 1.02e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.00785 |\n",
      "| fps                | 812      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 95.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -2.51    |\n",
      "| fps                | 862      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 4.52e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0361  |\n",
      "| fps                | 827      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 1.23e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0111   |\n",
      "| fps                | 811      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -15.3    |\n",
      "| fps                | 839      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 5.67e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -101     |\n",
      "| fps                | 822      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 2.98e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.0238   |\n",
      "| fps                | 812      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -1.1     |\n",
      "| fps                | 831      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 5.63e-06 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -2.38e+03 |\n",
      "| fps                | 821       |\n",
      "| nupdates           | 1100      |\n",
      "| policy_entropy     | 1.3       |\n",
      "| total_timesteps    | 5500      |\n",
      "| value_loss         | 2.24e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.012    |\n",
      "| fps                | 813      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 95.1     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -3.44e+03 |\n",
      "| fps                | 828       |\n",
      "| nupdates           | 1300      |\n",
      "| policy_entropy     | 1.34      |\n",
      "| total_timesteps    | 6500      |\n",
      "| value_loss         | 7.85e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -47.3    |\n",
      "| fps                | 819      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 0.000199 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0509  |\n",
      "| fps                | 814      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 96.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -372     |\n",
      "| fps                | 825      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 2.88e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -135     |\n",
      "| fps                | 817      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 3.77e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 5.47e-05 |\n",
      "| fps                | 813      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 95.2     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -5.38e+03 |\n",
      "| fps                | 822       |\n",
      "| nupdates           | 1900      |\n",
      "| policy_entropy     | 1.27      |\n",
      "| total_timesteps    | 9500      |\n",
      "| value_loss         | 1.32e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -4.65    |\n",
      "| fps                | 816      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 3.18e-05 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 770\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -38      |\n",
      "| fps                | 1529     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 8.12e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.00285 |\n",
      "| fps                | 740      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.227    |\n",
      "| fps                | 868      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 7.22e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -8.1e+05 |\n",
      "| fps                | 814      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 1.04e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.000247 |\n",
      "| fps                | 794      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 96.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -1.27    |\n",
      "| fps                | 835      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 1.01e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.0207   |\n",
      "| fps                | 813      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 1.94e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.00718  |\n",
      "| fps                | 802      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -78.4    |\n",
      "| fps                | 826      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 2.8e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -1.48    |\n",
      "| fps                | 816      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 4.41e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.00757 |\n",
      "| fps                | 808      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -150     |\n",
      "| fps                | 824      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 5.12e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -30.9    |\n",
      "| fps                | 812      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 1.33e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -0.000274 |\n",
      "| fps                | 804       |\n",
      "| nupdates           | 1300      |\n",
      "| policy_entropy     | 1.33      |\n",
      "| total_timesteps    | 6500      |\n",
      "| value_loss         | 94.2      |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -6.99    |\n",
      "| fps                | 818      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 1.43e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -3.36    |\n",
      "| fps                | 812      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 2.02e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.00153 |\n",
      "| fps                | 808      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -13.6    |\n",
      "| fps                | 818      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 6.63e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.00168 |\n",
      "| fps                | 814      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 2.09e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -0.000657 |\n",
      "| fps                | 810       |\n",
      "| nupdates           | 1900      |\n",
      "| policy_entropy     | 1.32      |\n",
      "| total_timesteps    | 9500      |\n",
      "| value_loss         | 94.6      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0155   |\n",
      "| fps                | 819      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 2.58e-08 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 803\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -439     |\n",
      "| fps                | 1617     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 2.53e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.00372 |\n",
      "| fps                | 736      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 1.08e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -0.000206 |\n",
      "| fps                | 741       |\n",
      "| nupdates           | 200       |\n",
      "| policy_entropy     | 1.33      |\n",
      "| total_timesteps    | 1000      |\n",
      "| value_loss         | 93.6      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -9.22    |\n",
      "| fps                | 823      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.17     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 0.000126 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -18.2    |\n",
      "| fps                | 797      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 2.6e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0118  |\n",
      "| fps                | 784      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 91.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -132     |\n",
      "| fps                | 818      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 0.000109 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.722   |\n",
      "| fps                | 804      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 7.53e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -2.9e-05 |\n",
      "| fps                | 794      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -208     |\n",
      "| fps                | 818      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 4.64e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -21.5    |\n",
      "| fps                | 806      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 7.32e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.0114   |\n",
      "| fps                | 798      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0248  |\n",
      "| fps                | 814      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 1.94e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.00412 |\n",
      "| fps                | 806      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 6.95e-09 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -0.000151 |\n",
      "| fps                | 801       |\n",
      "| nupdates           | 1400      |\n",
      "| policy_entropy     | 1.35      |\n",
      "| total_timesteps    | 7000      |\n",
      "| value_loss         | 94.2      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.00199 |\n",
      "| fps                | 814      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 1.75e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -40.8    |\n",
      "| fps                | 808      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 3.96e-05 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 7.8e-05  |\n",
      "| fps                | 804      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.00645 |\n",
      "| fps                | 814      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 8e-07    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -180     |\n",
      "| fps                | 809      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 1.55e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0234   |\n",
      "| fps                | 806      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 97.6     |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 837\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -166     |\n",
      "| fps                | 597      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000127 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -213     |\n",
      "| fps                | 1022     |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 1.25e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -10.9    |\n",
      "| fps                | 851      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 1.27e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -2.34e-05 |\n",
      "| fps                | 810       |\n",
      "| nupdates           | 300       |\n",
      "| policy_entropy     | 1.27      |\n",
      "| total_timesteps    | 1500      |\n",
      "| value_loss         | 96.6      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -260     |\n",
      "| fps                | 858      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 6.45e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 3.87e-06 |\n",
      "| fps                | 827      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 5.75e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.042   |\n",
      "| fps                | 811      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -32.2    |\n",
      "| fps                | 839      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 8.41e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0622  |\n",
      "| fps                | 824      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 1.88e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.0127   |\n",
      "| fps                | 814      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -43.1    |\n",
      "| fps                | 833      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.18     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 7.9e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.0686   |\n",
      "| fps                | 823      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 7.74e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.00284  |\n",
      "| fps                | 816      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 94.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0512  |\n",
      "| fps                | 830      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 6.29e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0366  |\n",
      "| fps                | 821      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 2.06e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.037   |\n",
      "| fps                | 815      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 94.9     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -1.92e-05 |\n",
      "| fps                | 827       |\n",
      "| nupdates           | 1600      |\n",
      "| policy_entropy     | 1.31      |\n",
      "| total_timesteps    | 8000      |\n",
      "| value_loss         | 4.45e-06  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.246    |\n",
      "| fps                | 821      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 8.26e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -1.34e-05 |\n",
      "| fps                | 816       |\n",
      "| nupdates           | 1800      |\n",
      "| policy_entropy     | 1.28      |\n",
      "| total_timesteps    | 9000      |\n",
      "| value_loss         | 96.5      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.647    |\n",
      "| fps                | 826      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 2.5e-10  |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.589   |\n",
      "| fps                | 821      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 3.02e-06 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 870\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -98.9    |\n",
      "| fps                | 1502     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000162 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.0848   |\n",
      "| fps                | 743      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 95.8     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -0.000505 |\n",
      "| fps                | 857       |\n",
      "| nupdates           | 200       |\n",
      "| policy_entropy     | 1.35      |\n",
      "| total_timesteps    | 1000      |\n",
      "| value_loss         | 1.03e-06  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.933   |\n",
      "| fps                | 802      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 4.66e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0267  |\n",
      "| fps                | 786      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 96.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.986   |\n",
      "| fps                | 823      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 1.48e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.176   |\n",
      "| fps                | 806      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 9.03e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.000615 |\n",
      "| fps                | 795      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.946   |\n",
      "| fps                | 820      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.15     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 7.33e-07 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -0.000951 |\n",
      "| fps                | 804       |\n",
      "| nupdates           | 900       |\n",
      "| policy_entropy     | 1.37      |\n",
      "| total_timesteps    | 4500      |\n",
      "| value_loss         | 2.01e-07  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0217  |\n",
      "| fps                | 798      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 95.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -29.7    |\n",
      "| fps                | 816      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 1.55e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -1.07    |\n",
      "| fps                | 810      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 9.59e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.00211  |\n",
      "| fps                | 803      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 95.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0267   |\n",
      "| fps                | 816      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 3.38e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -3.72    |\n",
      "| fps                | 810      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 1.14e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.388   |\n",
      "| fps                | 804      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 96       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -153     |\n",
      "| fps                | 816      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 2.05e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -0.000135 |\n",
      "| fps                | 807       |\n",
      "| nupdates           | 1800      |\n",
      "| policy_entropy     | 1.26      |\n",
      "| total_timesteps    | 9000      |\n",
      "| value_loss         | 0.000457  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.00564 |\n",
      "| fps                | 803      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -5.43    |\n",
      "| fps                | 813      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 1.46e-06 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 903\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.0124   |\n",
      "| fps                | 1580     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 5.36e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.0288   |\n",
      "| fps                | 733      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 1.02e-05 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0213  |\n",
      "| fps                | 737      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 97.4     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -7.45e+03 |\n",
      "| fps                | 818       |\n",
      "| nupdates           | 300       |\n",
      "| policy_entropy     | 1.29      |\n",
      "| total_timesteps    | 1500      |\n",
      "| value_loss         | 6.93e-06  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -539     |\n",
      "| fps                | 790      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 0.000118 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0136  |\n",
      "| fps                | 779      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -7.59e+03 |\n",
      "| fps                | 813       |\n",
      "| nupdates           | 600       |\n",
      "| policy_entropy     | 1.26      |\n",
      "| total_timesteps    | 3000      |\n",
      "| value_loss         | 1.58e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 5.96e-08 |\n",
      "| fps                | 800      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 3.59e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -0.000475 |\n",
      "| fps                | 794       |\n",
      "| nupdates           | 800       |\n",
      "| policy_entropy     | 1.2       |\n",
      "| total_timesteps    | 4000      |\n",
      "| value_loss         | 94.2      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -41.3    |\n",
      "| fps                | 815      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 8.29e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 4.17e-07 |\n",
      "| fps                | 803      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.09     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 2.51e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.00884  |\n",
      "| fps                | 796      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 91.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -5.08    |\n",
      "| fps                | 812      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 3.16e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 805      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 4.97e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.0343   |\n",
      "| fps                | 801      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -7.62    |\n",
      "| fps                | 813      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 4.13e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -1.75    |\n",
      "| fps                | 806      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 1.34e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0581  |\n",
      "| fps                | 802      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 93.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -46.4    |\n",
      "| fps                | 812      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 1.62e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -0.000585 |\n",
      "| fps                | 807       |\n",
      "| nupdates           | 1900      |\n",
      "| policy_entropy     | 1.15      |\n",
      "| total_timesteps    | 9500      |\n",
      "| value_loss         | 4.82e-06  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 803      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 937\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.355   |\n",
      "| fps                | 658      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 5.56e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -99.2    |\n",
      "| fps                | 1051     |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 5.24e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -4.59    |\n",
      "| fps                | 862      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 3.21e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0205  |\n",
      "| fps                | 814      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 95       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.0233   |\n",
      "| fps                | 863      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 2.73e-06 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.883   |\n",
      "| fps                | 835      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 7.67e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0113  |\n",
      "| fps                | 817      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 98.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -35      |\n",
      "| fps                | 845      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 1.17e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -6.9     |\n",
      "| fps                | 828      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 0.0369   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.000176 |\n",
      "| fps                | 817      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -5.1     |\n",
      "| fps                | 836      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 1.65e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -77.1    |\n",
      "| fps                | 825      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 0.000163 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0129  |\n",
      "| fps                | 818      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -25      |\n",
      "| fps                | 832      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.17     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 1.8e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -1.16    |\n",
      "| fps                | 824      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 2.94e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0132  |\n",
      "| fps                | 818      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -407     |\n",
      "| fps                | 829      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 6.79e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -4.56    |\n",
      "| fps                | 822      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 6.31e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.00434  |\n",
      "| fps                | 817      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.17     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 1.19e-07 |\n",
      "| fps                | 826      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 1.12e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -279     |\n",
      "| fps                | 820      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 2.29e-05 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 970\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -877     |\n",
      "| fps                | 1506     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000258 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.00544 |\n",
      "| fps                | 731      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.19     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 93.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.00457  |\n",
      "| fps                | 855      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.13     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 0.00815  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.156    |\n",
      "| fps                | 802      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 9.61e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 784      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 94.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -95.1    |\n",
      "| fps                | 826      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 1.29e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.0769   |\n",
      "| fps                | 806      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 7.66e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 4.17e-07 |\n",
      "| fps                | 797      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.13     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 96.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -22.1    |\n",
      "| fps                | 820      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 3.51e-05 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -1.91    |\n",
      "| fps                | 807      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 1.45e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0055  |\n",
      "| fps                | 799      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.134    |\n",
      "| fps                | 817      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 4e-06    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -1.82    |\n",
      "| fps                | 809      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 7.25e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0212  |\n",
      "| fps                | 803      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 96.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0287  |\n",
      "| fps                | 816      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 0.133    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -9.24    |\n",
      "| fps                | 808      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 3.22e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -7.82e-05 |\n",
      "| fps                | 803       |\n",
      "| nupdates           | 1600      |\n",
      "| policy_entropy     | 1.38      |\n",
      "| total_timesteps    | 8000      |\n",
      "| value_loss         | 93.6      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -1.53    |\n",
      "| fps                | 815      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 3.47e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -15.7    |\n",
      "| fps                | 810      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 1.78e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.00455  |\n",
      "| fps                | 806      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -8.39    |\n",
      "| fps                | 815      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 3.94e-07 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1003\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -76.6    |\n",
      "| fps                | 1603     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 3.83e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -8.14    |\n",
      "| fps                | 713      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 0.000128 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0103  |\n",
      "| fps                | 727      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 93.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -15.1    |\n",
      "| fps                | 815      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.19     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 1.44e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -22.2    |\n",
      "| fps                | 791      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 3.85e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.0342   |\n",
      "| fps                | 779      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 99.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0344  |\n",
      "| fps                | 813      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 1.22e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -90.8    |\n",
      "| fps                | 797      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 3.82e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 5.82e-05 |\n",
      "| fps                | 788      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 93.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -19.2    |\n",
      "| fps                | 807      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 1.09e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.251    |\n",
      "| fps                | 797      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 3.46e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0512  |\n",
      "| fps                | 789      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 96.6     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.194   |\n",
      "| fps                | 803      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 1.47e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -13.1    |\n",
      "| fps                | 796      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 1.78e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0264  |\n",
      "| fps                | 790      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 91.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -225     |\n",
      "| fps                | 801      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 0.000764 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.778   |\n",
      "| fps                | 796      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 1.36e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.0173   |\n",
      "| fps                | 791      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -9.06    |\n",
      "| fps                | 801      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 2.43e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0731   |\n",
      "| fps                | 796      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 8.9e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 792      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1037\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -22      |\n",
      "| fps                | 792      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000349 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -3.84e+03 |\n",
      "| fps                | 989       |\n",
      "| nupdates           | 100       |\n",
      "| policy_entropy     | 1.31      |\n",
      "| total_timesteps    | 500       |\n",
      "| value_loss         | 4.35e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.84    |\n",
      "| fps                | 839      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 1.44e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -0.000154 |\n",
      "| fps                | 799       |\n",
      "| nupdates           | 300       |\n",
      "| policy_entropy     | 1.36      |\n",
      "| total_timesteps    | 1500      |\n",
      "| value_loss         | 94.2      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -859     |\n",
      "| fps                | 842      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 0.000276 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0144  |\n",
      "| fps                | 812      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 3.78e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.00158  |\n",
      "| fps                | 797      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -97      |\n",
      "| fps                | 823      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 2.84e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -3.66    |\n",
      "| fps                | 808      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 0.000136 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.00102 |\n",
      "| fps                | 797      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 94.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 3.28e-06 |\n",
      "| fps                | 814      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 9.34e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.229    |\n",
      "| fps                | 802      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 9.03e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.00652 |\n",
      "| fps                | 796      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -262     |\n",
      "| fps                | 811      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 5.85e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -1.02e+04 |\n",
      "| fps                | 804       |\n",
      "| nupdates           | 1400      |\n",
      "| policy_entropy     | 1.29      |\n",
      "| total_timesteps    | 7000      |\n",
      "| value_loss         | 0.000126  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -0.000263 |\n",
      "| fps                | 799       |\n",
      "| nupdates           | 1500      |\n",
      "| policy_entropy     | 1.29      |\n",
      "| total_timesteps    | 7500      |\n",
      "| value_loss         | 94.8      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 3.93e-06 |\n",
      "| fps                | 809      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 6.16e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -7.58    |\n",
      "| fps                | 803      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 1.73e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0138   |\n",
      "| fps                | 799      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 93.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -332     |\n",
      "| fps                | 808      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 2.27e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -274     |\n",
      "| fps                | 803      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 0.000113 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1070\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0136  |\n",
      "| fps                | 1500     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 2.32e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0172  |\n",
      "| fps                | 724      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -16.9    |\n",
      "| fps                | 843      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 4.17e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -7.19e+03 |\n",
      "| fps                | 798       |\n",
      "| nupdates           | 300       |\n",
      "| policy_entropy     | 1.34      |\n",
      "| total_timesteps    | 1500      |\n",
      "| value_loss         | 7.05e-07  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0194  |\n",
      "| fps                | 780      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 93.9     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -8.22e+03 |\n",
      "| fps                | 815       |\n",
      "| nupdates           | 500       |\n",
      "| policy_entropy     | 1.26      |\n",
      "| total_timesteps    | 2500      |\n",
      "| value_loss         | 4.13e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -10.6    |\n",
      "| fps                | 796      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 6.11e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.000432 |\n",
      "| fps                | 784      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -8.86    |\n",
      "| fps                | 808      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 2.44e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -2.87    |\n",
      "| fps                | 796      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 2.1e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.035   |\n",
      "| fps                | 788      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 96.2     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -1.15e+06 |\n",
      "| fps                | 803       |\n",
      "| nupdates           | 1100      |\n",
      "| policy_entropy     | 1.36      |\n",
      "| total_timesteps    | 5500      |\n",
      "| value_loss         | 2.51e-07  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.274   |\n",
      "| fps                | 795      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 3.75e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 1.59e-05 |\n",
      "| fps                | 789      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 95.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -9.75    |\n",
      "| fps                | 802      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.19     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 2.21e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -232     |\n",
      "| fps                | 797      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 4.69e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 2.98e-07 |\n",
      "| fps                | 792      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.08     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.00584  |\n",
      "| fps                | 804      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 3.19e-05 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -41.9    |\n",
      "| fps                | 796      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 3.2e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0165   |\n",
      "| fps                | 792      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 94.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -54      |\n",
      "| fps                | 802      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 1.61e-05 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1103\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 2.03e-06 |\n",
      "| fps                | 1535     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 9.52e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -53.4    |\n",
      "| fps                | 735      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.16     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 0.000467 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 7.13e-05 |\n",
      "| fps                | 732      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -4.52e-05 |\n",
      "| fps                | 817       |\n",
      "| nupdates           | 300       |\n",
      "| policy_entropy     | 1.29      |\n",
      "| total_timesteps    | 1500      |\n",
      "| value_loss         | 1.08e-06  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.542    |\n",
      "| fps                | 794      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 8.26e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.00559  |\n",
      "| fps                | 781      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 93.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0071   |\n",
      "| fps                | 817      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 6.41e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -36.5    |\n",
      "| fps                | 804      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 1.14e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.00546  |\n",
      "| fps                | 796      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0395   |\n",
      "| fps                | 818      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 1.43e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -34      |\n",
      "| fps                | 808      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 1.28e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0318  |\n",
      "| fps                | 798      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 95.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -3.15    |\n",
      "| fps                | 814      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 2.07e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.269    |\n",
      "| fps                | 807      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 4.96e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -0.000361 |\n",
      "| fps                | 801       |\n",
      "| nupdates           | 1400      |\n",
      "| policy_entropy     | 1.32      |\n",
      "| total_timesteps    | 7000      |\n",
      "| value_loss         | 94.7      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -0.000285 |\n",
      "| fps                | 814       |\n",
      "| nupdates           | 1500      |\n",
      "| policy_entropy     | 1.35      |\n",
      "| total_timesteps    | 7500      |\n",
      "| value_loss         | 2.8e-08   |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -1.32    |\n",
      "| fps                | 808      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 2.75e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.00387  |\n",
      "| fps                | 804      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -1.69    |\n",
      "| fps                | 815      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 1.18e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -8.72    |\n",
      "| fps                | 810      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 1.88e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0174  |\n",
      "| fps                | 806      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 93.6     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Rewards for A2C: 1137\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -56.1    |\n",
      "| fps                | 611      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.00144  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -57.5    |\n",
      "| fps                | 1034     |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 0.00011  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.00428  |\n",
      "| fps                | 848      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 3.55e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 1.19e-07 |\n",
      "| fps                | 811      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 94.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -34.8    |\n",
      "| fps                | 863      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 4.52e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -2.2e+03 |\n",
      "| fps                | 832      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 2.85e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0156  |\n",
      "| fps                | 811      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 93.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.00011  |\n",
      "| fps                | 839      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 1.11e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -4.38e+03 |\n",
      "| fps                | 821       |\n",
      "| nupdates           | 800       |\n",
      "| policy_entropy     | 1.28      |\n",
      "| total_timesteps    | 4000      |\n",
      "| value_loss         | 2.97e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 6.56e-06 |\n",
      "| fps                | 812      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -216     |\n",
      "| fps                | 831      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 0.000193 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.493    |\n",
      "| fps                | 821      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 3.09e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0142   |\n",
      "| fps                | 812      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -109     |\n",
      "| fps                | 825      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 1.41e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.111   |\n",
      "| fps                | 818      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 5.03e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -5.01e-06 |\n",
      "| fps                | 812       |\n",
      "| nupdates           | 1500      |\n",
      "| policy_entropy     | 1.38      |\n",
      "| total_timesteps    | 7500      |\n",
      "| value_loss         | 93.8      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -59.3    |\n",
      "| fps                | 823      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 5.63e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -7.8     |\n",
      "| fps                | 815      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 1.83e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0103   |\n",
      "| fps                | 810      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -510     |\n",
      "| fps                | 818      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 1.2e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.002    |\n",
      "| fps                | 814      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 0.0157   |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1170\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -392     |\n",
      "| fps                | 1508     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.00108  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0215   |\n",
      "| fps                | 728      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 95.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 1.31e-06 |\n",
      "| fps                | 862      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 2.52e-06 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -9.02    |\n",
      "| fps                | 814      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 9.03e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.00932 |\n",
      "| fps                | 791      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 95       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -6.2     |\n",
      "| fps                | 833      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 4.18e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.00422  |\n",
      "| fps                | 815      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 1.01e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.0326   |\n",
      "| fps                | 803      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 96.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -420     |\n",
      "| fps                | 828      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 0.00016  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -27.6    |\n",
      "| fps                | 815      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 3.16e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0512  |\n",
      "| fps                | 806      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -4.18    |\n",
      "| fps                | 824      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 1.49e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0025  |\n",
      "| fps                | 815      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 0.000116 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.163    |\n",
      "| fps                | 808      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 95.9     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -1.13e+03 |\n",
      "| fps                | 820       |\n",
      "| nupdates           | 1400      |\n",
      "| policy_entropy     | 1.29      |\n",
      "| total_timesteps    | 7000      |\n",
      "| value_loss         | 6.81e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 298      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -173     |\n",
      "| fps                | 793      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 0.000253 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 0.00254  |\n",
      "| fps                | 790      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 0.797    |\n",
      "| fps                | 801      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 8.64e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 0.111    |\n",
      "| fps                | 795      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 1.21e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 297       |\n",
      "| ep_reward_mean     | -30       |\n",
      "| explained_variance | -0.000156 |\n",
      "| fps                | 792       |\n",
      "| nupdates           | 1900      |\n",
      "| policy_entropy     | 1.35      |\n",
      "| total_timesteps    | 9500      |\n",
      "| value_loss         | 94.2      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | 0.0714   |\n",
      "| fps                | 788      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 6.66e-06 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1205\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | -27.2    |\n",
      "| fps                | 1587     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 1.51e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | -237     |\n",
      "| fps                | 733      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 0.000193 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | 2.98e-07 |\n",
      "| fps                | 735      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | 0.00221  |\n",
      "| fps                | 814      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 7.66e-07 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 294       |\n",
      "| ep_reward_mean     | -29.7     |\n",
      "| explained_variance | -0.000197 |\n",
      "| fps                | 791       |\n",
      "| nupdates           | 400       |\n",
      "| policy_entropy     | 1.16      |\n",
      "| total_timesteps    | 2000      |\n",
      "| value_loss         | 5.25e-06  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | 5.96e-07 |\n",
      "| fps                | 759      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | -0.328   |\n",
      "| fps                | 796      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 7.01e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | -0.00118 |\n",
      "| fps                | 783      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 2.67e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | 0.00643  |\n",
      "| fps                | 776      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 93.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | -58.5    |\n",
      "| fps                | 797      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 6.25e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | -6.01    |\n",
      "| fps                | 790      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 1.2e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | -0.0141  |\n",
      "| fps                | 782      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | -371     |\n",
      "| fps                | 797      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 0.000115 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | 2.98e-07 |\n",
      "| fps                | 791      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 3.25e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | 0.0198   |\n",
      "| fps                | 787      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 94.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | -106     |\n",
      "| fps                | 799      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 4.42e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | -99.9    |\n",
      "| fps                | 795      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 0.000114 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | 0.128    |\n",
      "| fps                | 789      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 94.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | -839     |\n",
      "| fps                | 800      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 5.3e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | -2.84    |\n",
      "| fps                | 796      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.18     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 1.32e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 294       |\n",
      "| ep_reward_mean     | -29.7     |\n",
      "| explained_variance | -0.000518 |\n",
      "| fps                | 793       |\n",
      "| nupdates           | 2000      |\n",
      "| policy_entropy     | 1.22      |\n",
      "| total_timesteps    | 10000     |\n",
      "| value_loss         | 94.1      |\n",
      "----------------------------------\n",
      "Length of Rewards for A2C: 1239\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | -16.2    |\n",
      "| fps                | 1056     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000641 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | -131     |\n",
      "| fps                | 1030     |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 3.09e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | -11.8    |\n",
      "| fps                | 847      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 1.02e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | 0.0104   |\n",
      "| fps                | 795      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | -0.106   |\n",
      "| fps                | 842      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 3.02e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | -2.88    |\n",
      "| fps                | 820      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 1.82e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | 1.73e-06 |\n",
      "| fps                | 803      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 93.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | -641     |\n",
      "| fps                | 825      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 5.81e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | -6.69    |\n",
      "| fps                | 796      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 7.64e-08 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | 0.0154   |\n",
      "| fps                | 789      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 95       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | 0.151    |\n",
      "| fps                | 808      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 4.79e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | -10.4    |\n",
      "| fps                | 801      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 1.58e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | 6.74e-06 |\n",
      "| fps                | 797      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 92.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | -27.8    |\n",
      "| fps                | 811      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 2.19e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 294       |\n",
      "| ep_reward_mean     | -29.7     |\n",
      "| explained_variance | -3.55e-05 |\n",
      "| fps                | 804       |\n",
      "| nupdates           | 1400      |\n",
      "| policy_entropy     | 1.34      |\n",
      "| total_timesteps    | 7000      |\n",
      "| value_loss         | 5.27e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | 0.0159   |\n",
      "| fps                | 799      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 95.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | -720     |\n",
      "| fps                | 807      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 4.04e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | -6.66    |\n",
      "| fps                | 798      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 2.35e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | -0.0116  |\n",
      "| fps                | 794      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 93.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | -88.3    |\n",
      "| fps                | 804      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 0.000192 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | -1.55    |\n",
      "| fps                | 800      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 3.59e-05 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1272\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | 2.38e-07 |\n",
      "| fps                | 1543     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 5.29e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | 0.0635   |\n",
      "| fps                | 743      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 95.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 292      |\n",
      "| ep_reward_mean     | -29.6    |\n",
      "| explained_variance | -0.0958  |\n",
      "| fps                | 735      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 1.75e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.4    |\n",
      "| explained_variance | -80.4    |\n",
      "| fps                | 729      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 9.08e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | 2.15e-06 |\n",
      "| fps                | 733      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 98.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -0.00546 |\n",
      "| fps                | 779      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 1.35e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -0.128   |\n",
      "| fps                | 771      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 0.000137 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | 0.0598   |\n",
      "| fps                | 763      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 94.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -314     |\n",
      "| fps                | 786      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 3.89e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 777      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 6.91e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -0.0434  |\n",
      "| fps                | 773      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 94.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -10.1    |\n",
      "| fps                | 792      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 0.000141 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -19.5    |\n",
      "| fps                | 787      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 5.29e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -0.0626  |\n",
      "| fps                | 782      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 93.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 293      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | -34      |\n",
      "| fps                | 793      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 8.52e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 294       |\n",
      "| ep_reward_mean     | -29.8     |\n",
      "| explained_variance | -4.41e+03 |\n",
      "| fps                | 782       |\n",
      "| nupdates           | 1500      |\n",
      "| policy_entropy     | 1.26      |\n",
      "| total_timesteps    | 7500      |\n",
      "| value_loss         | 1.92e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | -0.00523 |\n",
      "| fps                | 777      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 95.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | -30.5    |\n",
      "| fps                | 788      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 0.000244 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 294      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | 0.0323   |\n",
      "| fps                | 784      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 7.86e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -0.00024 |\n",
      "| fps                | 781      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 96.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -0.577   |\n",
      "| fps                | 791      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 6.03e-06 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1306\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -0.391   |\n",
      "| fps                | 1228     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 5.38e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -0.28    |\n",
      "| fps                | 728      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 1.59e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -0.0312  |\n",
      "| fps                | 724      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 98.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -375     |\n",
      "| fps                | 800      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 0.000135 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | 0.117    |\n",
      "| fps                | 780      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 2.24e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | 0.00241  |\n",
      "| fps                | 772      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 91.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -4.21    |\n",
      "| fps                | 806      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 9.29e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -1.99    |\n",
      "| fps                | 783      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 3.47e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | 0.108    |\n",
      "| fps                | 777      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -0.0262  |\n",
      "| fps                | 798      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 2.57e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -4.63    |\n",
      "| fps                | 791      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 4.98e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | 0.000188 |\n",
      "| fps                | 787      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 94.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | 0.148    |\n",
      "| fps                | 802      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 4.37e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -21.7    |\n",
      "| fps                | 796      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 2.27e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -0.0173  |\n",
      "| fps                | 792      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -0.0869  |\n",
      "| fps                | 805      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 3.5e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -2.12    |\n",
      "| fps                | 800      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 1.09e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | 0.0123   |\n",
      "| fps                | 796      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -58.9    |\n",
      "| fps                | 806      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 7.66e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -0.113   |\n",
      "| fps                | 802      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 3.33e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 297       |\n",
      "| ep_reward_mean     | -30.1     |\n",
      "| explained_variance | -0.000289 |\n",
      "| fps                | 799       |\n",
      "| nupdates           | 2000      |\n",
      "| policy_entropy     | 1.38      |\n",
      "| total_timesteps    | 10000     |\n",
      "| value_loss         | 94.2      |\n",
      "----------------------------------\n",
      "Length of Rewards for A2C: 1340\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -13.7    |\n",
      "| fps                | 695      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000102 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -42.7    |\n",
      "| fps                | 1059     |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 1.19e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -76.1    |\n",
      "| fps                | 870      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 4.26e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | 0.011    |\n",
      "| fps                | 820      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 297       |\n",
      "| ep_reward_mean     | -30.1     |\n",
      "| explained_variance | -1.12e+03 |\n",
      "| fps                | 860       |\n",
      "| nupdates           | 400       |\n",
      "| policy_entropy     | 1.27      |\n",
      "| total_timesteps    | 2000      |\n",
      "| value_loss         | 5.17e-06  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -261     |\n",
      "| fps                | 823      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 3.5e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -0.00214 |\n",
      "| fps                | 797      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 95.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -385     |\n",
      "| fps                | 823      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 7.08e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -49.9    |\n",
      "| fps                | 797      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 2.27e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -0.016   |\n",
      "| fps                | 784      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -96.8    |\n",
      "| fps                | 804      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 3.15e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -31.5    |\n",
      "| fps                | 797      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 7.32e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 0.0143   |\n",
      "| fps                | 788      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 95.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30.1    |\n",
      "| explained_variance | -0.00484 |\n",
      "| fps                | 803      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 1.21e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -0.299   |\n",
      "| fps                | 796      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 1.78e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -0.0164  |\n",
      "| fps                | 791      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 96.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -1.31    |\n",
      "| fps                | 803      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 2.69e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 0.232    |\n",
      "| fps                | 799      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 9.08e-07 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 0.000811 |\n",
      "| fps                | 795      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.39     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 94.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -0.0626  |\n",
      "| fps                | 804      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 2.38e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -2.26    |\n",
      "| fps                | 800      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 8.98e-06 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1373\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -3.55    |\n",
      "| fps                | 1493     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 1.43e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 0.00781  |\n",
      "| fps                | 730      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 299       |\n",
      "| ep_reward_mean     | -30.2     |\n",
      "| explained_variance | -1.11e+03 |\n",
      "| fps                | 840       |\n",
      "| nupdates           | 200       |\n",
      "| policy_entropy     | 1.19      |\n",
      "| total_timesteps    | 1000      |\n",
      "| value_loss         | 3.3e-06   |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -68.3    |\n",
      "| fps                | 793      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 0.00431  |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -7.19e-05 |\n",
      "| fps                | 773       |\n",
      "| nupdates           | 400       |\n",
      "| policy_entropy     | 1.32      |\n",
      "| total_timesteps    | 2000      |\n",
      "| value_loss         | 96.3      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -1.22e+03 |\n",
      "| fps                | 816       |\n",
      "| nupdates           | 500       |\n",
      "| policy_entropy     | 1.33      |\n",
      "| total_timesteps    | 2500      |\n",
      "| value_loss         | 2.88e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0835   |\n",
      "| fps                | 801      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 1.4e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.0231   |\n",
      "| fps                | 792      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 94.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0311  |\n",
      "| fps                | 815      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 6.91e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0216  |\n",
      "| fps                | 804      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 7.08e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.000196 |\n",
      "| fps                | 796      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -263     |\n",
      "| fps                | 815      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 1.61e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 1.85e-06 |\n",
      "| fps                | 806      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 1.79e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -9.58e-05 |\n",
      "| fps                | 800       |\n",
      "| nupdates           | 1300      |\n",
      "| policy_entropy     | 1.29      |\n",
      "| total_timesteps    | 6500      |\n",
      "| value_loss         | 96.8      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -976     |\n",
      "| fps                | 814      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 2.98e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -1.11    |\n",
      "| fps                | 808      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 5.61e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0616  |\n",
      "| fps                | 803      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 94.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.054   |\n",
      "| fps                | 814      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 5.72e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.246   |\n",
      "| fps                | 809      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 4.71e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.00194  |\n",
      "| fps                | 804      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -69      |\n",
      "| fps                | 813      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 2.31e-05 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Rewards for A2C: 1406\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -4.64e+04 |\n",
      "| fps                | 1654      |\n",
      "| nupdates           | 1         |\n",
      "| policy_entropy     | 1.33      |\n",
      "| total_timesteps    | 5         |\n",
      "| value_loss         | 9.87e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -13.4    |\n",
      "| fps                | 710      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 3.06e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.00212 |\n",
      "| fps                | 726      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -1.53e+03 |\n",
      "| fps                | 808       |\n",
      "| nupdates           | 300       |\n",
      "| policy_entropy     | 1.24      |\n",
      "| total_timesteps    | 1500      |\n",
      "| value_loss         | 0.000114  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -14      |\n",
      "| fps                | 785      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 3.94e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0118  |\n",
      "| fps                | 775      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 97.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.102   |\n",
      "| fps                | 809      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 4.26e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -41.8    |\n",
      "| fps                | 797      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 5.58e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.00022  |\n",
      "| fps                | 789      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 94.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0788  |\n",
      "| fps                | 811      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 0.000223 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -302     |\n",
      "| fps                | 801      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 2.45e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 2.98e-07 |\n",
      "| fps                | 795      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 95.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.319    |\n",
      "| fps                | 811      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 1.37e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -1.23    |\n",
      "| fps                | 802      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 8.07e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0387   |\n",
      "| fps                | 797      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 95       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0407   |\n",
      "| fps                | 810      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 7.81e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0756  |\n",
      "| fps                | 804      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 1.96e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 9.93e-05 |\n",
      "| fps                | 800      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -1.1     |\n",
      "| fps                | 809      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 7.89e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0131   |\n",
      "| fps                | 804      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 0.00842  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0243  |\n",
      "| fps                | 801      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 96.1     |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1440\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -10.1    |\n",
      "| fps                | 819      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000187 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.519   |\n",
      "| fps                | 1050     |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 8.8e-07  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.477    |\n",
      "| fps                | 864      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 8.07e-07 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0108   |\n",
      "| fps                | 820      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 95.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0194   |\n",
      "| fps                | 867      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 0.008    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -642     |\n",
      "| fps                | 835      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 0.000185 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.00646  |\n",
      "| fps                | 815      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -0.000844 |\n",
      "| fps                | 840       |\n",
      "| nupdates           | 700       |\n",
      "| policy_entropy     | 1.33      |\n",
      "| total_timesteps    | 3500      |\n",
      "| value_loss         | 5.56e-07  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.131    |\n",
      "| fps                | 824      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 7.19e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 4.49e-05 |\n",
      "| fps                | 808      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -27.3    |\n",
      "| fps                | 826      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 1.93e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -60.1    |\n",
      "| fps                | 805      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 6.25e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.00829 |\n",
      "| fps                | 793      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -23.5    |\n",
      "| fps                | 800      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 7.95e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -178     |\n",
      "| fps                | 789      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 1.53e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0205  |\n",
      "| fps                | 784      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 93.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0315   |\n",
      "| fps                | 795      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 6.18e-09 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.337    |\n",
      "| fps                | 790      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 2.6e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0817  |\n",
      "| fps                | 784      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.000872 |\n",
      "| fps                | 793      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 5.39e-07 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -1.25e+03 |\n",
      "| fps                | 789       |\n",
      "| nupdates           | 2000      |\n",
      "| policy_entropy     | 1.35      |\n",
      "| total_timesteps    | 10000     |\n",
      "| value_loss         | 6.6e-06   |\n",
      "----------------------------------\n",
      "Length of Rewards for A2C: 1473\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -1.38e+04 |\n",
      "| fps                | 1163      |\n",
      "| nupdates           | 1         |\n",
      "| policy_entropy     | 1.35      |\n",
      "| total_timesteps    | 5         |\n",
      "| value_loss         | 8.17e-06  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -1.17e-05 |\n",
      "| fps                | 717       |\n",
      "| nupdates           | 100       |\n",
      "| policy_entropy     | 1.38      |\n",
      "| total_timesteps    | 500       |\n",
      "| value_loss         | 94.6      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0236  |\n",
      "| fps                | 850      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 0.0305   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -18      |\n",
      "| fps                | 808      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 9.31e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -5.6e-06 |\n",
      "| fps                | 790      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 93.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -83.9    |\n",
      "| fps                | 825      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 3.17e-07 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.00288  |\n",
      "| fps                | 809      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 9.53e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 1.19e-05 |\n",
      "| fps                | 798      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -1.08e+03 |\n",
      "| fps                | 819       |\n",
      "| nupdates           | 800       |\n",
      "| policy_entropy     | 1.36      |\n",
      "| total_timesteps    | 4000      |\n",
      "| value_loss         | 1.8e-05   |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -19.4    |\n",
      "| fps                | 803      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 2.7e-05  |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -3.58e-06 |\n",
      "| fps                | 792       |\n",
      "| nupdates           | 1000      |\n",
      "| policy_entropy     | 1.34      |\n",
      "| total_timesteps    | 5000      |\n",
      "| value_loss         | 97        |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -162     |\n",
      "| fps                | 809      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 9.41e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -226     |\n",
      "| fps                | 801      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 2.84e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 3.95e-05 |\n",
      "| fps                | 795      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 95.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -6.6e-05 |\n",
      "| fps                | 808      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 6.09e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0747   |\n",
      "| fps                | 801      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 1.71e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 2.18e-05 |\n",
      "| fps                | 796      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 94.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.000371 |\n",
      "| fps                | 808      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 3.06e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -3.63    |\n",
      "| fps                | 803      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 4.09e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 6.08e-06 |\n",
      "| fps                | 798      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 95       |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -1.31e+03 |\n",
      "| fps                | 807       |\n",
      "| nupdates           | 2000      |\n",
      "| policy_entropy     | 1.33      |\n",
      "| total_timesteps    | 10000     |\n",
      "| value_loss         | 3.83e-05  |\n",
      "----------------------------------\n",
      "Length of Rewards for A2C: 1506\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -6.95e+03 |\n",
      "| fps                | 1544      |\n",
      "| nupdates           | 1         |\n",
      "| policy_entropy     | 1.33      |\n",
      "| total_timesteps    | 5         |\n",
      "| value_loss         | 8.11e-06  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.00463 |\n",
      "| fps                | 715      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 9.25e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -3.1e-05 |\n",
      "| fps                | 725      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -227     |\n",
      "| fps                | 805      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 0.000302 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 782      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 9.6e-10  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 1.07e-06 |\n",
      "| fps                | 773      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.00723  |\n",
      "| fps                | 805      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 2.57e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -32.5    |\n",
      "| fps                | 788      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 6.12e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -7.75e-06 |\n",
      "| fps                | 780       |\n",
      "| nupdates           | 800       |\n",
      "| policy_entropy     | 1.34      |\n",
      "| total_timesteps    | 4000      |\n",
      "| value_loss         | 96        |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.021    |\n",
      "| fps                | 798      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 1.43e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0729  |\n",
      "| fps                | 785      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 1.09e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.012   |\n",
      "| fps                | 768      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 93.7     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -3.61e+06 |\n",
      "| fps                | 771       |\n",
      "| nupdates           | 1200      |\n",
      "| policy_entropy     | 1.25      |\n",
      "| total_timesteps    | 6000      |\n",
      "| value_loss         | 1.88e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -11.2    |\n",
      "| fps                | 767      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 0.000697 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0225  |\n",
      "| fps                | 763      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 97.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0829  |\n",
      "| fps                | 777      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 1.35e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 773      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 8.51e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 2.39e-05 |\n",
      "| fps                | 770      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 96.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0494  |\n",
      "| fps                | 781      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 5.52e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -5.44    |\n",
      "| fps                | 779      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 1.59e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -2.38e-07 |\n",
      "| fps                | 776       |\n",
      "| nupdates           | 2000      |\n",
      "| policy_entropy     | 1.25      |\n",
      "| total_timesteps    | 10000     |\n",
      "| value_loss         | 93.8      |\n",
      "----------------------------------\n",
      "Length of Rewards for A2C: 1540\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -583     |\n",
      "| fps                | 879      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.00693  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 5.96e-08 |\n",
      "| fps                | 1045     |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 7.54e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -948     |\n",
      "| fps                | 863      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 3.97e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0363  |\n",
      "| fps                | 817      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -1.61    |\n",
      "| fps                | 865      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 1.17e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0201  |\n",
      "| fps                | 834      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 1.51e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -0.000222 |\n",
      "| fps                | 815       |\n",
      "| nupdates           | 600       |\n",
      "| policy_entropy     | 1.34      |\n",
      "| total_timesteps    | 3000      |\n",
      "| value_loss         | 94.4      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.00336 |\n",
      "| fps                | 842      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 3.65e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -15.6    |\n",
      "| fps                | 827      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 6.07e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 817      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -15.9    |\n",
      "| fps                | 831      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 1.39e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -10.4    |\n",
      "| fps                | 821      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 1.62e-05 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0113  |\n",
      "| fps                | 811      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.17     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 95.3     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -0.000704 |\n",
      "| fps                | 825       |\n",
      "| nupdates           | 1300      |\n",
      "| policy_entropy     | 1.38      |\n",
      "| total_timesteps    | 6500      |\n",
      "| value_loss         | 3.26e-06  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.638    |\n",
      "| fps                | 817      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 8.94e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.00147  |\n",
      "| fps                | 811      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 92.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -222     |\n",
      "| fps                | 823      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 0.000147 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -56.3    |\n",
      "| fps                | 817      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 0.000125 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0222   |\n",
      "| fps                | 812      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 93.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.297   |\n",
      "| fps                | 820      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 1.29e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -56.9    |\n",
      "| fps                | 816      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 0.000202 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1573\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -13.2    |\n",
      "| fps                | 1515     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 8.65e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.00119 |\n",
      "| fps                | 733      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 93.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -624     |\n",
      "| fps                | 799      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 0.000139 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -326     |\n",
      "| fps                | 720      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 9.88e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0012  |\n",
      "| fps                | 715      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 93.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -87.9    |\n",
      "| fps                | 763      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 7.36e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -79.7    |\n",
      "| fps                | 754      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 1.65e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -7.19e-05 |\n",
      "| fps                | 738       |\n",
      "| nupdates           | 700       |\n",
      "| policy_entropy     | 1.27      |\n",
      "| total_timesteps    | 3500      |\n",
      "| value_loss         | 95.3      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.00474  |\n",
      "| fps                | 741      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 1.89e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0935   |\n",
      "| fps                | 736      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 7.24e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.005   |\n",
      "| fps                | 734      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.14     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 98.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0976   |\n",
      "| fps                | 753      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 4.21e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.985   |\n",
      "| fps                | 747      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 1.56e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 1.59e-05 |\n",
      "| fps                | 735      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 95       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -1.84    |\n",
      "| fps                | 747      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 4.66e-06 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.153    |\n",
      "| fps                | 744      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 5.27e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 742      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 96       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.206    |\n",
      "| fps                | 755      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 7.74e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0505  |\n",
      "| fps                | 753      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 0.000134 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 2.94e-05 |\n",
      "| fps                | 751      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -152     |\n",
      "| fps                | 761      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 7.39e-05 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1606\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -30.4    |\n",
      "| fps                | 1438     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 1.64e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -171     |\n",
      "| fps                | 721      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 9.82e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0593  |\n",
      "| fps                | 719      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 96.7     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -1.52e+03 |\n",
      "| fps                | 804       |\n",
      "| nupdates           | 300       |\n",
      "| policy_entropy     | 1.28      |\n",
      "| total_timesteps    | 1500      |\n",
      "| value_loss         | 0.000214  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -18.4    |\n",
      "| fps                | 784      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 5.41e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0546   |\n",
      "| fps                | 771      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 96.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -297     |\n",
      "| fps                | 804      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 3.65e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -42      |\n",
      "| fps                | 792      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 2.02e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 2.98e-07 |\n",
      "| fps                | 785      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 93.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0344   |\n",
      "| fps                | 807      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 2.4e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0294   |\n",
      "| fps                | 798      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 3.14e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -0.000505 |\n",
      "| fps                | 792       |\n",
      "| nupdates           | 1100      |\n",
      "| policy_entropy     | 1.3       |\n",
      "| total_timesteps    | 5500      |\n",
      "| value_loss         | 93.7      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -72.4    |\n",
      "| fps                | 807      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 4.24e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.102   |\n",
      "| fps                | 801      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 3.66e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0437  |\n",
      "| fps                | 795      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 93.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0121   |\n",
      "| fps                | 809      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 2.11e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -1.27e+03 |\n",
      "| fps                | 803       |\n",
      "| nupdates           | 1600      |\n",
      "| policy_entropy     | 1.17      |\n",
      "| total_timesteps    | 8000      |\n",
      "| value_loss         | 4.95e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0308   |\n",
      "| fps                | 798      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.00729  |\n",
      "| fps                | 808      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 2.94e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -37.6    |\n",
      "| fps                | 803      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 0.000131 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.00428  |\n",
      "| fps                | 798      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1640\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 748      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 2.84e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 1.38e-05 |\n",
      "| fps                | 1041     |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 3.54e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -487     |\n",
      "| fps                | 846      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 0.000467 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0198  |\n",
      "| fps                | 798      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 847      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 0.000393 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -5.01    |\n",
      "| fps                | 816      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 2.37e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.000274 |\n",
      "| fps                | 800      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 96.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 1.31e-06 |\n",
      "| fps                | 826      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 6.11e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.0336   |\n",
      "| fps                | 813      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 0.000335 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0503  |\n",
      "| fps                | 804      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0223  |\n",
      "| fps                | 824      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 1.19e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -182     |\n",
      "| fps                | 814      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 6.08e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0354  |\n",
      "| fps                | 808      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 93.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0756  |\n",
      "| fps                | 821      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 3.66e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.0724   |\n",
      "| fps                | 814      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 5.78e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.000597 |\n",
      "| fps                | 796      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 94.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.00131 |\n",
      "| fps                | 802      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 1.28e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -2.73    |\n",
      "| fps                | 796      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 5.82e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -4.41e-06 |\n",
      "| fps                | 792       |\n",
      "| nupdates           | 1800      |\n",
      "| policy_entropy     | 1.37      |\n",
      "| total_timesteps    | 9000      |\n",
      "| value_loss         | 94.4      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -0.000219 |\n",
      "| fps                | 802       |\n",
      "| nupdates           | 1900      |\n",
      "| policy_entropy     | 1.38      |\n",
      "| total_timesteps    | 9500      |\n",
      "| value_loss         | 4.77e-06  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.00602  |\n",
      "| fps                | 797      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 2.91e-05 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Rewards for A2C: 1673\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0707  |\n",
      "| fps                | 1515     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 2.66e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.026   |\n",
      "| fps                | 738      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 93.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.865   |\n",
      "| fps                | 866      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 1.09e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -59.4    |\n",
      "| fps                | 817      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 7.64e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0655  |\n",
      "| fps                | 797      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 94.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -8.4e+03 |\n",
      "| fps                | 838      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 6.89e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 813      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 5.77e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0199   |\n",
      "| fps                | 800      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -372     |\n",
      "| fps                | 824      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 0.000124 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -1.54e+03 |\n",
      "| fps                | 811       |\n",
      "| nupdates           | 900       |\n",
      "| policy_entropy     | 1.28      |\n",
      "| total_timesteps    | 4500      |\n",
      "| value_loss         | 4.43e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.0367  |\n",
      "| fps                | 801      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 95.8     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -3.97e+04 |\n",
      "| fps                | 814       |\n",
      "| nupdates           | 1100      |\n",
      "| policy_entropy     | 1.32      |\n",
      "| total_timesteps    | 5500      |\n",
      "| value_loss         | 8.66e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 804      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 0.00752  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.00072  |\n",
      "| fps                | 796      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -164     |\n",
      "| fps                | 809      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 7.86e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.0183   |\n",
      "| fps                | 804      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 0.00033  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0359  |\n",
      "| fps                | 799      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 92.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.447   |\n",
      "| fps                | 808      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 1.15e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -9.52    |\n",
      "| fps                | 802      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 2.82e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 798      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 96.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0696  |\n",
      "| fps                | 802      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 1.93e-06 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1706\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 1.01e-06 |\n",
      "| fps                | 1195     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 1.76e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0406  |\n",
      "| fps                | 643      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 1.61e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 1.97e-06 |\n",
      "| fps                | 690      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 94.8     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.242    |\n",
      "| fps                | 778      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 3.02e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -7.97    |\n",
      "| fps                | 766      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 4.19e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.000286 |\n",
      "| fps                | 759      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -998     |\n",
      "| fps                | 793      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 4.68e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -14.1    |\n",
      "| fps                | 782      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 2.69e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.00483 |\n",
      "| fps                | 774      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -88.3    |\n",
      "| fps                | 797      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 5.78e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.638   |\n",
      "| fps                | 790      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 8.38e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.00196 |\n",
      "| fps                | 777      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 96.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -1.2e-05 |\n",
      "| fps                | 791      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 9.26e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -17.3    |\n",
      "| fps                | 786      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 3.9e-05  |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -0.000306 |\n",
      "| fps                | 782       |\n",
      "| nupdates           | 1400      |\n",
      "| policy_entropy     | 1.35      |\n",
      "| total_timesteps    | 7000      |\n",
      "| value_loss         | 94        |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.126   |\n",
      "| fps                | 795      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 0.0233   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -3.44    |\n",
      "| fps                | 790      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 2.27e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -0.0438  |\n",
      "| fps                | 772      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 110      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -1.21    |\n",
      "| fps                | 783      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 0.000329 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -0.538   |\n",
      "| fps                | 780      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 4.33e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -0.0451  |\n",
      "| fps                | 777      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 96       |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1741\n",
      "----------------------------------\n",
      "| ep_len_mean        | 297       |\n",
      "| ep_reward_mean     | -30       |\n",
      "| explained_variance | -3.32e+03 |\n",
      "| fps                | 814       |\n",
      "| nupdates           | 1         |\n",
      "| policy_entropy     | 1.31      |\n",
      "| total_timesteps    | 5         |\n",
      "| value_loss         | 0.00448   |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 0.0292   |\n",
      "| fps                | 1048     |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 1.83e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -0.0982  |\n",
      "| fps                | 865      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 1.25e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 297       |\n",
      "| ep_reward_mean     | -30       |\n",
      "| explained_variance | -0.000126 |\n",
      "| fps                | 820       |\n",
      "| nupdates           | 300       |\n",
      "| policy_entropy     | 1.32      |\n",
      "| total_timesteps    | 1500      |\n",
      "| value_loss         | 94.1      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -99.3    |\n",
      "| fps                | 863      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 1.3e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 0.0572   |\n",
      "| fps                | 832      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 1.23e-05 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 0.0004   |\n",
      "| fps                | 813      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 95.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 836      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 1.54e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 297       |\n",
      "| ep_reward_mean     | -30       |\n",
      "| explained_variance | -2.28e+03 |\n",
      "| fps                | 819       |\n",
      "| nupdates           | 800       |\n",
      "| policy_entropy     | 1.32      |\n",
      "| total_timesteps    | 4000      |\n",
      "| value_loss         | 0.000594  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 0.000972 |\n",
      "| fps                | 810      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 0.165    |\n",
      "| fps                | 830      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 6.75e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -0.00141 |\n",
      "| fps                | 819      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 7.49e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 0.000874 |\n",
      "| fps                | 812      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.15     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -0.137   |\n",
      "| fps                | 826      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.19     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 0.000232 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -22.5    |\n",
      "| fps                | 818      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 4.55e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 0.0961   |\n",
      "| fps                | 812      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 95       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -776     |\n",
      "| fps                | 824      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 0.000428 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 297       |\n",
      "| ep_reward_mean     | -30       |\n",
      "| explained_variance | -1.67e+03 |\n",
      "| fps                | 818       |\n",
      "| nupdates           | 1700      |\n",
      "| policy_entropy     | 1.24      |\n",
      "| total_timesteps    | 8500      |\n",
      "| value_loss         | 0.000247  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -0.0235  |\n",
      "| fps                | 812      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 0.454    |\n",
      "| fps                | 821      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 7.95e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -90.1    |\n",
      "| fps                | 816      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 0.00016  |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1774\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -2.03    |\n",
      "| fps                | 1500     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 1.43e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 734      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 93.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 0.0189   |\n",
      "| fps                | 864      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 1.68e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -20.6    |\n",
      "| fps                | 816      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 1.47e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 796      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 93.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -3.13    |\n",
      "| fps                | 837      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 4.7e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -0.00157 |\n",
      "| fps                | 815      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 1.33e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 800      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 96       |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 297       |\n",
      "| ep_reward_mean     | -30       |\n",
      "| explained_variance | -1.46e+03 |\n",
      "| fps                | 824       |\n",
      "| nupdates           | 800       |\n",
      "| policy_entropy     | 1.3       |\n",
      "| total_timesteps    | 4000      |\n",
      "| value_loss         | 7.81e-05  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 5.96e-08 |\n",
      "| fps                | 813      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 1.53e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -3.1e-05 |\n",
      "| fps                | 804      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -0.00541 |\n",
      "| fps                | 821      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 8.82e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 0.0186   |\n",
      "| fps                | 813      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 1.5e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 805      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 0.0189   |\n",
      "| fps                | 819      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 5.9e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 812      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 1.96e-09 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 297       |\n",
      "| ep_reward_mean     | -30       |\n",
      "| explained_variance | -4.63e-05 |\n",
      "| fps                | 804       |\n",
      "| nupdates           | 1600      |\n",
      "| policy_entropy     | 1.28      |\n",
      "| total_timesteps    | 8000      |\n",
      "| value_loss         | 95.1      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -273     |\n",
      "| fps                | 816      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 0.000156 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -93.5    |\n",
      "| fps                | 811      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 0.00011  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -0.177   |\n",
      "| fps                | 806      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.04     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 8.34e-07 |\n",
      "| fps                | 812      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 2.17e-06 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1807\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -0.387   |\n",
      "| fps                | 884      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 1.9e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 0.125    |\n",
      "| fps                | 699      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 6.54e-09 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -3.5e-05 |\n",
      "| fps                | 719      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -1.08    |\n",
      "| fps                | 797      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 4.8e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -14.8    |\n",
      "| fps                | 776      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 8.97e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 2.15e-06 |\n",
      "| fps                | 752      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 95.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -20.4    |\n",
      "| fps                | 785      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 9.42e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 0.0587   |\n",
      "| fps                | 778      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 5.78e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -0.125   |\n",
      "| fps                | 773      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 96.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -5.67    |\n",
      "| fps                | 794      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 1.01e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -31.7    |\n",
      "| fps                | 785      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 0.0001   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -0.00301 |\n",
      "| fps                | 780      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 793      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 7.78e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | 0.000656 |\n",
      "| fps                | 785      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 3.82e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -29.9    |\n",
      "| explained_variance | 0.0113   |\n",
      "| fps                | 782      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -248     |\n",
      "| fps                | 795      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 0.000291 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 297      |\n",
      "| ep_reward_mean     | -30      |\n",
      "| explained_variance | -4.11    |\n",
      "| fps                | 790      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 6.88e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 1.98e-05 |\n",
      "| fps                | 787      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0192  |\n",
      "| fps                | 798      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 5.22e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0159  |\n",
      "| fps                | 794      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 1e-05    |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -5.63e-05 |\n",
      "| fps                | 790       |\n",
      "| nupdates           | 2000      |\n",
      "| policy_entropy     | 1.36      |\n",
      "| total_timesteps    | 10000     |\n",
      "| value_loss         | 94.3      |\n",
      "----------------------------------\n",
      "Length of Rewards for A2C: 1841\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -61.1    |\n",
      "| fps                | 765      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.00106  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0523  |\n",
      "| fps                | 1035     |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 5.7e-07  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0198  |\n",
      "| fps                | 855      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 3.07e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -7.38e-05 |\n",
      "| fps                | 806       |\n",
      "| nupdates           | 300       |\n",
      "| policy_entropy     | 1.29      |\n",
      "| total_timesteps    | 1500      |\n",
      "| value_loss         | 95.1      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0186  |\n",
      "| fps                | 854      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 3.81e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -0.000953 |\n",
      "| fps                | 824       |\n",
      "| nupdates           | 500       |\n",
      "| policy_entropy     | 1.34      |\n",
      "| total_timesteps    | 2500      |\n",
      "| value_loss         | 1.07e-06  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.0726   |\n",
      "| fps                | 806      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 94.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -51.5    |\n",
      "| fps                | 834      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 2.17e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -79      |\n",
      "| fps                | 819      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 1.34e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 1.19e-05 |\n",
      "| fps                | 807      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 94.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0058  |\n",
      "| fps                | 825      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 1.14e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -7.96    |\n",
      "| fps                | 814      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 3.14e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.000128 |\n",
      "| fps                | 806      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 94.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -49.6    |\n",
      "| fps                | 820      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 1.5e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.00243  |\n",
      "| fps                | 804      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 4.36e-06 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.0218   |\n",
      "| fps                | 791      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 94.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.00903  |\n",
      "| fps                | 797      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.17     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 7.66e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.00122 |\n",
      "| fps                | 783      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.19     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 9.74e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -7.75e-06 |\n",
      "| fps                | 775       |\n",
      "| nupdates           | 1800      |\n",
      "| policy_entropy     | 1.28      |\n",
      "| total_timesteps    | 9000      |\n",
      "| value_loss         | 93.9      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -33.4    |\n",
      "| fps                | 785      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 3.96e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -53.2    |\n",
      "| fps                | 780      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 1.98e-05 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1874\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -17.2    |\n",
      "| fps                | 1186     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 7.05e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 4.11e-06 |\n",
      "| fps                | 700      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -45.2    |\n",
      "| fps                | 825      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.19     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 0.000187 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 2.98e-07 |\n",
      "| fps                | 786      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.19     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 1.03e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 2.98e-07 |\n",
      "| fps                | 772      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 96.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -2.21    |\n",
      "| fps                | 812      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 5.68e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -0.000765 |\n",
      "| fps                | 795       |\n",
      "| nupdates           | 600       |\n",
      "| policy_entropy     | 1.34      |\n",
      "| total_timesteps    | 3000      |\n",
      "| value_loss         | 1.05e-05  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -1.14e-05 |\n",
      "| fps                | 785       |\n",
      "| nupdates           | 700       |\n",
      "| policy_entropy     | 1.35      |\n",
      "| total_timesteps    | 3500      |\n",
      "| value_loss         | 93.8      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -15      |\n",
      "| fps                | 807      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 3.98e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -120     |\n",
      "| fps                | 797      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 9.02e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -0.000134 |\n",
      "| fps                | 791       |\n",
      "| nupdates           | 1000      |\n",
      "| policy_entropy     | 1.37      |\n",
      "| total_timesteps    | 5000      |\n",
      "| value_loss         | 93.6      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.264    |\n",
      "| fps                | 807      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 0.0392   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.00522 |\n",
      "| fps                | 801      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 1.48e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.000108 |\n",
      "| fps                | 796      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.198   |\n",
      "| fps                | 810      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 6.41e-09 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.0917   |\n",
      "| fps                | 803      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.17     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 1.12e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 4.11e-06 |\n",
      "| fps                | 799      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 98.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -69      |\n",
      "| fps                | 810      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 0.000122 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 806      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 2.58e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 801      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 95.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.0226   |\n",
      "| fps                | 811      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 1.11e-07 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1907\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.00201 |\n",
      "| fps                | 1516     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 1.02e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -14      |\n",
      "| fps                | 733      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 1.42e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 738      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -61.5    |\n",
      "| fps                | 814      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 4.1e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0205   |\n",
      "| fps                | 785      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 2.18e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.00327 |\n",
      "| fps                | 773      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.00584 |\n",
      "| fps                | 806      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 3.95e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.00209 |\n",
      "| fps                | 794      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 1.46e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 1.96e-05 |\n",
      "| fps                | 786      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 1.19e-07 |\n",
      "| fps                | 806      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 2.43e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -56.9    |\n",
      "| fps                | 797      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 3.63e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.00333  |\n",
      "| fps                | 792      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 94.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -63.7    |\n",
      "| fps                | 807      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 4.5e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -141     |\n",
      "| fps                | 799      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 7.15e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0011   |\n",
      "| fps                | 793      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -59.2    |\n",
      "| fps                | 806      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 3.85e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -69.4    |\n",
      "| fps                | 791      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.18     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 0.000268 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.000333 |\n",
      "| fps                | 778      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 97.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -37.8    |\n",
      "| fps                | 780      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 0.000219 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -164     |\n",
      "| fps                | 773      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 6.12e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0155  |\n",
      "| fps                | 770      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 93.7     |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1941\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -53.5    |\n",
      "| fps                | 781      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000581 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.00297  |\n",
      "| fps                | 982      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 5.15e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 1.41e-05 |\n",
      "| fps                | 819      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 4.06e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -1.14e-05 |\n",
      "| fps                | 791       |\n",
      "| nupdates           | 300       |\n",
      "| policy_entropy     | 1.34      |\n",
      "| total_timesteps    | 1500      |\n",
      "| value_loss         | 95        |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -19.7    |\n",
      "| fps                | 840      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 5.33e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.946   |\n",
      "| fps                | 811      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 2.49e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0079  |\n",
      "| fps                | 791      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 94.6     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -0.000696 |\n",
      "| fps                | 811       |\n",
      "| nupdates           | 700       |\n",
      "| policy_entropy     | 1.38      |\n",
      "| total_timesteps    | 3500      |\n",
      "| value_loss         | 3.35e-06  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.0018   |\n",
      "| fps                | 793      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 6.19e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.027   |\n",
      "| fps                | 786      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.16     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 97.1     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -2.04e+03 |\n",
      "| fps                | 804       |\n",
      "| nupdates           | 1000      |\n",
      "| policy_entropy     | 1.16      |\n",
      "| total_timesteps    | 5000      |\n",
      "| value_loss         | 7.85e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.00132 |\n",
      "| fps                | 785      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 3.71e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.00715  |\n",
      "| fps                | 776      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.00153  |\n",
      "| fps                | 792      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 1.12e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -2.54    |\n",
      "| fps                | 787      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 1.36e-07 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -6.83e-05 |\n",
      "| fps                | 782       |\n",
      "| nupdates           | 1500      |\n",
      "| policy_entropy     | 1.37      |\n",
      "| total_timesteps    | 7500      |\n",
      "| value_loss         | 94.5      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -17.4    |\n",
      "| fps                | 793      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 3.85e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.00109 |\n",
      "| fps                | 790      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 1.35e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -7.51e-06 |\n",
      "| fps                | 785       |\n",
      "| nupdates           | 1800      |\n",
      "| policy_entropy     | 1.3       |\n",
      "| total_timesteps    | 9000      |\n",
      "| value_loss         | 95.2      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.834   |\n",
      "| fps                | 787      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 2.49e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0459   |\n",
      "| fps                | 776      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 3.47e-07 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1974\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -21.4    |\n",
      "| fps                | 991      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 2.62e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.000653 |\n",
      "| fps                | 683      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 93.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -33.6    |\n",
      "| fps                | 810      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 1.41e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -61.7    |\n",
      "| fps                | 779      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 2.41e-05 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0507   |\n",
      "| fps                | 762      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 95.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -30.9    |\n",
      "| fps                | 806      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 4.05e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | -0.224   |\n",
      "| fps                | 793      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 1.76e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 0.0308   |\n",
      "| fps                | 778      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 95.6     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -1.21e+03 |\n",
      "| fps                | 799       |\n",
      "| nupdates           | 800       |\n",
      "| policy_entropy     | 1.3       |\n",
      "| total_timesteps    | 4000      |\n",
      "| value_loss         | 1.45e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.0178  |\n",
      "| fps                | 781      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.16     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 1.36e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -2.38e-07 |\n",
      "| fps                | 763       |\n",
      "| nupdates           | 1000      |\n",
      "| policy_entropy     | 1.22      |\n",
      "| total_timesteps    | 5000      |\n",
      "| value_loss         | 95.3      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 8.52e-06 |\n",
      "| fps                | 774      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 4.69e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.4     |\n",
      "| explained_variance | -1.16e+04 |\n",
      "| fps                | 766       |\n",
      "| nupdates           | 1200      |\n",
      "| policy_entropy     | 1.27      |\n",
      "| total_timesteps    | 6000      |\n",
      "| value_loss         | 0.000168  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.4    |\n",
      "| explained_variance | 2.15e-06 |\n",
      "| fps                | 762      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.104    |\n",
      "| fps                | 755      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 1.25e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 7.51e-06 |\n",
      "| fps                | 744      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 2.69e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.00847 |\n",
      "| fps                | 736      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 95       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | -0.202   |\n",
      "| fps                | 743      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 4.92e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 7.93e-06 |\n",
      "| fps                | 737      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 3.72e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 300       |\n",
      "| ep_reward_mean     | -30.3     |\n",
      "| explained_variance | -3.58e-06 |\n",
      "| fps                | 733       |\n",
      "| nupdates           | 1900      |\n",
      "| policy_entropy     | 1.34      |\n",
      "| total_timesteps    | 9500      |\n",
      "| value_loss         | 94.2      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 300      |\n",
      "| ep_reward_mean     | -30.3    |\n",
      "| explained_variance | 0.0221   |\n",
      "| fps                | 741      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 5.62e-05 |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "while (len(rewards) < 2000):\n",
    "    print(\"Length of Rewards for DQN: {}\".format(len(rewards)))\n",
    "    model.learn(total_timesteps=10000)\n",
    "    rewards = env.get_episode_rewards()\n",
    "\n",
    "while (len(rewards2) < 2000):\n",
    "    print(\"Length of Rewards for A2C: {}\".format(len(rewards2)))\n",
    "    model2.learn(total_timesteps=10000)\n",
    "    rewards2 = env2.get_episode_rewards()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = rewards[:2000]\n",
    "rewards2 = rewards2[:2000]\n",
    "episodes = len(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.title(\"Task {}\".format(i+1))\n",
    "plt.plot(list(range(episodes)),rewards, label='DQN')\n",
    "plt.plot(list(range(episodes)),rewards2, label='A2C')\n",
    "plt.legend()\n",
    "plt.savefig(\"Task 2 A4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.title(\"Task {}\".format(i+1))\n",
    "plt.plot(list(range(episodes)[1900:]),rewards[1900:], label='DQN')\n",
    "plt.plot(list(range(episodes)[1900:]),rewards2[1900:], label='A2C')\n",
    "plt.ylim(bottom=-32,top=-25)\n",
    "plt.legend()\n",
    "plt.savefig(\"Task 2 A4 Last 100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4\n",
      "-0.2\n"
     ]
    }
   ],
   "source": [
    "print(max(rewards))\n",
    "print(max(rewards2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.835259000000171\n",
      "0.059884000000000964\n"
     ]
    }
   ],
   "source": [
    "print(np.var(rewards[1900:]))\n",
    "print(np.var(rewards2[1900:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
