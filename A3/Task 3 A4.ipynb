{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "from maze_env import Maze\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stable_baselines.common.env_checker import check_env\n",
    "from stable_baselines.bench import Monitor\n",
    "from stable_baselines import DQN,A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TK_SILENCE_DEPRECATION=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MazeGym(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    def __init__(self,task):\n",
    "        self.first = 0\n",
    "        self.agentXY = [0,0]\n",
    "        self.goalXY = [4,4]\n",
    "        walls,pits = self.mazeInfo(task)\n",
    "        self.env = Maze(self.agentXY, self.goalXY, walls, pits)\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        self.observation_space = spaces.Box(low=5,high=395,shape=(4,))\n",
    "        self.counter = 0\n",
    "        self.max_steps = 300\n",
    "    \n",
    "    def mazeInfo(self, task):\n",
    "        if task == 0:\n",
    "            wall_shape=np.array([[2,2],[3,6]])\n",
    "            pits=np.array([[6,3],[1,4]])\n",
    "        elif task == 1:\n",
    "            wall_shape=np.array([[6,2],[5,2],[4,2],[3,2],[2,2],[6,3],[6,4],[6,5],[2,3],[2,4],[2,5]])\n",
    "            pits=[]\n",
    "        elif task == 2:\n",
    "            wall_shape=np.array([[6,3],[6,3],[6,2],[5,2],[4,2],[3,2],[3,3],[3,4],[3,5],[3,6],[4,6],[5,6],[5,7],[7,3]])\n",
    "            pits=np.array([[1,3],[0,5], [7,7], [8,5]])\n",
    "        return wall_shape, pits\n",
    "\n",
    "    def step(self,action):\n",
    "        self.counter += 1\n",
    "        s_,r,d = self.env.step(action)\n",
    "        if (self.counter == self.max_steps):\n",
    "            self.counter = 0\n",
    "            d = True\n",
    "        return np.array(s_),r,d,{}\n",
    "\n",
    "    def reset(self):\n",
    "        state = np.array(self.env.reset(value=self.first))\n",
    "        self.first = 1\n",
    "        return state\n",
    "\n",
    "    def render(self,mode='human'):\n",
    "        self.env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/deepq/dqn.py:129: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:358: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:359: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:139: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/deepq/policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:149: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:415: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:449: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 2 # represents which task we will run\n",
    "env = MazeGym(task=i)\n",
    "env = Monitor(env=env, filename=None)\n",
    "model = DQN('MlpPolicy', env, verbose=1) # pick your algorithm from stable baselines\n",
    "rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a DummyVecEnv.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/stable_baselines/a2c/a2c.py:184: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "env2 = MazeGym(task=i)\n",
    "env2 = Monitor(env2, filename=None)\n",
    "model2 = A2C('MlpPolicy', env2, verbose=1)\n",
    "rewards2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Rewards for DQN: 0\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 100      |\n",
      "| mean 100 episode reward | -12.6    |\n",
      "| steps                   | 3572     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 200      |\n",
      "| mean 100 episode reward | -10.8    |\n",
      "| steps                   | 4566     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 300      |\n",
      "| mean 100 episode reward | -12.1    |\n",
      "| steps                   | 7508     |\n",
      "--------------------------------------\n",
      "Length of Rewards for DQN: 330\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 100      |\n",
      "| mean 100 episode reward | -17.2    |\n",
      "| steps                   | 9611     |\n",
      "--------------------------------------\n",
      "Length of Rewards for DQN: 430\n",
      "Length of Rewards for DQN: 474\n",
      "Length of Rewards for DQN: 526\n",
      "Length of Rewards for DQN: 582\n",
      "Length of Rewards for DQN: 655\n",
      "Length of Rewards for DQN: 728\n",
      "Length of Rewards for DQN: 782\n",
      "Length of Rewards for DQN: 846\n",
      "Length of Rewards for DQN: 909\n",
      "Length of Rewards for DQN: 956\n",
      "Length of Rewards for DQN: 1005\n",
      "Length of Rewards for DQN: 1049\n",
      "Length of Rewards for DQN: 1101\n",
      "Length of Rewards for DQN: 1195\n",
      "Length of Rewards for DQN: 1246\n",
      "Length of Rewards for DQN: 1301\n",
      "Length of Rewards for DQN: 1387\n",
      "Length of Rewards for DQN: 1432\n",
      "Length of Rewards for DQN: 1505\n",
      "Length of Rewards for DQN: 1572\n",
      "Length of Rewards for DQN: 1635\n",
      "Length of Rewards for DQN: 1705\n",
      "Length of Rewards for DQN: 1767\n",
      "Length of Rewards for DQN: 1824\n",
      "Length of Rewards for DQN: 1916\n",
      "Length of Rewards for DQN: 1984\n",
      "Length of Rewards for A2C: 0\n",
      "---------------------------------\n",
      "| explained_variance | -1.79    |\n",
      "| fps                | 12       |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.39     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.312    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 50.4     |\n",
      "| ep_reward_mean     | -14.4    |\n",
      "| explained_variance | -1.28    |\n",
      "| fps                | 191      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.39     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 0.41     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 37.3     |\n",
      "| ep_reward_mean     | -12.9    |\n",
      "| explained_variance | -0.0022  |\n",
      "| fps                | 156      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.39     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 0.177    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 42.9     |\n",
      "| ep_reward_mean     | -13.2    |\n",
      "| explained_variance | 0.309    |\n",
      "| fps                | 174      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.39     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 0.056    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 48.8     |\n",
      "| ep_reward_mean     | -13.8    |\n",
      "| explained_variance | -0.657   |\n",
      "| fps                | 200      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.39     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 0.0751   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 49.8     |\n",
      "| ep_reward_mean     | -13.7    |\n",
      "| explained_variance | 0.617    |\n",
      "| fps                | 205      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.39     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 0.222    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 46.9     |\n",
      "| ep_reward_mean     | -13.5    |\n",
      "| explained_variance | -0.00569 |\n",
      "| fps                | 192      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 14.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 46       |\n",
      "| ep_reward_mean     | -13.5    |\n",
      "| explained_variance | -0.209   |\n",
      "| fps                | 193      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 0.00885  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 47.5     |\n",
      "| ep_reward_mean     | -13.5    |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 198      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 0.00843  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 45.5     |\n",
      "| ep_reward_mean     | -13.3    |\n",
      "| explained_variance | -0.284   |\n",
      "| fps                | 189      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 87.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 46       |\n",
      "| ep_reward_mean     | -13.3    |\n",
      "| explained_variance | -92.5    |\n",
      "| fps                | 196      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 0.000594 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 50.8     |\n",
      "| ep_reward_mean     | -13.6    |\n",
      "| explained_variance | 0.00647  |\n",
      "| fps                | 210      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 2.85e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 54.9     |\n",
      "| ep_reward_mean     | -13.8    |\n",
      "| explained_variance | 1.26e-05 |\n",
      "| fps                | 223      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 57.4     |\n",
      "| ep_reward_mean     | -14      |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 237      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 1.27e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 63       |\n",
      "| ep_reward_mean     | -14.4    |\n",
      "| explained_variance | -228     |\n",
      "| fps                | 246      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 8.47e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 67.1     |\n",
      "| ep_reward_mean     | -14.6    |\n",
      "| explained_variance | 0.0851   |\n",
      "| fps                | 255      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 69.9     |\n",
      "| ep_reward_mean     | -14.8    |\n",
      "| explained_variance | 0.369    |\n",
      "| fps                | 267      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 8.55e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 75       |\n",
      "| ep_reward_mean     | -15.2    |\n",
      "| explained_variance | -12.8    |\n",
      "| fps                | 272      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 1.16e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 80.4     |\n",
      "| ep_reward_mean     | -15.6    |\n",
      "| explained_variance | -0.0362  |\n",
      "| fps                | 281      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 93.1     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 83.3     |\n",
      "| ep_reward_mean     | -15.8    |\n",
      "| explained_variance | 0.571    |\n",
      "| fps                | 292      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 6.15e-09 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 88.8     |\n",
      "| ep_reward_mean     | -16.2    |\n",
      "| explained_variance | -183     |\n",
      "| fps                | 301      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.17     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 0.000231 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 128\n",
      "---------------------------------\n",
      "| ep_len_mean        | 88.8     |\n",
      "| ep_reward_mean     | -16.2    |\n",
      "| explained_variance | -174     |\n",
      "| fps                | 1013     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.11     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000318 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 92.2     |\n",
      "| ep_reward_mean     | -16.4    |\n",
      "| explained_variance | 0.00333  |\n",
      "| fps                | 526      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 94.2     |\n",
      "| ep_reward_mean     | -16.5    |\n",
      "| explained_variance | 0.24     |\n",
      "| fps                | 684      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 1.32e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 96.5     |\n",
      "| ep_reward_mean     | -16.5    |\n",
      "| explained_variance | -32.4    |\n",
      "| fps                | 573      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 7.2e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 101      |\n",
      "| ep_reward_mean     | -16.9    |\n",
      "| explained_variance | -0.0272  |\n",
      "| fps                | 600      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 104       |\n",
      "| ep_reward_mean     | -17.1     |\n",
      "| explained_variance | -2.66e+03 |\n",
      "| fps                | 647       |\n",
      "| nupdates           | 500       |\n",
      "| policy_entropy     | 1.32      |\n",
      "| total_timesteps    | 2500      |\n",
      "| value_loss         | 0.000342  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 108      |\n",
      "| ep_reward_mean     | -17.4    |\n",
      "| explained_variance | 0.751    |\n",
      "| fps                | 651      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 2.72e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 113      |\n",
      "| ep_reward_mean     | -17.7    |\n",
      "| explained_variance | -0.0584  |\n",
      "| fps                | 632      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 94.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 116      |\n",
      "| ep_reward_mean     | -18      |\n",
      "| explained_variance | -49.1    |\n",
      "| fps                | 581      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 6.26e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 117       |\n",
      "| ep_reward_mean     | -17.9     |\n",
      "| explained_variance | -0.000831 |\n",
      "| fps                | 560       |\n",
      "| nupdates           | 900       |\n",
      "| policy_entropy     | 1.31      |\n",
      "| total_timesteps    | 4500      |\n",
      "| value_loss         | 1.43e-06  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 123       |\n",
      "| ep_reward_mean     | -18.4     |\n",
      "| explained_variance | -0.000994 |\n",
      "| fps                | 564       |\n",
      "| nupdates           | 1000      |\n",
      "| policy_entropy     | 1.33      |\n",
      "| total_timesteps    | 5000      |\n",
      "| value_loss         | 94.6      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 126      |\n",
      "| ep_reward_mean     | -18.5    |\n",
      "| explained_variance | -0.921   |\n",
      "| fps                | 583      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 1.63e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 131      |\n",
      "| ep_reward_mean     | -18.9    |\n",
      "| explained_variance | 0.0274   |\n",
      "| fps                | 576      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 1.45e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 136      |\n",
      "| ep_reward_mean     | -19.2    |\n",
      "| explained_variance | 0.000944 |\n",
      "| fps                | 581      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 97       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 139      |\n",
      "| ep_reward_mean     | -19.4    |\n",
      "| explained_variance | -1.06    |\n",
      "| fps                | 596      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 0.00124  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 144      |\n",
      "| ep_reward_mean     | -19.8    |\n",
      "| explained_variance | -8.71    |\n",
      "| fps                | 599      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 2.1e-08  |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 149       |\n",
      "| ep_reward_mean     | -20.1     |\n",
      "| explained_variance | -0.000318 |\n",
      "| fps                | 605       |\n",
      "| nupdates           | 1600      |\n",
      "| policy_entropy     | 1.37      |\n",
      "| total_timesteps    | 8000      |\n",
      "| value_loss         | 94.7      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 152      |\n",
      "| ep_reward_mean     | -20.3    |\n",
      "| explained_variance | -355     |\n",
      "| fps                | 617      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 0.000548 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 157      |\n",
      "| ep_reward_mean     | -20.6    |\n",
      "| explained_variance | -39.1    |\n",
      "| fps                | 618      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 0.000148 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 162      |\n",
      "| ep_reward_mean     | -21      |\n",
      "| explained_variance | 0.0111   |\n",
      "| fps                | 611      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 96.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 163      |\n",
      "| ep_reward_mean     | -21      |\n",
      "| explained_variance | -6.82    |\n",
      "| fps                | 605      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 6.94e-06 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 175\n",
      "---------------------------------\n",
      "| ep_len_mean        | 163      |\n",
      "| ep_reward_mean     | -21      |\n",
      "| explained_variance | -11.4    |\n",
      "| fps                | 956      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 2.26e-05 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 165      |\n",
      "| ep_reward_mean     | -21.1    |\n",
      "| explained_variance | -40.4    |\n",
      "| fps                | 323      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 0.000192 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 169      |\n",
      "| ep_reward_mean     | -21.4    |\n",
      "| explained_variance | -0.00939 |\n",
      "| fps                | 346      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 96       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 172      |\n",
      "| ep_reward_mean     | -21.6    |\n",
      "| explained_variance | -0.0287  |\n",
      "| fps                | 413      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 1.38e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 177      |\n",
      "| ep_reward_mean     | -21.9    |\n",
      "| explained_variance | -29.8    |\n",
      "| fps                | 459      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 1.3e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 183      |\n",
      "| ep_reward_mean     | -22.4    |\n",
      "| explained_variance | 8.07e-05 |\n",
      "| fps                | 473      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 186      |\n",
      "| ep_reward_mean     | -22.7    |\n",
      "| explained_variance | -110     |\n",
      "| fps                | 497      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 0.000198 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 190      |\n",
      "| ep_reward_mean     | -22.9    |\n",
      "| explained_variance | -0.00215 |\n",
      "| fps                | 503      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.17     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 0.0233   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 195      |\n",
      "| ep_reward_mean     | -23.2    |\n",
      "| explained_variance | 0.0127   |\n",
      "| fps                | 521      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 96.5     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 198       |\n",
      "| ep_reward_mean     | -23.4     |\n",
      "| explained_variance | -8.83e+03 |\n",
      "| fps                | 550       |\n",
      "| nupdates           | 900       |\n",
      "| policy_entropy     | 1.36      |\n",
      "| total_timesteps    | 4500      |\n",
      "| value_loss         | 0.000127  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 203      |\n",
      "| ep_reward_mean     | -23.8    |\n",
      "| explained_variance | -33.3    |\n",
      "| fps                | 559      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 2.66e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 207       |\n",
      "| ep_reward_mean     | -24.1     |\n",
      "| explained_variance | -0.000212 |\n",
      "| fps                | 568       |\n",
      "| nupdates           | 1100      |\n",
      "| policy_entropy     | 1.28      |\n",
      "| total_timesteps    | 5500      |\n",
      "| value_loss         | 95.2      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 209      |\n",
      "| ep_reward_mean     | -24.2    |\n",
      "| explained_variance | 0.0061   |\n",
      "| fps                | 589      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 1.88e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 210      |\n",
      "| ep_reward_mean     | -24.3    |\n",
      "| explained_variance | -5.8     |\n",
      "| fps                | 597      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 4.07e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 210       |\n",
      "| ep_reward_mean     | -24.3     |\n",
      "| explained_variance | -6.94e-05 |\n",
      "| fps                | 603       |\n",
      "| nupdates           | 1400      |\n",
      "| policy_entropy     | 1.34      |\n",
      "| total_timesteps    | 7000      |\n",
      "| value_loss         | 97.7      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 210       |\n",
      "| ep_reward_mean     | -24.3     |\n",
      "| explained_variance | -9.46e+05 |\n",
      "| fps                | 619       |\n",
      "| nupdates           | 1500      |\n",
      "| policy_entropy     | 1.33      |\n",
      "| total_timesteps    | 7500      |\n",
      "| value_loss         | 0.00362   |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 198      |\n",
      "| ep_reward_mean     | -23.5    |\n",
      "| explained_variance | -5.5     |\n",
      "| fps                | 553      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 0.00128  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 168      |\n",
      "| ep_reward_mean     | -21.4    |\n",
      "| explained_variance | -0.0123  |\n",
      "| fps                | 471      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 40.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 155      |\n",
      "| ep_reward_mean     | -20.4    |\n",
      "| explained_variance | -8.08    |\n",
      "| fps                | 460      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 5.95e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 153      |\n",
      "| ep_reward_mean     | -20.4    |\n",
      "| explained_variance | -232     |\n",
      "| fps                | 441      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 1.66e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 135       |\n",
      "| ep_reward_mean     | -19.1     |\n",
      "| explained_variance | -0.000436 |\n",
      "| fps                | 417       |\n",
      "| nupdates           | 2000      |\n",
      "| policy_entropy     | 1.38      |\n",
      "| total_timesteps    | 10000     |\n",
      "| value_loss         | 19.6      |\n",
      "----------------------------------\n",
      "Length of Rewards for A2C: 261\n",
      "---------------------------------\n",
      "| ep_len_mean        | 135      |\n",
      "| ep_reward_mean     | -19.1    |\n",
      "| explained_variance | -41.1    |\n",
      "| fps                | 902      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000218 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 107       |\n",
      "| ep_reward_mean     | -17.3     |\n",
      "| explained_variance | -1.13e+04 |\n",
      "| fps                | 155       |\n",
      "| nupdates           | 100       |\n",
      "| policy_entropy     | 1.34      |\n",
      "| total_timesteps    | 500       |\n",
      "| value_loss         | 4.68e-07  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 93.6      |\n",
      "| ep_reward_mean     | -16.3     |\n",
      "| explained_variance | -4.44e+03 |\n",
      "| fps                | 156       |\n",
      "| nupdates           | 200       |\n",
      "| policy_entropy     | 1.34      |\n",
      "| total_timesteps    | 1000      |\n",
      "| value_loss         | 4.27e-06  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 78       |\n",
      "| ep_reward_mean     | -15.2    |\n",
      "| explained_variance | -0.00665 |\n",
      "| fps                | 170      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 41.9     |\n",
      "| ep_reward_mean     | -12.7    |\n",
      "| explained_variance | -62.6    |\n",
      "| fps                | 166      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 5.62e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 42.8     |\n",
      "| ep_reward_mean     | -12.8    |\n",
      "| explained_variance | -3.2e+07 |\n",
      "| fps                | 171      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 2.88e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 46.9     |\n",
      "| ep_reward_mean     | -13      |\n",
      "| explained_variance | 0.0296   |\n",
      "| fps                | 183      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 95.4     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 50.9      |\n",
      "| ep_reward_mean     | -13.3     |\n",
      "| explained_variance | -3.66e+03 |\n",
      "| fps                | 202       |\n",
      "| nupdates           | 700       |\n",
      "| policy_entropy     | 1.28      |\n",
      "| total_timesteps    | 3500      |\n",
      "| value_loss         | 1.5e-05   |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 54       |\n",
      "| ep_reward_mean     | -13.5    |\n",
      "| explained_variance | -17      |\n",
      "| fps                | 221      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 2.97e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 59.5     |\n",
      "| ep_reward_mean     | -13.9    |\n",
      "| explained_variance | -0.0239  |\n",
      "| fps                | 237      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 91.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 60.2     |\n",
      "| ep_reward_mean     | -14      |\n",
      "| explained_variance | -0.0455  |\n",
      "| fps                | 252      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 5.41e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 65.1     |\n",
      "| ep_reward_mean     | -14.3    |\n",
      "| explained_variance | -198     |\n",
      "| fps                | 268      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.17     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 0.000181 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 69       |\n",
      "| ep_reward_mean     | -14.6    |\n",
      "| explained_variance | 4.17e-07 |\n",
      "| fps                | 282      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 71.4     |\n",
      "| ep_reward_mean     | -14.7    |\n",
      "| explained_variance | -1.6e+03 |\n",
      "| fps                | 299      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 9.15e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 75.7     |\n",
      "| ep_reward_mean     | -15      |\n",
      "| explained_variance | 0.00024  |\n",
      "| fps                | 308      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 7.37e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 81       |\n",
      "| ep_reward_mean     | -15.4    |\n",
      "| explained_variance | 0.000275 |\n",
      "| fps                | 320      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 97       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 82.4     |\n",
      "| ep_reward_mean     | -15.4    |\n",
      "| explained_variance | -0.71    |\n",
      "| fps                | 334      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 2.94e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 87       |\n",
      "| ep_reward_mean     | -15.8    |\n",
      "| explained_variance | 0.0213   |\n",
      "| fps                | 345      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.16     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 2.65e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 91.2     |\n",
      "| ep_reward_mean     | -16      |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 352      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 94.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 93.8     |\n",
      "| ep_reward_mean     | -16.2    |\n",
      "| explained_variance | 0.0437   |\n",
      "| fps                | 364      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 0.0153   |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 99        |\n",
      "| ep_reward_mean     | -16.5     |\n",
      "| explained_variance | -4.55e+03 |\n",
      "| fps                | 373       |\n",
      "| nupdates           | 2000      |\n",
      "| policy_entropy     | 1.32      |\n",
      "| total_timesteps    | 10000     |\n",
      "| value_loss         | 0.000131  |\n",
      "----------------------------------\n",
      "Length of Rewards for A2C: 360\n",
      "----------------------------------\n",
      "| ep_len_mean        | 99        |\n",
      "| ep_reward_mean     | -16.5     |\n",
      "| explained_variance | -2.29e+03 |\n",
      "| fps                | 1171      |\n",
      "| nupdates           | 1         |\n",
      "| policy_entropy     | 1.29      |\n",
      "| total_timesteps    | 5         |\n",
      "| value_loss         | 6.43e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 104      |\n",
      "| ep_reward_mean     | -16.9    |\n",
      "| explained_variance | -0.00256 |\n",
      "| fps                | 436      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 107      |\n",
      "| ep_reward_mean     | -17.1    |\n",
      "| explained_variance | 0.497    |\n",
      "| fps                | 544      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 2.02e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 112      |\n",
      "| ep_reward_mean     | -17.4    |\n",
      "| explained_variance | -4.92    |\n",
      "| fps                | 586      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 1.18e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 117      |\n",
      "| ep_reward_mean     | -17.8    |\n",
      "| explained_variance | 8.23e-06 |\n",
      "| fps                | 545      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 120      |\n",
      "| ep_reward_mean     | -18      |\n",
      "| explained_variance | -339     |\n",
      "| fps                | 567      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 2.14e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 122      |\n",
      "| ep_reward_mean     | -18.1    |\n",
      "| explained_variance | -6.46    |\n",
      "| fps                | 471      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 0.000212 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 126      |\n",
      "| ep_reward_mean     | -18.4    |\n",
      "| explained_variance | -0.026   |\n",
      "| fps                | 444      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 127       |\n",
      "| ep_reward_mean     | -18.5     |\n",
      "| explained_variance | -1.74e+03 |\n",
      "| fps                | 465       |\n",
      "| nupdates           | 800       |\n",
      "| policy_entropy     | 1.32      |\n",
      "| total_timesteps    | 4000      |\n",
      "| value_loss         | 8.3e-07   |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 132      |\n",
      "| ep_reward_mean     | -18.8    |\n",
      "| explained_variance | -8.98    |\n",
      "| fps                | 483      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 1.29e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 137      |\n",
      "| ep_reward_mean     | -19.2    |\n",
      "| explained_variance | -0.0206  |\n",
      "| fps                | 498      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 93.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 140      |\n",
      "| ep_reward_mean     | -19.4    |\n",
      "| explained_variance | 0.659    |\n",
      "| fps                | 521      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 2.86e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 144      |\n",
      "| ep_reward_mean     | -19.6    |\n",
      "| explained_variance | -3.22    |\n",
      "| fps                | 522      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 1.19e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 150      |\n",
      "| ep_reward_mean     | -20.1    |\n",
      "| explained_variance | -0.0236  |\n",
      "| fps                | 531      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 90.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 153      |\n",
      "| ep_reward_mean     | -20.3    |\n",
      "| explained_variance | 0.246    |\n",
      "| fps                | 548      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 7.98e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 158      |\n",
      "| ep_reward_mean     | -20.7    |\n",
      "| explained_variance | -0.138   |\n",
      "| fps                | 557      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 9.78e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 164      |\n",
      "| ep_reward_mean     | -21      |\n",
      "| explained_variance | -0.0115  |\n",
      "| fps                | 563      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 92.7     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 166       |\n",
      "| ep_reward_mean     | -21.1     |\n",
      "| explained_variance | -0.000506 |\n",
      "| fps                | 577       |\n",
      "| nupdates           | 1700      |\n",
      "| policy_entropy     | 1.34      |\n",
      "| total_timesteps    | 8500      |\n",
      "| value_loss         | 1.84e-06  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 171      |\n",
      "| ep_reward_mean     | -21.5    |\n",
      "| explained_variance | -45.3    |\n",
      "| fps                | 582      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 1.75e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 177      |\n",
      "| ep_reward_mean     | -22      |\n",
      "| explained_variance | 0.00442  |\n",
      "| fps                | 586      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 93.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 179      |\n",
      "| ep_reward_mean     | -22.1    |\n",
      "| explained_variance | -24.9    |\n",
      "| fps                | 597      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 4.68e-06 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 411\n",
      "---------------------------------\n",
      "| ep_len_mean        | 179      |\n",
      "| ep_reward_mean     | -22.1    |\n",
      "| explained_variance | -1.9     |\n",
      "| fps                | 1162     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 1.16e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 184      |\n",
      "| ep_reward_mean     | -22.4    |\n",
      "| explained_variance | -22.7    |\n",
      "| fps                | 536      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 0.00018  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 189      |\n",
      "| ep_reward_mean     | -22.8    |\n",
      "| explained_variance | -0.0016  |\n",
      "| fps                | 602      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 94.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 192      |\n",
      "| ep_reward_mean     | -22.9    |\n",
      "| explained_variance | -0.00545 |\n",
      "| fps                | 693      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 3.85e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 196      |\n",
      "| ep_reward_mean     | -23.2    |\n",
      "| explained_variance | -3.53    |\n",
      "| fps                | 689      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 5.72e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 202      |\n",
      "| ep_reward_mean     | -23.6    |\n",
      "| explained_variance | 0.00695  |\n",
      "| fps                | 688      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 204      |\n",
      "| ep_reward_mean     | -23.8    |\n",
      "| explained_variance | -0.0232  |\n",
      "| fps                | 682      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 1.66e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 208      |\n",
      "| ep_reward_mean     | -24.1    |\n",
      "| explained_variance | -10.4    |\n",
      "| fps                | 685      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 8.2e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 213      |\n",
      "| ep_reward_mean     | -24.5    |\n",
      "| explained_variance | -0.00616 |\n",
      "| fps                | 685      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 95.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 216      |\n",
      "| ep_reward_mean     | -24.6    |\n",
      "| explained_variance | -11.3    |\n",
      "| fps                | 705      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 8.21e-05 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 222      |\n",
      "| ep_reward_mean     | -25      |\n",
      "| explained_variance | -4.35    |\n",
      "| fps                | 701      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.18     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 7.38e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 222      |\n",
      "| ep_reward_mean     | -25.1    |\n",
      "| explained_variance | -0.00538 |\n",
      "| fps                | 700      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 223      |\n",
      "| ep_reward_mean     | -25.1    |\n",
      "| explained_variance | -301     |\n",
      "| fps                | 701      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 0.000208 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 225      |\n",
      "| ep_reward_mean     | -25.3    |\n",
      "| explained_variance | -21.4    |\n",
      "| fps                | 701      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 3.11e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 228      |\n",
      "| ep_reward_mean     | -25.5    |\n",
      "| explained_variance | 0.00021  |\n",
      "| fps                | 701      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 95.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 228      |\n",
      "| ep_reward_mean     | -25.5    |\n",
      "| explained_variance | -29.7    |\n",
      "| fps                | 713      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 6.24e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 231      |\n",
      "| ep_reward_mean     | -25.7    |\n",
      "| explained_variance | -5.2     |\n",
      "| fps                | 710      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 3.28e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 231       |\n",
      "| ep_reward_mean     | -25.7     |\n",
      "| explained_variance | -1.47e-05 |\n",
      "| fps                | 710       |\n",
      "| nupdates           | 1700      |\n",
      "| policy_entropy     | 1.38      |\n",
      "| total_timesteps    | 8500      |\n",
      "| value_loss         | 94        |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 231      |\n",
      "| ep_reward_mean     | -25.7    |\n",
      "| explained_variance | -227     |\n",
      "| fps                | 719      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 1.75e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 231      |\n",
      "| ep_reward_mean     | -25.7    |\n",
      "| explained_variance | -308     |\n",
      "| fps                | 716      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.13     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 2.95e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 231      |\n",
      "| ep_reward_mean     | -25.7    |\n",
      "| explained_variance | -0.0129  |\n",
      "| fps                | 703      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 96.4     |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 449\n",
      "---------------------------------\n",
      "| ep_len_mean        | 231      |\n",
      "| ep_reward_mean     | -25.7    |\n",
      "| explained_variance | -26.2    |\n",
      "| fps                | 1169     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000118 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 229      |\n",
      "| ep_reward_mean     | -25.6    |\n",
      "| explained_variance | -35.5    |\n",
      "| fps                | 674      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 4.15e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 228       |\n",
      "| ep_reward_mean     | -25.5     |\n",
      "| explained_variance | -1.07e+03 |\n",
      "| fps                | 670       |\n",
      "| nupdates           | 200       |\n",
      "| policy_entropy     | 1.11      |\n",
      "| total_timesteps    | 1000      |\n",
      "| value_loss         | 9.28e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 228      |\n",
      "| ep_reward_mean     | -25.5    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 678      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 230      |\n",
      "| ep_reward_mean     | -25.6    |\n",
      "| explained_variance | 0.207    |\n",
      "| fps                | 728      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 2.61e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 231      |\n",
      "| ep_reward_mean     | -25.7    |\n",
      "| explained_variance | -0.594   |\n",
      "| fps                | 708      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 4.14e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 231      |\n",
      "| ep_reward_mean     | -25.7    |\n",
      "| explained_variance | -0.186   |\n",
      "| fps                | 705      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 93.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 231      |\n",
      "| ep_reward_mean     | -25.7    |\n",
      "| explained_variance | 0.108    |\n",
      "| fps                | 728      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 1.38e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 234      |\n",
      "| ep_reward_mean     | -25.8    |\n",
      "| explained_variance | -0.0235  |\n",
      "| fps                | 718      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 8.59e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 237       |\n",
      "| ep_reward_mean     | -26.1     |\n",
      "| explained_variance | -7.51e-06 |\n",
      "| fps                | 704       |\n",
      "| nupdates           | 900       |\n",
      "| policy_entropy     | 1.35      |\n",
      "| total_timesteps    | 4500      |\n",
      "| value_loss         | 94.4      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 240      |\n",
      "| ep_reward_mean     | -26.3    |\n",
      "| explained_variance | -465     |\n",
      "| fps                | 720      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 1.52e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 240      |\n",
      "| ep_reward_mean     | -26.3    |\n",
      "| explained_variance | -9.22    |\n",
      "| fps                | 716      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 4.69e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 243      |\n",
      "| ep_reward_mean     | -26.5    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 711      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 95.4     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 244      |\n",
      "| ep_reward_mean     | -26.5    |\n",
      "| explained_variance | -0.162   |\n",
      "| fps                | 724      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 2.4e-07  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 246      |\n",
      "| ep_reward_mean     | -26.7    |\n",
      "| explained_variance | -26.4    |\n",
      "| fps                | 722      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 3.63e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 249      |\n",
      "| ep_reward_mean     | -26.9    |\n",
      "| explained_variance | -0.00938 |\n",
      "| fps                | 715      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 95.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 251      |\n",
      "| ep_reward_mean     | -27.1    |\n",
      "| explained_variance | -363     |\n",
      "| fps                | 721      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 5.82e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 257      |\n",
      "| ep_reward_mean     | -27.4    |\n",
      "| explained_variance | 0.254    |\n",
      "| fps                | 717      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 7.26e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 262      |\n",
      "| ep_reward_mean     | -27.7    |\n",
      "| explained_variance | 2.86e-06 |\n",
      "| fps                | 716      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 95.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 264      |\n",
      "| ep_reward_mean     | -27.9    |\n",
      "| explained_variance | -698     |\n",
      "| fps                | 724      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 4.29e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 269      |\n",
      "| ep_reward_mean     | -28.2    |\n",
      "| explained_variance | -1.4e+04 |\n",
      "| fps                | 721      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 0.994    |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 0.0041   |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 483\n",
      "---------------------------------\n",
      "| ep_len_mean        | 269      |\n",
      "| ep_reward_mean     | -28.2    |\n",
      "| explained_variance | -340     |\n",
      "| fps                | 1044     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.12     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000105 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 274       |\n",
      "| ep_reward_mean     | -28.5     |\n",
      "| explained_variance | -8.63e-05 |\n",
      "| fps                | 707       |\n",
      "| nupdates           | 100       |\n",
      "| policy_entropy     | 1.28      |\n",
      "| total_timesteps    | 500       |\n",
      "| value_loss         | 93.1      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 276      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | 0.00914  |\n",
      "| fps                | 792      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 1.72e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 279      |\n",
      "| ep_reward_mean     | -29      |\n",
      "| explained_variance | -20      |\n",
      "| fps                | 741      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 3.98e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -29.2    |\n",
      "| explained_variance | 0.00435  |\n",
      "| fps                | 730      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.12     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 97       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -29.2    |\n",
      "| explained_variance | -0.00366 |\n",
      "| fps                | 774      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 1.08e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -29.2    |\n",
      "| explained_variance | -0.00921 |\n",
      "| fps                | 758      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.17     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 6.37e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 282       |\n",
      "| ep_reward_mean     | -29.2     |\n",
      "| explained_variance | -0.000182 |\n",
      "| fps                | 746       |\n",
      "| nupdates           | 700       |\n",
      "| policy_entropy     | 1.28      |\n",
      "| total_timesteps    | 3500      |\n",
      "| value_loss         | 93.9      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -29.2    |\n",
      "| explained_variance | -5.99    |\n",
      "| fps                | 764      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 9.84e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -29.4    |\n",
      "| explained_variance | -0.0012  |\n",
      "| fps                | 758      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 1.84e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -29.4    |\n",
      "| explained_variance | 0.0181   |\n",
      "| fps                | 750      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 93.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -29.4    |\n",
      "| explained_variance | -0.0015  |\n",
      "| fps                | 762      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 2.92e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -29.4    |\n",
      "| explained_variance | 0.16     |\n",
      "| fps                | 757      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 1.06e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -29.4    |\n",
      "| explained_variance | -0.0262  |\n",
      "| fps                | 752      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.17     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 94.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -29.4    |\n",
      "| explained_variance | -6       |\n",
      "| fps                | 763      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 1.03e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 285       |\n",
      "| ep_reward_mean     | -29.4     |\n",
      "| explained_variance | -1.49e+03 |\n",
      "| fps                | 756       |\n",
      "| nupdates           | 1500      |\n",
      "| policy_entropy     | 1.18      |\n",
      "| total_timesteps    | 7500      |\n",
      "| value_loss         | 0.000149  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -29.3    |\n",
      "| explained_variance | 0.000282 |\n",
      "| fps                | 752      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -29.3    |\n",
      "| explained_variance | 6.56e-06 |\n",
      "| fps                | 761      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 3e-06    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -29.3    |\n",
      "| explained_variance | -0.135   |\n",
      "| fps                | 756      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.19     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 8.57e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | 0.0185   |\n",
      "| fps                | 753      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 96.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -29.3    |\n",
      "| explained_variance | -0.0941  |\n",
      "| fps                | 748      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 9.43e-06 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 517\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -29.3    |\n",
      "| explained_variance | -26.1    |\n",
      "| fps                | 991      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 5.04e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -29.3    |\n",
      "| explained_variance | -0.788   |\n",
      "| fps                | 681      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 5.52e-07 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 285       |\n",
      "| ep_reward_mean     | -29.3     |\n",
      "| explained_variance | -0.000209 |\n",
      "| fps                | 675       |\n",
      "| nupdates           | 200       |\n",
      "| policy_entropy     | 1.33      |\n",
      "| total_timesteps    | 1000      |\n",
      "| value_loss         | 93.9      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 287      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | 0.0138   |\n",
      "| fps                | 753      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 7.57e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -7.32    |\n",
      "| fps                | 734      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 2.39e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | 0.0293   |\n",
      "| fps                | 723      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 93.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -0.273   |\n",
      "| fps                | 751      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 1.78e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -119     |\n",
      "| fps                | 740      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 0.000304 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | 6.32e-05 |\n",
      "| fps                | 728      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 94.9     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 288       |\n",
      "| ep_reward_mean     | -29.5     |\n",
      "| explained_variance | -1.06e+03 |\n",
      "| fps                | 751       |\n",
      "| nupdates           | 900       |\n",
      "| policy_entropy     | 1.29      |\n",
      "| total_timesteps    | 4500      |\n",
      "| value_loss         | 2.58e-05  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 291       |\n",
      "| ep_reward_mean     | -29.7     |\n",
      "| explained_variance | -5.28e+03 |\n",
      "| fps                | 744       |\n",
      "| nupdates           | 1000      |\n",
      "| policy_entropy     | 1.32      |\n",
      "| total_timesteps    | 5000      |\n",
      "| value_loss         | 0.000185  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | -0.011   |\n",
      "| fps                | 741      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | -946     |\n",
      "| fps                | 755      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 4.59e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 291       |\n",
      "| ep_reward_mean     | -29.7     |\n",
      "| explained_variance | -0.000257 |\n",
      "| fps                | 749       |\n",
      "| nupdates           | 1300      |\n",
      "| policy_entropy     | 1.33      |\n",
      "| total_timesteps    | 6500      |\n",
      "| value_loss         | 6.22e-06  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -29.3    |\n",
      "| explained_variance | -0.00875 |\n",
      "| fps                | 711      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 270      |\n",
      "| ep_reward_mean     | -28.4    |\n",
      "| explained_variance | -65.6    |\n",
      "| fps                | 636      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 1.3e-07  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 256      |\n",
      "| ep_reward_mean     | -27.4    |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 590      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 0.00028  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 252      |\n",
      "| ep_reward_mean     | -27.2    |\n",
      "| explained_variance | -0.0478  |\n",
      "| fps                | 588      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 96.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 246      |\n",
      "| ep_reward_mean     | -26.8    |\n",
      "| explained_variance | -5.2     |\n",
      "| fps                | 583      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 1.26e-06 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 246      |\n",
      "| ep_reward_mean     | -26.8    |\n",
      "| explained_variance | 0.00221  |\n",
      "| fps                | 587      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 1.62e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 246      |\n",
      "| ep_reward_mean     | -26.8    |\n",
      "| explained_variance | -0.183   |\n",
      "| fps                | 591      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 96.8     |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 568\n",
      "---------------------------------\n",
      "| ep_len_mean        | 246      |\n",
      "| ep_reward_mean     | -26.8    |\n",
      "| explained_variance | -174     |\n",
      "| fps                | 1234     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000534 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 244      |\n",
      "| ep_reward_mean     | -26.6    |\n",
      "| explained_variance | -0.0135  |\n",
      "| fps                | 687      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 1.32e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 237       |\n",
      "| ep_reward_mean     | -26.2     |\n",
      "| explained_variance | -1.54e+08 |\n",
      "| fps                | 541       |\n",
      "| nupdates           | 200       |\n",
      "| policy_entropy     | 1.24      |\n",
      "| total_timesteps    | 1000      |\n",
      "| value_loss         | 0.00075   |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 237      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | -0.025   |\n",
      "| fps                | 582      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 234      |\n",
      "| ep_reward_mean     | -25.9    |\n",
      "| explained_variance | -77.2    |\n",
      "| fps                | 604      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 1.25e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 234      |\n",
      "| ep_reward_mean     | -25.9    |\n",
      "| explained_variance | -316     |\n",
      "| fps                | 618      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 4.18e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 231      |\n",
      "| ep_reward_mean     | -25.7    |\n",
      "| explained_variance | 0.0293   |\n",
      "| fps                | 603      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 224      |\n",
      "| ep_reward_mean     | -25.3    |\n",
      "| explained_variance | -551     |\n",
      "| fps                | 571      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 4.2e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 219      |\n",
      "| ep_reward_mean     | -24.9    |\n",
      "| explained_variance | -8.64    |\n",
      "| fps                | 565      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 4.27e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 207      |\n",
      "| ep_reward_mean     | -24.1    |\n",
      "| explained_variance | 0.00186  |\n",
      "| fps                | 519      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 201      |\n",
      "| ep_reward_mean     | -23.7    |\n",
      "| explained_variance | -111     |\n",
      "| fps                | 519      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 3.62e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 160       |\n",
      "| ep_reward_mean     | -20.9     |\n",
      "| explained_variance | -1.17e+03 |\n",
      "| fps                | 415       |\n",
      "| nupdates           | 1100      |\n",
      "| policy_entropy     | 1.37      |\n",
      "| total_timesteps    | 5500      |\n",
      "| value_loss         | 0.000365  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 144      |\n",
      "| ep_reward_mean     | -19.8    |\n",
      "| explained_variance | -0.0101  |\n",
      "| fps                | 395      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 144      |\n",
      "| ep_reward_mean     | -19.8    |\n",
      "| explained_variance | -0.00477 |\n",
      "| fps                | 413      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 7.48e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 133      |\n",
      "| ep_reward_mean     | -19.1    |\n",
      "| explained_variance | -200     |\n",
      "| fps                | 406      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 0.000361 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 103      |\n",
      "| ep_reward_mean     | -17      |\n",
      "| explained_variance | -0.0181  |\n",
      "| fps                | 357      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 93.2      |\n",
      "| ep_reward_mean     | -16.2     |\n",
      "| explained_variance | -3.98e+03 |\n",
      "| fps                | 327       |\n",
      "| nupdates           | 1600      |\n",
      "| policy_entropy     | 1.34      |\n",
      "| total_timesteps    | 8000      |\n",
      "| value_loss         | 3.51e-08  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 87.5     |\n",
      "| ep_reward_mean     | -15.9    |\n",
      "| explained_variance | 0.187    |\n",
      "| fps                | 330      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 7.54e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 84.2     |\n",
      "| ep_reward_mean     | -15.5    |\n",
      "| explained_variance | 0.00844  |\n",
      "| fps                | 334      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 79.8     |\n",
      "| ep_reward_mean     | -15.4    |\n",
      "| explained_variance | -315     |\n",
      "| fps                | 336      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 0.0188   |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 43.9      |\n",
      "| ep_reward_mean     | -12.9     |\n",
      "| explained_variance | -3.56e+03 |\n",
      "| fps                | 272       |\n",
      "| nupdates           | 2000      |\n",
      "| policy_entropy     | 1.24      |\n",
      "| total_timesteps    | 10000     |\n",
      "| value_loss         | 0.00227   |\n",
      "----------------------------------\n",
      "Length of Rewards for A2C: 716\n",
      "---------------------------------\n",
      "| ep_len_mean        | 43.9     |\n",
      "| ep_reward_mean     | -12.9    |\n",
      "| explained_variance | -1.6e+04 |\n",
      "| fps                | 1153     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000877 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 33       |\n",
      "| ep_reward_mean     | -12.2    |\n",
      "| explained_variance | -0.224   |\n",
      "| fps                | 118      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 35.6     |\n",
      "| ep_reward_mean     | -12.3    |\n",
      "| explained_variance | -1.44    |\n",
      "| fps                | 186      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 2.75e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 39.7     |\n",
      "| ep_reward_mean     | -12.5    |\n",
      "| explained_variance | -3.17    |\n",
      "| fps                | 217      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 1.25e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 44.5     |\n",
      "| ep_reward_mean     | -12.9    |\n",
      "| explained_variance | 0.0125   |\n",
      "| fps                | 247      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 94.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 46.8     |\n",
      "| ep_reward_mean     | -13.1    |\n",
      "| explained_variance | -6.99    |\n",
      "| fps                | 283      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 3.36e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 52.6      |\n",
      "| ep_reward_mean     | -13.5     |\n",
      "| explained_variance | -1.16e+03 |\n",
      "| fps                | 301       |\n",
      "| nupdates           | 600       |\n",
      "| policy_entropy     | 1.31      |\n",
      "| total_timesteps    | 3000      |\n",
      "| value_loss         | 0.00027   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 57        |\n",
      "| ep_reward_mean     | -13.8     |\n",
      "| explained_variance | -0.000211 |\n",
      "| fps                | 315       |\n",
      "| nupdates           | 700       |\n",
      "| policy_entropy     | 1.32      |\n",
      "| total_timesteps    | 3500      |\n",
      "| value_loss         | 94.2      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 59.3     |\n",
      "| ep_reward_mean     | -13.9    |\n",
      "| explained_variance | -112     |\n",
      "| fps                | 333      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 0.00022  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 60.1     |\n",
      "| ep_reward_mean     | -14      |\n",
      "| explained_variance | 0.488    |\n",
      "| fps                | 341      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 4.09e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 63       |\n",
      "| ep_reward_mean     | -14.2    |\n",
      "| explained_variance | 0.00611  |\n",
      "| fps                | 360      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 99.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 64.3     |\n",
      "| ep_reward_mean     | -14.3    |\n",
      "| explained_variance | -148     |\n",
      "| fps                | 366      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 2.45e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 64.5     |\n",
      "| ep_reward_mean     | -14.2    |\n",
      "| explained_variance | -21.4    |\n",
      "| fps                | 375      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 7.87e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 69.8     |\n",
      "| ep_reward_mean     | -14.6    |\n",
      "| explained_variance | -0.00275 |\n",
      "| fps                | 389      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 72.6      |\n",
      "| ep_reward_mean     | -14.7     |\n",
      "| explained_variance | -5.24e+03 |\n",
      "| fps                | 402       |\n",
      "| nupdates           | 1400      |\n",
      "| policy_entropy     | 1.28      |\n",
      "| total_timesteps    | 7000      |\n",
      "| value_loss         | 6.47e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 78.5     |\n",
      "| ep_reward_mean     | -15.1    |\n",
      "| explained_variance | -1.86    |\n",
      "| fps                | 414      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 1.81e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 84.3     |\n",
      "| ep_reward_mean     | -15.5    |\n",
      "| explained_variance | 0.0303   |\n",
      "| fps                | 419      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 96       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 87       |\n",
      "| ep_reward_mean     | -15.8    |\n",
      "| explained_variance | -4.06    |\n",
      "| fps                | 430      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 4.24e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 92.9     |\n",
      "| ep_reward_mean     | -16.2    |\n",
      "| explained_variance | -75.8    |\n",
      "| fps                | 418      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 4.34e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 97.8     |\n",
      "| ep_reward_mean     | -16.5    |\n",
      "| explained_variance | 0.000322 |\n",
      "| fps                | 419      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 100      |\n",
      "| ep_reward_mean     | -16.7    |\n",
      "| explained_variance | -124     |\n",
      "| fps                | 430      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 2.05e-05 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 798\n",
      "---------------------------------\n",
      "| ep_len_mean        | 100      |\n",
      "| ep_reward_mean     | -16.7    |\n",
      "| explained_variance | -47.4    |\n",
      "| fps                | 1117     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 2.67e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 106      |\n",
      "| ep_reward_mean     | -17.1    |\n",
      "| explained_variance | 0.0143   |\n",
      "| fps                | 520      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 0.0375   |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 112       |\n",
      "| ep_reward_mean     | -17.4     |\n",
      "| explained_variance | -0.000373 |\n",
      "| fps                | 532       |\n",
      "| nupdates           | 200       |\n",
      "| policy_entropy     | 1.33      |\n",
      "| total_timesteps    | 1000      |\n",
      "| value_loss         | 97.5      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 115      |\n",
      "| ep_reward_mean     | -17.6    |\n",
      "| explained_variance | 1.31e-06 |\n",
      "| fps                | 617      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 1.82e-07 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 121      |\n",
      "| ep_reward_mean     | -18      |\n",
      "| explained_variance | 2.4e-05  |\n",
      "| fps                | 633      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 8.65e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 126      |\n",
      "| ep_reward_mean     | -18.4    |\n",
      "| explained_variance | 0.0225   |\n",
      "| fps                | 643      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 96.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 129      |\n",
      "| ep_reward_mean     | -18.6    |\n",
      "| explained_variance | -19.5    |\n",
      "| fps                | 677      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 4.72e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 135      |\n",
      "| ep_reward_mean     | -19.1    |\n",
      "| explained_variance | -34      |\n",
      "| fps                | 676      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 0.000365 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 141       |\n",
      "| ep_reward_mean     | -19.5     |\n",
      "| explained_variance | -0.000276 |\n",
      "| fps                | 678       |\n",
      "| nupdates           | 800       |\n",
      "| policy_entropy     | 1.31      |\n",
      "| total_timesteps    | 4000      |\n",
      "| value_loss         | 95.9      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 143      |\n",
      "| ep_reward_mean     | -19.6    |\n",
      "| explained_variance | 0.0869   |\n",
      "| fps                | 700      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 2.96e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 149      |\n",
      "| ep_reward_mean     | -20      |\n",
      "| explained_variance | 0.00182  |\n",
      "| fps                | 698      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 0.0159   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 154      |\n",
      "| ep_reward_mean     | -20.3    |\n",
      "| explained_variance | 0.00524  |\n",
      "| fps                | 697      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 156      |\n",
      "| ep_reward_mean     | -20.5    |\n",
      "| explained_variance | -3.54    |\n",
      "| fps                | 714      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 4.1e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 162      |\n",
      "| ep_reward_mean     | -20.9    |\n",
      "| explained_variance | -0.0207  |\n",
      "| fps                | 710      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 3.04e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 167       |\n",
      "| ep_reward_mean     | -21.3     |\n",
      "| explained_variance | -2.38e-07 |\n",
      "| fps                | 708       |\n",
      "| nupdates           | 1400      |\n",
      "| policy_entropy     | 1.37      |\n",
      "| total_timesteps    | 7000      |\n",
      "| value_loss         | 94.3      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 170      |\n",
      "| ep_reward_mean     | -21.4    |\n",
      "| explained_variance | -0.0307  |\n",
      "| fps                | 721      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 2.81e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 176      |\n",
      "| ep_reward_mean     | -21.8    |\n",
      "| explained_variance | 0.045    |\n",
      "| fps                | 717      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 1.14e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 181      |\n",
      "| ep_reward_mean     | -22.2    |\n",
      "| explained_variance | 2.74e-05 |\n",
      "| fps                | 714      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 96.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 184      |\n",
      "| ep_reward_mean     | -22.4    |\n",
      "| explained_variance | 4.77e-06 |\n",
      "| fps                | 724      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 2.96e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 190      |\n",
      "| ep_reward_mean     | -22.8    |\n",
      "| explained_variance | -0.026   |\n",
      "| fps                | 723      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 1.22e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 195      |\n",
      "| ep_reward_mean     | -23.1    |\n",
      "| explained_variance | -0.0411  |\n",
      "| fps                | 719      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 94.8     |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 834\n",
      "---------------------------------\n",
      "| ep_len_mean        | 195      |\n",
      "| ep_reward_mean     | -23.1    |\n",
      "| explained_variance | -41.9    |\n",
      "| fps                | 988      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000325 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 198      |\n",
      "| ep_reward_mean     | -23.4    |\n",
      "| explained_variance | -60.9    |\n",
      "| fps                | 895      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 5.52e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 201      |\n",
      "| ep_reward_mean     | -23.6    |\n",
      "| explained_variance | -20.3    |\n",
      "| fps                | 589      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 1.54e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 203      |\n",
      "| ep_reward_mean     | -23.7    |\n",
      "| explained_variance | -0.0744  |\n",
      "| fps                | 529      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 93.6     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 205       |\n",
      "| ep_reward_mean     | -23.9     |\n",
      "| explained_variance | -4.76e+03 |\n",
      "| fps                | 561       |\n",
      "| nupdates           | 400       |\n",
      "| policy_entropy     | 1.36      |\n",
      "| total_timesteps    | 2000      |\n",
      "| value_loss         | 6.58e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 205      |\n",
      "| ep_reward_mean     | -23.8    |\n",
      "| explained_variance | -0.0108  |\n",
      "| fps                | 557      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 9.99e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 209      |\n",
      "| ep_reward_mean     | -24.1    |\n",
      "| explained_variance | 0.0394   |\n",
      "| fps                | 571      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 210      |\n",
      "| ep_reward_mean     | -24.2    |\n",
      "| explained_variance | -3.94    |\n",
      "| fps                | 604      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 1.03e-09 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 210      |\n",
      "| ep_reward_mean     | -24.2    |\n",
      "| explained_variance | -0.0636  |\n",
      "| fps                | 613      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 2.42e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 215      |\n",
      "| ep_reward_mean     | -24.6    |\n",
      "| explained_variance | 4.31e-05 |\n",
      "| fps                | 622      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 218      |\n",
      "| ep_reward_mean     | -24.8    |\n",
      "| explained_variance | -80.7    |\n",
      "| fps                | 630      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 2.34e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 219      |\n",
      "| ep_reward_mean     | -24.8    |\n",
      "| explained_variance | 0.00718  |\n",
      "| fps                | 637      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 1.78e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 219       |\n",
      "| ep_reward_mean     | -24.9     |\n",
      "| explained_variance | -7.75e-06 |\n",
      "| fps                | 614       |\n",
      "| nupdates           | 1200      |\n",
      "| policy_entropy     | 1.31      |\n",
      "| total_timesteps    | 6000      |\n",
      "| value_loss         | 97.6      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 219      |\n",
      "| ep_reward_mean     | -24.8    |\n",
      "| explained_variance | -7.01    |\n",
      "| fps                | 630      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 2.78e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 219      |\n",
      "| ep_reward_mean     | -24.9    |\n",
      "| explained_variance | -3.53    |\n",
      "| fps                | 611      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 3.94e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 219      |\n",
      "| ep_reward_mean     | -24.9    |\n",
      "| explained_variance | -0.0238  |\n",
      "| fps                | 586      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 214      |\n",
      "| ep_reward_mean     | -24.5    |\n",
      "| explained_variance | -63.5    |\n",
      "| fps                | 565      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 6.03e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 202      |\n",
      "| ep_reward_mean     | -23.7    |\n",
      "| explained_variance | -222     |\n",
      "| fps                | 534      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 2.7e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 201      |\n",
      "| ep_reward_mean     | -23.6    |\n",
      "| explained_variance | -0.00204 |\n",
      "| fps                | 509      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 196      |\n",
      "| ep_reward_mean     | -23.4    |\n",
      "| explained_variance | -2.29    |\n",
      "| fps                | 494      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 2.91e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 195       |\n",
      "| ep_reward_mean     | -23.2     |\n",
      "| explained_variance | -0.000334 |\n",
      "| fps                | 495       |\n",
      "| nupdates           | 2000      |\n",
      "| policy_entropy     | 1.31      |\n",
      "| total_timesteps    | 10000     |\n",
      "| value_loss         | 3.71e-06  |\n",
      "----------------------------------\n",
      "Length of Rewards for A2C: 901\n",
      "---------------------------------\n",
      "| ep_len_mean        | 195      |\n",
      "| ep_reward_mean     | -23.2    |\n",
      "| explained_variance | 0.011    |\n",
      "| fps                | 1193     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 2.64e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 192       |\n",
      "| ep_reward_mean     | -23       |\n",
      "| explained_variance | -1.56e-05 |\n",
      "| fps                | 443       |\n",
      "| nupdates           | 100       |\n",
      "| policy_entropy     | 1.36      |\n",
      "| total_timesteps    | 500       |\n",
      "| value_loss         | 93.8      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 192      |\n",
      "| ep_reward_mean     | -23      |\n",
      "| explained_variance | -3.22    |\n",
      "| fps                | 603      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 5.53e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 186      |\n",
      "| ep_reward_mean     | -22.6    |\n",
      "| explained_variance | -21.3    |\n",
      "| fps                | 538      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 9.2e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 186      |\n",
      "| ep_reward_mean     | -22.6    |\n",
      "| explained_variance | 1.2e-05  |\n",
      "| fps                | 569      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 93.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 186      |\n",
      "| ep_reward_mean     | -22.6    |\n",
      "| explained_variance | -35.5    |\n",
      "| fps                | 620      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.16     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 0.000143 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 186      |\n",
      "| ep_reward_mean     | -22.6    |\n",
      "| explained_variance | 0.00618  |\n",
      "| fps                | 627      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 1.95e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 183      |\n",
      "| ep_reward_mean     | -22.4    |\n",
      "| explained_variance | 8.26e-05 |\n",
      "| fps                | 613      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 95.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 183      |\n",
      "| ep_reward_mean     | -22.4    |\n",
      "| explained_variance | 0.00445  |\n",
      "| fps                | 635      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 5.29e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 183      |\n",
      "| ep_reward_mean     | -22.4    |\n",
      "| explained_variance | -0.00608 |\n",
      "| fps                | 640      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 1.22e-05 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 180      |\n",
      "| ep_reward_mean     | -22.2    |\n",
      "| explained_variance | -0.00172 |\n",
      "| fps                | 626      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 93.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 180      |\n",
      "| ep_reward_mean     | -22.2    |\n",
      "| explained_variance | -0.069   |\n",
      "| fps                | 647      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 1.36e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 180      |\n",
      "| ep_reward_mean     | -22.2    |\n",
      "| explained_variance | -176     |\n",
      "| fps                | 651      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.19     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 0.000435 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 180      |\n",
      "| ep_reward_mean     | -22.2    |\n",
      "| explained_variance | 0.0077   |\n",
      "| fps                | 654      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 180      |\n",
      "| ep_reward_mean     | -22.2    |\n",
      "| explained_variance | -156     |\n",
      "| fps                | 669      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 8.34e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 180       |\n",
      "| ep_reward_mean     | -22.2     |\n",
      "| explained_variance | -5.81e-05 |\n",
      "| fps                | 670       |\n",
      "| nupdates           | 1500      |\n",
      "| policy_entropy     | 1.3       |\n",
      "| total_timesteps    | 7500      |\n",
      "| value_loss         | 3.75e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 180      |\n",
      "| ep_reward_mean     | -22.2    |\n",
      "| explained_variance | 1.92e-05 |\n",
      "| fps                | 672      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 97.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 180      |\n",
      "| ep_reward_mean     | -22.2    |\n",
      "| explained_variance | -0.909   |\n",
      "| fps                | 684      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 2.65e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 182      |\n",
      "| ep_reward_mean     | -22.2    |\n",
      "| explained_variance | 0.00356  |\n",
      "| fps                | 685      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 0.0285   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 185      |\n",
      "| ep_reward_mean     | -22.5    |\n",
      "| explained_variance | -0.0222  |\n",
      "| fps                | 685      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 95       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 186      |\n",
      "| ep_reward_mean     | -22.6    |\n",
      "| explained_variance | -0.00341 |\n",
      "| fps                | 685      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 1.25e-06 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 941\n",
      "---------------------------------\n",
      "| ep_len_mean        | 186      |\n",
      "| ep_reward_mean     | -22.6    |\n",
      "| explained_variance | -61      |\n",
      "| fps                | 1450     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 2.52e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 189      |\n",
      "| ep_reward_mean     | -22.8    |\n",
      "| explained_variance | -0.00589 |\n",
      "| fps                | 698      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 0.000581 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 191      |\n",
      "| ep_reward_mean     | -22.9    |\n",
      "| explained_variance | 0.000115 |\n",
      "| fps                | 693      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 95.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 192      |\n",
      "| ep_reward_mean     | -23      |\n",
      "| explained_variance | -0.00262 |\n",
      "| fps                | 767      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 5.65e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 195      |\n",
      "| ep_reward_mean     | -23.2    |\n",
      "| explained_variance | 0.0434   |\n",
      "| fps                | 746      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.15     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 5.8e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 195      |\n",
      "| ep_reward_mean     | -23.2    |\n",
      "| explained_variance | 1.19e-06 |\n",
      "| fps                | 733      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 96.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 195      |\n",
      "| ep_reward_mean     | -23.2    |\n",
      "| explained_variance | -51.9    |\n",
      "| fps                | 761      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.09     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 0.000418 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 195      |\n",
      "| ep_reward_mean     | -23.2    |\n",
      "| explained_variance | 0.000428 |\n",
      "| fps                | 752      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 6.4e-06  |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 195       |\n",
      "| ep_reward_mean     | -23.2     |\n",
      "| explained_variance | -0.000271 |\n",
      "| fps                | 743       |\n",
      "| nupdates           | 800       |\n",
      "| policy_entropy     | 1.34      |\n",
      "| total_timesteps    | 4000      |\n",
      "| value_loss         | 94.9      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 195      |\n",
      "| ep_reward_mean     | -23.2    |\n",
      "| explained_variance | -0.0141  |\n",
      "| fps                | 760      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 3.07e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 198      |\n",
      "| ep_reward_mean     | -23.4    |\n",
      "| explained_variance | -1.89    |\n",
      "| fps                | 752      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 1.33e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 200       |\n",
      "| ep_reward_mean     | -23.5     |\n",
      "| explained_variance | -7.62e-05 |\n",
      "| fps                | 747       |\n",
      "| nupdates           | 1100      |\n",
      "| policy_entropy     | 1.26      |\n",
      "| total_timesteps    | 5500      |\n",
      "| value_loss         | 95.4      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 202      |\n",
      "| ep_reward_mean     | -23.6    |\n",
      "| explained_variance | -0.012   |\n",
      "| fps                | 761      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.14     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 2.72e-05 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 204      |\n",
      "| ep_reward_mean     | -23.8    |\n",
      "| explained_variance | 0.00995  |\n",
      "| fps                | 754      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 2.84e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 204      |\n",
      "| ep_reward_mean     | -23.8    |\n",
      "| explained_variance | 9.42e-06 |\n",
      "| fps                | 749      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 204      |\n",
      "| ep_reward_mean     | -23.8    |\n",
      "| explained_variance | 0.0508   |\n",
      "| fps                | 760      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 1.27e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 210      |\n",
      "| ep_reward_mean     | -24.2    |\n",
      "| explained_variance | -70.4    |\n",
      "| fps                | 755      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.19     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 0.00021  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 214      |\n",
      "| ep_reward_mean     | -24.4    |\n",
      "| explained_variance | -0.017   |\n",
      "| fps                | 752      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 95       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 216      |\n",
      "| ep_reward_mean     | -24.6    |\n",
      "| explained_variance | -169     |\n",
      "| fps                | 761      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 5.48e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 219      |\n",
      "| ep_reward_mean     | -24.8    |\n",
      "| explained_variance | -10.3    |\n",
      "| fps                | 756      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.19     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 3.49e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 225      |\n",
      "| ep_reward_mean     | -25.2    |\n",
      "| explained_variance | 4.11e-06 |\n",
      "| fps                | 754      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 975\n",
      "---------------------------------\n",
      "| ep_len_mean        | 225      |\n",
      "| ep_reward_mean     | -25.2    |\n",
      "| explained_variance | -17.7    |\n",
      "| fps                | 985      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.19     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000215 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 226      |\n",
      "| ep_reward_mean     | -25.2    |\n",
      "| explained_variance | 0.178    |\n",
      "| fps                | 924      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 7.67e-07 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 230       |\n",
      "| ep_reward_mean     | -25.6     |\n",
      "| explained_variance | -4.21e+03 |\n",
      "| fps                | 791       |\n",
      "| nupdates           | 200       |\n",
      "| policy_entropy     | 1.32      |\n",
      "| total_timesteps    | 1000      |\n",
      "| value_loss         | 0.000158  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 235      |\n",
      "| ep_reward_mean     | -25.8    |\n",
      "| explained_variance | -0.00071 |\n",
      "| fps                | 755      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 91.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 237      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | -0.0664  |\n",
      "| fps                | 804      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 7.07e-07 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 240       |\n",
      "| ep_reward_mean     | -26.2     |\n",
      "| explained_variance | -0.000412 |\n",
      "| fps                | 777       |\n",
      "| nupdates           | 500       |\n",
      "| policy_entropy     | 1.23      |\n",
      "| total_timesteps    | 2500      |\n",
      "| value_loss         | 4.38e-06  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 246      |\n",
      "| ep_reward_mean     | -26.6    |\n",
      "| explained_variance | -0.702   |\n",
      "| fps                | 757      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 90.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 246      |\n",
      "| ep_reward_mean     | -26.7    |\n",
      "| explained_variance | -12.8    |\n",
      "| fps                | 748      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 1.74e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 250      |\n",
      "| ep_reward_mean     | -26.9    |\n",
      "| explained_variance | -7.41    |\n",
      "| fps                | 738      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 1.63e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 255      |\n",
      "| ep_reward_mean     | -27.2    |\n",
      "| explained_variance | 0.00589  |\n",
      "| fps                | 730      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 258      |\n",
      "| ep_reward_mean     | -27.5    |\n",
      "| explained_variance | -3.54    |\n",
      "| fps                | 746      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 3.35e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 262      |\n",
      "| ep_reward_mean     | -27.7    |\n",
      "| explained_variance | -16.4    |\n",
      "| fps                | 720      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 4.36e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 266      |\n",
      "| ep_reward_mean     | -28      |\n",
      "| explained_variance | 0.00731  |\n",
      "| fps                | 717      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 269      |\n",
      "| ep_reward_mean     | -28.2    |\n",
      "| explained_variance | -11.1    |\n",
      "| fps                | 728      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 5.12e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 273      |\n",
      "| ep_reward_mean     | -28.5    |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 720      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.15     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 0.033    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 273      |\n",
      "| ep_reward_mean     | -28.5    |\n",
      "| explained_variance | 0.0947   |\n",
      "| fps                | 712      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.19     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 275      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | -2.39    |\n",
      "| fps                | 719      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 1.69e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 279      |\n",
      "| ep_reward_mean     | -28.9    |\n",
      "| explained_variance | -299     |\n",
      "| fps                | 717      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 0.00024  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 278      |\n",
      "| ep_reward_mean     | -28.9    |\n",
      "| explained_variance | 0.0218   |\n",
      "| fps                | 706      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 279      |\n",
      "| ep_reward_mean     | -28.9    |\n",
      "| explained_variance | 2.38e-07 |\n",
      "| fps                | 715      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 1.14e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -29.1    |\n",
      "| explained_variance | 0.00149  |\n",
      "| fps                | 711      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 7.35e-07 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1011\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -29.1    |\n",
      "| explained_variance | -0.0999  |\n",
      "| fps                | 1186     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 4.01e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -29.2    |\n",
      "| explained_variance | 0.00198  |\n",
      "| fps                | 696      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -29.2    |\n",
      "| explained_variance | -73.7    |\n",
      "| fps                | 800      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 0.000671 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 282      |\n",
      "| ep_reward_mean     | -29.2    |\n",
      "| explained_variance | 0.129    |\n",
      "| fps                | 723      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 3.88e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -29.4    |\n",
      "| explained_variance | 0.00802  |\n",
      "| fps                | 670      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -29.4    |\n",
      "| explained_variance | -15.7    |\n",
      "| fps                | 710      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 4.34e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -29.4    |\n",
      "| explained_variance | 0.0905   |\n",
      "| fps                | 686      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 1.01e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -29.4    |\n",
      "| explained_variance | 0.0472   |\n",
      "| fps                | 660      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.16     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 95.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -29.4    |\n",
      "| explained_variance | 4.77e-07 |\n",
      "| fps                | 686      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 4.09e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -29.4    |\n",
      "| explained_variance | -0.275   |\n",
      "| fps                | 684      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 3.58e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -29.4    |\n",
      "| explained_variance | -0.0457  |\n",
      "| fps                | 682      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 95.5     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 282       |\n",
      "| ep_reward_mean     | -29.2     |\n",
      "| explained_variance | -1.92e+04 |\n",
      "| fps                | 676       |\n",
      "| nupdates           | 1100      |\n",
      "| policy_entropy     | 1.29      |\n",
      "| total_timesteps    | 5500      |\n",
      "| value_loss         | 0.000443  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 279      |\n",
      "| ep_reward_mean     | -29      |\n",
      "| explained_variance | -11.5    |\n",
      "| fps                | 661      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 1.04e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 264      |\n",
      "| ep_reward_mean     | -27.9    |\n",
      "| explained_variance | -0.00287 |\n",
      "| fps                | 589      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 93.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 252      |\n",
      "| ep_reward_mean     | -27.1    |\n",
      "| explained_variance | -0.0207  |\n",
      "| fps                | 566      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.16     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 6.62e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 249      |\n",
      "| ep_reward_mean     | -26.9    |\n",
      "| explained_variance | -4.98    |\n",
      "| fps                | 565      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 1.19e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 246      |\n",
      "| ep_reward_mean     | -26.7    |\n",
      "| explained_variance | 4.7e-05  |\n",
      "| fps                | 563      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 95.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 246      |\n",
      "| ep_reward_mean     | -26.7    |\n",
      "| explained_variance | -184     |\n",
      "| fps                | 576      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 0.00367  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 246      |\n",
      "| ep_reward_mean     | -26.7    |\n",
      "| explained_variance | 0.00468  |\n",
      "| fps                | 582      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 2.15e-05 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| ep_len_mean        | 246       |\n",
      "| ep_reward_mean     | -26.7     |\n",
      "| explained_variance | -0.000101 |\n",
      "| fps                | 585       |\n",
      "| nupdates           | 1900      |\n",
      "| policy_entropy     | 1.32      |\n",
      "| total_timesteps    | 9500      |\n",
      "| value_loss         | 94.5      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 246      |\n",
      "| ep_reward_mean     | -26.7    |\n",
      "| explained_variance | -0.0155  |\n",
      "| fps                | 597      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 1.38e-06 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1059\n",
      "----------------------------------\n",
      "| ep_len_mean        | 246       |\n",
      "| ep_reward_mean     | -26.7     |\n",
      "| explained_variance | -0.000218 |\n",
      "| fps                | 993       |\n",
      "| nupdates           | 1         |\n",
      "| policy_entropy     | 1.33      |\n",
      "| total_timesteps    | 5         |\n",
      "| value_loss         | 1.2e-06   |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 246      |\n",
      "| ep_reward_mean     | -26.7    |\n",
      "| explained_variance | 0.466    |\n",
      "| fps                | 679      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 0.0402   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 243      |\n",
      "| ep_reward_mean     | -26.5    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 588      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 94.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 243      |\n",
      "| ep_reward_mean     | -26.5    |\n",
      "| explained_variance | -298     |\n",
      "| fps                | 677      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 4.16e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 240      |\n",
      "| ep_reward_mean     | -26.3    |\n",
      "| explained_variance | -32.5    |\n",
      "| fps                | 623      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 6.4e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 240      |\n",
      "| ep_reward_mean     | -26.3    |\n",
      "| explained_variance | -0.0536  |\n",
      "| fps                | 636      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 93.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 240      |\n",
      "| ep_reward_mean     | -26.3    |\n",
      "| explained_variance | -0.0231  |\n",
      "| fps                | 671      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 1.08e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 240      |\n",
      "| ep_reward_mean     | -26.3    |\n",
      "| explained_variance | -0.00333 |\n",
      "| fps                | 669      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 7.35e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 237      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | -0.0104  |\n",
      "| fps                | 651      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 94.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 237      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | -0.0151  |\n",
      "| fps                | 671      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 2.87e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 237      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | -3.54    |\n",
      "| fps                | 669      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 7.27e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 237      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | -0.00947 |\n",
      "| fps                | 670      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 100      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 234      |\n",
      "| ep_reward_mean     | -25.9    |\n",
      "| explained_variance | -5.95    |\n",
      "| fps                | 668      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 1.24e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 231      |\n",
      "| ep_reward_mean     | -25.7    |\n",
      "| explained_variance | 0.0986   |\n",
      "| fps                | 644      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 2e-05    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 215      |\n",
      "| ep_reward_mean     | -24.6    |\n",
      "| explained_variance | 0.104    |\n",
      "| fps                | 581      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 94.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 213      |\n",
      "| ep_reward_mean     | -24.4    |\n",
      "| explained_variance | -67.2    |\n",
      "| fps                | 587      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 9.56e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 201      |\n",
      "| ep_reward_mean     | -23.6    |\n",
      "| explained_variance | -11.5    |\n",
      "| fps                | 558      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 2.5e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 201      |\n",
      "| ep_reward_mean     | -23.6    |\n",
      "| explained_variance | -0.00521 |\n",
      "| fps                | 564      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 97.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 201      |\n",
      "| ep_reward_mean     | -23.6    |\n",
      "| explained_variance | 0.0297   |\n",
      "| fps                | 576      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 8.05e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 201      |\n",
      "| ep_reward_mean     | -23.6    |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 575      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 6.98e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 198      |\n",
      "| ep_reward_mean     | -23.4    |\n",
      "| explained_variance | 1.2e-05  |\n",
      "| fps                | 571      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 93.7     |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1112\n",
      "---------------------------------\n",
      "| ep_len_mean        | 198      |\n",
      "| ep_reward_mean     | -23.4    |\n",
      "| explained_variance | -43.1    |\n",
      "| fps                | 1121     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000851 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 198      |\n",
      "| ep_reward_mean     | -23.4    |\n",
      "| explained_variance | -727     |\n",
      "| fps                | 883      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 0.000169 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 192      |\n",
      "| ep_reward_mean     | -23      |\n",
      "| explained_variance | -49.9    |\n",
      "| fps                | 571      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 2.52e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 192      |\n",
      "| ep_reward_mean     | -23      |\n",
      "| explained_variance | -0.0337  |\n",
      "| fps                | 600      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 95.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 192      |\n",
      "| ep_reward_mean     | -23      |\n",
      "| explained_variance | 0.000448 |\n",
      "| fps                | 661      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 3.27e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 192      |\n",
      "| ep_reward_mean     | -23      |\n",
      "| explained_variance | -807     |\n",
      "| fps                | 665      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 0.000127 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 195       |\n",
      "| ep_reward_mean     | -23.2     |\n",
      "| explained_variance | -4.79e-05 |\n",
      "| fps                | 670       |\n",
      "| nupdates           | 600       |\n",
      "| policy_entropy     | 1.29      |\n",
      "| total_timesteps    | 3000      |\n",
      "| value_loss         | 93.9      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 195       |\n",
      "| ep_reward_mean     | -23.2     |\n",
      "| explained_variance | -0.000467 |\n",
      "| fps                | 701       |\n",
      "| nupdates           | 700       |\n",
      "| policy_entropy     | 1.33      |\n",
      "| total_timesteps    | 3500      |\n",
      "| value_loss         | 1.92e-06  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 195      |\n",
      "| ep_reward_mean     | -23.2    |\n",
      "| explained_variance | -4.12    |\n",
      "| fps                | 700      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 1.85e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 187      |\n",
      "| ep_reward_mean     | -22.6    |\n",
      "| explained_variance | 6.26e-06 |\n",
      "| fps                | 623      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 94.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 186      |\n",
      "| ep_reward_mean     | -22.6    |\n",
      "| explained_variance | -34.7    |\n",
      "| fps                | 614      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 3.67e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 190      |\n",
      "| ep_reward_mean     | -22.8    |\n",
      "| explained_variance | -1.4     |\n",
      "| fps                | 591      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 8.29e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 195      |\n",
      "| ep_reward_mean     | -23.2    |\n",
      "| explained_variance | -0.011   |\n",
      "| fps                | 598      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 197      |\n",
      "| ep_reward_mean     | -23.3    |\n",
      "| explained_variance | -13.9    |\n",
      "| fps                | 603      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 7.4e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 198      |\n",
      "| ep_reward_mean     | -23.4    |\n",
      "| explained_variance | -121     |\n",
      "| fps                | 588      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 3.59e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 201      |\n",
      "| ep_reward_mean     | -23.6    |\n",
      "| explained_variance | -0.00487 |\n",
      "| fps                | 593      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 93.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 185      |\n",
      "| ep_reward_mean     | -22.6    |\n",
      "| explained_variance | -0.533   |\n",
      "| fps                | 547      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 1.74e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 177       |\n",
      "| ep_reward_mean     | -22       |\n",
      "| explained_variance | -2.98e+03 |\n",
      "| fps                | 532       |\n",
      "| nupdates           | 1700      |\n",
      "| policy_entropy     | 1.27      |\n",
      "| total_timesteps    | 8500      |\n",
      "| value_loss         | 0.000177  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 165      |\n",
      "| ep_reward_mean     | -21.1    |\n",
      "| explained_variance | 0.156    |\n",
      "| fps                | 508      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 96.8     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 158       |\n",
      "| ep_reward_mean     | -20.7     |\n",
      "| explained_variance | -1.21e+04 |\n",
      "| fps                | 503       |\n",
      "| nupdates           | 1900      |\n",
      "| policy_entropy     | 1.31      |\n",
      "| total_timesteps    | 9500      |\n",
      "| value_loss         | 1.06e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 143      |\n",
      "| ep_reward_mean     | -19.5    |\n",
      "| explained_variance | -33.4    |\n",
      "| fps                | 480      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 9.86e-05 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1182\n",
      "---------------------------------\n",
      "| ep_len_mean        | 143      |\n",
      "| ep_reward_mean     | -19.5    |\n",
      "| explained_variance | -0.56    |\n",
      "| fps                | 1161     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 5.56e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 140      |\n",
      "| ep_reward_mean     | -19.3    |\n",
      "| explained_variance | -0.0181  |\n",
      "| fps                | 289      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 139      |\n",
      "| ep_reward_mean     | -19.4    |\n",
      "| explained_variance | -51      |\n",
      "| fps                | 306      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 2.87e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 138      |\n",
      "| ep_reward_mean     | -19.3    |\n",
      "| explained_variance | -1.8     |\n",
      "| fps                | 357      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 1.17e-05 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 143      |\n",
      "| ep_reward_mean     | -19.6    |\n",
      "| explained_variance | 0.000986 |\n",
      "| fps                | 376      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 92.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 141      |\n",
      "| ep_reward_mean     | -19.5    |\n",
      "| explained_variance | -0.0272  |\n",
      "| fps                | 413      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 2.68e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 141      |\n",
      "| ep_reward_mean     | -19.5    |\n",
      "| explained_variance | -0.0683  |\n",
      "| fps                | 443      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 1.07e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 141      |\n",
      "| ep_reward_mean     | -19.5    |\n",
      "| explained_variance | 0.00146  |\n",
      "| fps                | 455      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 95.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 141      |\n",
      "| ep_reward_mean     | -19.5    |\n",
      "| explained_variance | -71.1    |\n",
      "| fps                | 476      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 6.19e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 137      |\n",
      "| ep_reward_mean     | -19.2    |\n",
      "| explained_variance | 0.0356   |\n",
      "| fps                | 463      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 9.49e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 135      |\n",
      "| ep_reward_mean     | -19.1    |\n",
      "| explained_variance | 0.0024   |\n",
      "| fps                | 469      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 126      |\n",
      "| ep_reward_mean     | -18.5    |\n",
      "| explained_variance | 0.0898   |\n",
      "| fps                | 467      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 2.86e-07 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 126       |\n",
      "| ep_reward_mean     | -18.5     |\n",
      "| explained_variance | -6.16e-05 |\n",
      "| fps                | 481       |\n",
      "| nupdates           | 1200      |\n",
      "| policy_entropy     | 1.34      |\n",
      "| total_timesteps    | 6000      |\n",
      "| value_loss         | 9.49e-06  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 126      |\n",
      "| ep_reward_mean     | -18.5    |\n",
      "| explained_variance | 2.74e-05 |\n",
      "| fps                | 492      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 94.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 127      |\n",
      "| ep_reward_mean     | -18.5    |\n",
      "| explained_variance | -0.00834 |\n",
      "| fps                | 503      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 0.00802  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 132      |\n",
      "| ep_reward_mean     | -18.8    |\n",
      "| explained_variance | 1.31e-06 |\n",
      "| fps                | 512      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 6.76e-07 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 135       |\n",
      "| ep_reward_mean     | -19.1     |\n",
      "| explained_variance | -8.46e-06 |\n",
      "| fps                | 521       |\n",
      "| nupdates           | 1600      |\n",
      "| policy_entropy     | 1.27      |\n",
      "| total_timesteps    | 8000      |\n",
      "| value_loss         | 93.7      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 138       |\n",
      "| ep_reward_mean     | -19.3     |\n",
      "| explained_variance | -1.96e+03 |\n",
      "| fps                | 536       |\n",
      "| nupdates           | 1700      |\n",
      "| policy_entropy     | 1.27      |\n",
      "| total_timesteps    | 8500      |\n",
      "| value_loss         | 0.000157  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 141      |\n",
      "| ep_reward_mean     | -19.5    |\n",
      "| explained_variance | -0.133   |\n",
      "| fps                | 542      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 2.21e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 144      |\n",
      "| ep_reward_mean     | -19.7    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 548      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 98       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 145      |\n",
      "| ep_reward_mean     | -19.8    |\n",
      "| explained_variance | -244     |\n",
      "| fps                | 560      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 2.48e-05 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1239\n",
      "---------------------------------\n",
      "| ep_len_mean        | 145      |\n",
      "| ep_reward_mean     | -19.8    |\n",
      "| explained_variance | -181     |\n",
      "| fps                | 1209     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 1.21e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 139      |\n",
      "| ep_reward_mean     | -19.4    |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 322      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 0.000719 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 138      |\n",
      "| ep_reward_mean     | -19.3    |\n",
      "| explained_variance | 0.0159   |\n",
      "| fps                | 376      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 95.4     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 135       |\n",
      "| ep_reward_mean     | -19.1     |\n",
      "| explained_variance | -1.26e+06 |\n",
      "| fps                | 444       |\n",
      "| nupdates           | 300       |\n",
      "| policy_entropy     | 1.35      |\n",
      "| total_timesteps    | 1500      |\n",
      "| value_loss         | 0.00099   |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 140      |\n",
      "| ep_reward_mean     | -19.4    |\n",
      "| explained_variance | -4.79    |\n",
      "| fps                | 423      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 2.45e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 145      |\n",
      "| ep_reward_mean     | -19.8    |\n",
      "| explained_variance | 0.0159   |\n",
      "| fps                | 460      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 147      |\n",
      "| ep_reward_mean     | -20      |\n",
      "| explained_variance | -6.04    |\n",
      "| fps                | 501      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 0.000205 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 151      |\n",
      "| ep_reward_mean     | -20.2    |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 524      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 1.02e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 151      |\n",
      "| ep_reward_mean     | -20.2    |\n",
      "| explained_variance | 0.00272  |\n",
      "| fps                | 463      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 146      |\n",
      "| ep_reward_mean     | -19.9    |\n",
      "| explained_variance | -126     |\n",
      "| fps                | 417      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 9.4e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 148      |\n",
      "| ep_reward_mean     | -20      |\n",
      "| explained_variance | -269     |\n",
      "| fps                | 405      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 0.00028  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 151      |\n",
      "| ep_reward_mean     | -20.2    |\n",
      "| explained_variance | 1.29e-05 |\n",
      "| fps                | 414      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 153      |\n",
      "| ep_reward_mean     | -20.3    |\n",
      "| explained_variance | -171     |\n",
      "| fps                | 434      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.14     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 5.48e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 159      |\n",
      "| ep_reward_mean     | -20.7    |\n",
      "| explained_variance | 0.109    |\n",
      "| fps                | 441      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 0.00141  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 161      |\n",
      "| ep_reward_mean     | -20.9    |\n",
      "| explained_variance | 0.000805 |\n",
      "| fps                | 447      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 164      |\n",
      "| ep_reward_mean     | -21.1    |\n",
      "| explained_variance | -98.7    |\n",
      "| fps                | 458      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 9.43e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 163      |\n",
      "| ep_reward_mean     | -21      |\n",
      "| explained_variance | -2.46    |\n",
      "| fps                | 463      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 1.63e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 162      |\n",
      "| ep_reward_mean     | -20.9    |\n",
      "| explained_variance | 0.0012   |\n",
      "| fps                | 457      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 159       |\n",
      "| ep_reward_mean     | -20.7     |\n",
      "| explained_variance | -3.11e+03 |\n",
      "| fps                | 460       |\n",
      "| nupdates           | 1800      |\n",
      "| policy_entropy     | 1.34      |\n",
      "| total_timesteps    | 9000      |\n",
      "| value_loss         | 1.08e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 152      |\n",
      "| ep_reward_mean     | -20.2    |\n",
      "| explained_variance | -0.0959  |\n",
      "| fps                | 442      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 0.26     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 147      |\n",
      "| ep_reward_mean     | -19.9    |\n",
      "| explained_variance | -0.0294  |\n",
      "| fps                | 427      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 95       |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1323\n",
      "---------------------------------\n",
      "| ep_len_mean        | 147      |\n",
      "| ep_reward_mean     | -19.9    |\n",
      "| explained_variance | -46.2    |\n",
      "| fps                | 881      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.00026  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 144      |\n",
      "| ep_reward_mean     | -19.7    |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 690      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 3.83e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 144      |\n",
      "| ep_reward_mean     | -19.7    |\n",
      "| explained_variance | -8.5     |\n",
      "| fps                | 613      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 1.54e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 141      |\n",
      "| ep_reward_mean     | -19.5    |\n",
      "| explained_variance | 0.0101   |\n",
      "| fps                | 589      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 95       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 134      |\n",
      "| ep_reward_mean     | -19      |\n",
      "| explained_variance | -225     |\n",
      "| fps                | 542      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 4.67e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 132       |\n",
      "| ep_reward_mean     | -18.8     |\n",
      "| explained_variance | -3.64e+03 |\n",
      "| fps                | 571       |\n",
      "| nupdates           | 500       |\n",
      "| policy_entropy     | 1.34      |\n",
      "| total_timesteps    | 2500      |\n",
      "| value_loss         | 0.000101  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 132      |\n",
      "| ep_reward_mean     | -18.8    |\n",
      "| explained_variance | 0.0219   |\n",
      "| fps                | 592      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 130       |\n",
      "| ep_reward_mean     | -18.7     |\n",
      "| explained_variance | -5.97e+03 |\n",
      "| fps                | 547       |\n",
      "| nupdates           | 700       |\n",
      "| policy_entropy     | 1.25      |\n",
      "| total_timesteps    | 3500      |\n",
      "| value_loss         | 2.15e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 129      |\n",
      "| ep_reward_mean     | -18.6    |\n",
      "| explained_variance | -2.71    |\n",
      "| fps                | 515      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 3.16e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 130      |\n",
      "| ep_reward_mean     | -18.6    |\n",
      "| explained_variance | -0.0259  |\n",
      "| fps                | 519      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| ep_len_mean        | 132       |\n",
      "| ep_reward_mean     | -18.8     |\n",
      "| explained_variance | -1.76e+04 |\n",
      "| fps                | 517       |\n",
      "| nupdates           | 1000      |\n",
      "| policy_entropy     | 1.3       |\n",
      "| total_timesteps    | 5000      |\n",
      "| value_loss         | 4.93e-06  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 132       |\n",
      "| ep_reward_mean     | -18.8     |\n",
      "| explained_variance | -7.27e-06 |\n",
      "| fps                | 531       |\n",
      "| nupdates           | 1100      |\n",
      "| policy_entropy     | 1.22      |\n",
      "| total_timesteps    | 5500      |\n",
      "| value_loss         | 3.94e-06  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 132       |\n",
      "| ep_reward_mean     | -18.8     |\n",
      "| explained_variance | -1.79e-06 |\n",
      "| fps                | 543       |\n",
      "| nupdates           | 1200      |\n",
      "| policy_entropy     | 1.22      |\n",
      "| total_timesteps    | 6000      |\n",
      "| value_loss         | 95.6      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 129      |\n",
      "| ep_reward_mean     | -18.6    |\n",
      "| explained_variance | -0.00597 |\n",
      "| fps                | 552      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 1.16e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 132      |\n",
      "| ep_reward_mean     | -18.8    |\n",
      "| explained_variance | -6.7e+03 |\n",
      "| fps                | 549      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 1.36e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 135      |\n",
      "| ep_reward_mean     | -19      |\n",
      "| explained_variance | 1.19e-07 |\n",
      "| fps                | 541      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 93.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 138      |\n",
      "| ep_reward_mean     | -19.2    |\n",
      "| explained_variance | -0.00172 |\n",
      "| fps                | 555      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 8.79e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 142      |\n",
      "| ep_reward_mean     | -19.5    |\n",
      "| explained_variance | -7.61    |\n",
      "| fps                | 553      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 8.36e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 148      |\n",
      "| ep_reward_mean     | -19.8    |\n",
      "| explained_variance | -0.0618  |\n",
      "| fps                | 558      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.15     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 150      |\n",
      "| ep_reward_mean     | -20.1    |\n",
      "| explained_variance | -0.375   |\n",
      "| fps                | 558      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 2.91e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 151      |\n",
      "| ep_reward_mean     | -20      |\n",
      "| explained_variance | -0.997   |\n",
      "| fps                | 551      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 7.75e-07 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1381\n",
      "---------------------------------\n",
      "| ep_len_mean        | 151      |\n",
      "| ep_reward_mean     | -20      |\n",
      "| explained_variance | -3.47    |\n",
      "| fps                | 1378     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 7.54e-07 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 155       |\n",
      "| ep_reward_mean     | -20.4     |\n",
      "| explained_variance | -4.11e-05 |\n",
      "| fps                | 551       |\n",
      "| nupdates           | 100       |\n",
      "| policy_entropy     | 1.29      |\n",
      "| total_timesteps    | 500       |\n",
      "| value_loss         | 94.5      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 155      |\n",
      "| ep_reward_mean     | -20.4    |\n",
      "| explained_variance | -25.8    |\n",
      "| fps                | 548      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 4.86e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 147       |\n",
      "| ep_reward_mean     | -19.9     |\n",
      "| explained_variance | -1.88e+03 |\n",
      "| fps                | 446       |\n",
      "| nupdates           | 300       |\n",
      "| policy_entropy     | 1.29      |\n",
      "| total_timesteps    | 1500      |\n",
      "| value_loss         | 1.39e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 141      |\n",
      "| ep_reward_mean     | -19.5    |\n",
      "| explained_variance | -0.00401 |\n",
      "| fps                | 409      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 96.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 130      |\n",
      "| ep_reward_mean     | -18.8    |\n",
      "| explained_variance | -18.6    |\n",
      "| fps                | 301      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 1.76e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 132      |\n",
      "| ep_reward_mean     | -18.8    |\n",
      "| explained_variance | -4.12    |\n",
      "| fps                | 311      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 3.5e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 135      |\n",
      "| ep_reward_mean     | -19      |\n",
      "| explained_variance | 0.066    |\n",
      "| fps                | 325      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 95.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 136      |\n",
      "| ep_reward_mean     | -19.1    |\n",
      "| explained_variance | -404     |\n",
      "| fps                | 348      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 8.76e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 135       |\n",
      "| ep_reward_mean     | -19       |\n",
      "| explained_variance | -1.07e+05 |\n",
      "| fps                | 362       |\n",
      "| nupdates           | 900       |\n",
      "| policy_entropy     | 1.29      |\n",
      "| total_timesteps    | 4500      |\n",
      "| value_loss         | 0.000133  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 134      |\n",
      "| ep_reward_mean     | -18.9    |\n",
      "| explained_variance | 3.22e-06 |\n",
      "| fps                | 364      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 94.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 132      |\n",
      "| ep_reward_mean     | -18.9    |\n",
      "| explained_variance | -68.4    |\n",
      "| fps                | 375      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 2.11e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 128       |\n",
      "| ep_reward_mean     | -18.5     |\n",
      "| explained_variance | -2.03e+03 |\n",
      "| fps                | 381       |\n",
      "| nupdates           | 1200      |\n",
      "| policy_entropy     | 1.27      |\n",
      "| total_timesteps    | 6000      |\n",
      "| value_loss         | 2.79e-05  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 131      |\n",
      "| ep_reward_mean     | -18.8    |\n",
      "| explained_variance | -0.00127 |\n",
      "| fps                | 390      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 132      |\n",
      "| ep_reward_mean     | -18.8    |\n",
      "| explained_variance | -211     |\n",
      "| fps                | 403      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 0.000112 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 137      |\n",
      "| ep_reward_mean     | -19.1    |\n",
      "| explained_variance | -29      |\n",
      "| fps                | 410      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 3.98e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 138      |\n",
      "| ep_reward_mean     | -19.3    |\n",
      "| explained_variance | 0.0262   |\n",
      "| fps                | 421      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 96.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 139      |\n",
      "| ep_reward_mean     | -19.4    |\n",
      "| explained_variance | 0.292    |\n",
      "| fps                | 431      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 1.78e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 140      |\n",
      "| ep_reward_mean     | -19.3    |\n",
      "| explained_variance | -0.0168  |\n",
      "| fps                | 436      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 1.21e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 141      |\n",
      "| ep_reward_mean     | -19.5    |\n",
      "| explained_variance | 8.11e-06 |\n",
      "| fps                | 445      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 94.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 138      |\n",
      "| ep_reward_mean     | -19.3    |\n",
      "| explained_variance | -0.00138 |\n",
      "| fps                | 453      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 1.35e-05 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1459\n",
      "---------------------------------\n",
      "| ep_len_mean        | 138      |\n",
      "| ep_reward_mean     | -19.3    |\n",
      "| explained_variance | 0.00365  |\n",
      "| fps                | 1403     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 1.22e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 141      |\n",
      "| ep_reward_mean     | -19.5    |\n",
      "| explained_variance | -118     |\n",
      "| fps                | 704      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 4.84e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 142      |\n",
      "| ep_reward_mean     | -19.5    |\n",
      "| explained_variance | 0.0429   |\n",
      "| fps                | 709      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 93.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 141      |\n",
      "| ep_reward_mean     | -19.5    |\n",
      "| explained_variance | -3.97    |\n",
      "| fps                | 641      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 7.28e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 144       |\n",
      "| ep_reward_mean     | -19.7     |\n",
      "| explained_variance | -0.000514 |\n",
      "| fps                | 658       |\n",
      "| nupdates           | 400       |\n",
      "| policy_entropy     | 1.21      |\n",
      "| total_timesteps    | 2000      |\n",
      "| value_loss         | 6.11e-06  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 141       |\n",
      "| ep_reward_mean     | -19.4     |\n",
      "| explained_variance | -8.58e-05 |\n",
      "| fps                | 635       |\n",
      "| nupdates           | 500       |\n",
      "| policy_entropy     | 1.26      |\n",
      "| total_timesteps    | 2500      |\n",
      "| value_loss         | 94.5      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 138      |\n",
      "| ep_reward_mean     | -19.3    |\n",
      "| explained_variance | -52.5    |\n",
      "| fps                | 619      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 4.02e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 141      |\n",
      "| ep_reward_mean     | -19.5    |\n",
      "| explained_variance | 0.000696 |\n",
      "| fps                | 630      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 7.55e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 145       |\n",
      "| ep_reward_mean     | -19.7     |\n",
      "| explained_variance | -5.72e-06 |\n",
      "| fps                | 638       |\n",
      "| nupdates           | 800       |\n",
      "| policy_entropy     | 1.32      |\n",
      "| total_timesteps    | 4000      |\n",
      "| value_loss         | 96.1      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 147      |\n",
      "| ep_reward_mean     | -19.9    |\n",
      "| explained_variance | 0.0383   |\n",
      "| fps                | 665      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 4.08e-09 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 150      |\n",
      "| ep_reward_mean     | -20.1    |\n",
      "| explained_variance | 0.00702  |\n",
      "| fps                | 669      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 1.88e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 151      |\n",
      "| ep_reward_mean     | -20.2    |\n",
      "| explained_variance | 4.11e-06 |\n",
      "| fps                | 671      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 95       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 153      |\n",
      "| ep_reward_mean     | -20.3    |\n",
      "| explained_variance | 0.0197   |\n",
      "| fps                | 688      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 5.11e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 156      |\n",
      "| ep_reward_mean     | -20.5    |\n",
      "| explained_variance | 0.00499  |\n",
      "| fps                | 692      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 1.99e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 159      |\n",
      "| ep_reward_mean     | -20.7    |\n",
      "| explained_variance | 4.11e-06 |\n",
      "| fps                | 695      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 96.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 162      |\n",
      "| ep_reward_mean     | -21      |\n",
      "| explained_variance | -0.00206 |\n",
      "| fps                | 711      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 2e-06    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 165      |\n",
      "| ep_reward_mean     | -21.2    |\n",
      "| explained_variance | 7.75e-07 |\n",
      "| fps                | 697      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 1.07e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 169      |\n",
      "| ep_reward_mean     | -21.4    |\n",
      "| explained_variance | 2.98e-07 |\n",
      "| fps                | 697      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 94.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 172      |\n",
      "| ep_reward_mean     | -21.5    |\n",
      "| explained_variance | 0.00522  |\n",
      "| fps                | 708      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 1.31e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 177      |\n",
      "| ep_reward_mean     | -22      |\n",
      "| explained_variance | -0.0011  |\n",
      "| fps                | 707      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 5.37e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 179       |\n",
      "| ep_reward_mean     | -22.1     |\n",
      "| explained_variance | -1.67e-06 |\n",
      "| fps                | 686       |\n",
      "| nupdates           | 2000      |\n",
      "| policy_entropy     | 1.33      |\n",
      "| total_timesteps    | 10000     |\n",
      "| value_loss         | 96.1      |\n",
      "----------------------------------\n",
      "Length of Rewards for A2C: 1501\n",
      "----------------------------------\n",
      "| ep_len_mean        | 179       |\n",
      "| ep_reward_mean     | -22.1     |\n",
      "| explained_variance | -2.65e+04 |\n",
      "| fps                | 1238      |\n",
      "| nupdates           | 1         |\n",
      "| policy_entropy     | 1.34      |\n",
      "| total_timesteps    | 5         |\n",
      "| value_loss         | 0.000517  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 182      |\n",
      "| ep_reward_mean     | -22.3    |\n",
      "| explained_variance | 1.28e-05 |\n",
      "| fps                | 1006     |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 1.58e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 188      |\n",
      "| ep_reward_mean     | -22.7    |\n",
      "| explained_variance | 9.24e-06 |\n",
      "| fps                | 836      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 1.99e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 193      |\n",
      "| ep_reward_mean     | -23.1    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 791      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 95.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 196      |\n",
      "| ep_reward_mean     | -23.2    |\n",
      "| explained_variance | -0.21    |\n",
      "| fps                | 834      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 0.0355   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 201      |\n",
      "| ep_reward_mean     | -23.6    |\n",
      "| explained_variance | -0.00122 |\n",
      "| fps                | 804      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 1.13e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 207      |\n",
      "| ep_reward_mean     | -24      |\n",
      "| explained_variance | 1.39e-05 |\n",
      "| fps                | 785      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 209      |\n",
      "| ep_reward_mean     | -24.2    |\n",
      "| explained_variance | 1.19e-07 |\n",
      "| fps                | 811      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 2.35e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 214      |\n",
      "| ep_reward_mean     | -24.5    |\n",
      "| explained_variance | 7.75e-07 |\n",
      "| fps                | 802      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 2.61e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 219      |\n",
      "| ep_reward_mean     | -24.9    |\n",
      "| explained_variance | 4.11e-06 |\n",
      "| fps                | 794      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.38     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 222      |\n",
      "| ep_reward_mean     | -25.1    |\n",
      "| explained_variance | -0.0076  |\n",
      "| fps                | 814      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 2.84e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 225      |\n",
      "| ep_reward_mean     | -25.3    |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 805      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 5.24e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 228      |\n",
      "| ep_reward_mean     | -25.4    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 799      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 95.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 231      |\n",
      "| ep_reward_mean     | -25.7    |\n",
      "| explained_variance | -60.3    |\n",
      "| fps                | 812      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 5.18e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 231      |\n",
      "| ep_reward_mean     | -25.7    |\n",
      "| explained_variance | -115     |\n",
      "| fps                | 804      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 2.1e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 234      |\n",
      "| ep_reward_mean     | -25.9    |\n",
      "| explained_variance | 0.0023   |\n",
      "| fps                | 798      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 94.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 236      |\n",
      "| ep_reward_mean     | -26      |\n",
      "| explained_variance | 0.00104  |\n",
      "| fps                | 807      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 1.35e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 237      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | 2.44e-06 |\n",
      "| fps                | 799      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 1.37e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 241       |\n",
      "| ep_reward_mean     | -26.3     |\n",
      "| explained_variance | -7.51e-06 |\n",
      "| fps                | 792       |\n",
      "| nupdates           | 1800      |\n",
      "| policy_entropy     | 1.3       |\n",
      "| total_timesteps    | 9000      |\n",
      "| value_loss         | 94.7      |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 243      |\n",
      "| ep_reward_mean     | -26.5    |\n",
      "| explained_variance | -0.0661  |\n",
      "| fps                | 799      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 3.35e-09 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 246      |\n",
      "| ep_reward_mean     | -26.6    |\n",
      "| explained_variance | -0.501   |\n",
      "| fps                | 793      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 0.0382   |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1534\n",
      "---------------------------------\n",
      "| ep_len_mean        | 246      |\n",
      "| ep_reward_mean     | -26.6    |\n",
      "| explained_variance | -113     |\n",
      "| fps                | 1131     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.16     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000459 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 246      |\n",
      "| ep_reward_mean     | -26.7    |\n",
      "| explained_variance | -0.0075  |\n",
      "| fps                | 323      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 93.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 245      |\n",
      "| ep_reward_mean     | -26.7    |\n",
      "| explained_variance | -333     |\n",
      "| fps                | 374      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 1.08e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 243      |\n",
      "| ep_reward_mean     | -26.5    |\n",
      "| explained_variance | -15.1    |\n",
      "| fps                | 417      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 2.53e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 240      |\n",
      "| ep_reward_mean     | -26.3    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 444      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 239      |\n",
      "| ep_reward_mean     | -26.2    |\n",
      "| explained_variance | -1.57    |\n",
      "| fps                | 481      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 6.57e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 233      |\n",
      "| ep_reward_mean     | -25.8    |\n",
      "| explained_variance | -0.554   |\n",
      "| fps                | 444      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 2.93e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 228      |\n",
      "| ep_reward_mean     | -25.5    |\n",
      "| explained_variance | -0.00251 |\n",
      "| fps                | 445      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 228      |\n",
      "| ep_reward_mean     | -25.5    |\n",
      "| explained_variance | -13.3    |\n",
      "| fps                | 478      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 0.000239 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 225      |\n",
      "| ep_reward_mean     | -25.3    |\n",
      "| explained_variance | -0.0121  |\n",
      "| fps                | 464      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 5.97e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 223      |\n",
      "| ep_reward_mean     | -25      |\n",
      "| explained_variance | -0.00718 |\n",
      "| fps                | 463      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 219      |\n",
      "| ep_reward_mean     | -24.9    |\n",
      "| explained_variance | -2.16    |\n",
      "| fps                | 462      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 2.17e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 216      |\n",
      "| ep_reward_mean     | -24.6    |\n",
      "| explained_variance | -14.1    |\n",
      "| fps                | 468      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 3.94e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 210      |\n",
      "| ep_reward_mean     | -24.2    |\n",
      "| explained_variance | 2.98e-07 |\n",
      "| fps                | 465      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 96.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 210      |\n",
      "| ep_reward_mean     | -24.2    |\n",
      "| explained_variance | -136     |\n",
      "| fps                | 484      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.19     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 1.95e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 210      |\n",
      "| ep_reward_mean     | -24.2    |\n",
      "| explained_variance | 0.0727   |\n",
      "| fps                | 495      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 5.98e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 201      |\n",
      "| ep_reward_mean     | -23.6    |\n",
      "| explained_variance | -0.0104  |\n",
      "| fps                | 480      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 94.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 173      |\n",
      "| ep_reward_mean     | -21.7    |\n",
      "| explained_variance | -2.89    |\n",
      "| fps                | 432      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 3.72e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 162      |\n",
      "| ep_reward_mean     | -20.9    |\n",
      "| explained_variance | -0.00208 |\n",
      "| fps                | 428      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 1.55e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 153      |\n",
      "| ep_reward_mean     | -20.3    |\n",
      "| explained_variance | 3.99e-06 |\n",
      "| fps                | 425      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 144      |\n",
      "| ep_reward_mean     | -19.7    |\n",
      "| explained_variance | -14.6    |\n",
      "| fps                | 425      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 2.23e-05 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1619\n",
      "---------------------------------\n",
      "| ep_len_mean        | 144      |\n",
      "| ep_reward_mean     | -19.7    |\n",
      "| explained_variance | 0.00336  |\n",
      "| fps                | 1306     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 2.93e-06 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| ep_len_mean        | 141       |\n",
      "| ep_reward_mean     | -19.5     |\n",
      "| explained_variance | -1.74e+04 |\n",
      "| fps                | 552       |\n",
      "| nupdates           | 100       |\n",
      "| policy_entropy     | 1.28      |\n",
      "| total_timesteps    | 500       |\n",
      "| value_loss         | 2.66e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 138      |\n",
      "| ep_reward_mean     | -19.3    |\n",
      "| explained_variance | -0.00378 |\n",
      "| fps                | 552      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 134      |\n",
      "| ep_reward_mean     | -19      |\n",
      "| explained_variance | -88.6    |\n",
      "| fps                | 547      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 7.34e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 117      |\n",
      "| ep_reward_mean     | -17.7    |\n",
      "| explained_variance | 0.197    |\n",
      "| fps                | 444      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 0.000177 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 118      |\n",
      "| ep_reward_mean     | -17.9    |\n",
      "| explained_variance | -0.00627 |\n",
      "| fps                | 412      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 93.8     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 120       |\n",
      "| ep_reward_mean     | -18       |\n",
      "| explained_variance | -0.000448 |\n",
      "| fps                | 444       |\n",
      "| nupdates           | 600       |\n",
      "| policy_entropy     | 1.32      |\n",
      "| total_timesteps    | 3000      |\n",
      "| value_loss         | 2.1e-06   |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 123      |\n",
      "| ep_reward_mean     | -18.2    |\n",
      "| explained_variance | 0.0331   |\n",
      "| fps                | 469      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.16     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 5.25e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 125      |\n",
      "| ep_reward_mean     | -18.4    |\n",
      "| explained_variance | 0.000385 |\n",
      "| fps                | 490      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 97       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 124      |\n",
      "| ep_reward_mean     | -18.3    |\n",
      "| explained_variance | -34.5    |\n",
      "| fps                | 508      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 2.58e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 126      |\n",
      "| ep_reward_mean     | -18.5    |\n",
      "| explained_variance | 0.0011   |\n",
      "| fps                | 512      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 3.06e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 128      |\n",
      "| ep_reward_mean     | -18.5    |\n",
      "| explained_variance | 0.000409 |\n",
      "| fps                | 524      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 130      |\n",
      "| ep_reward_mean     | -18.6    |\n",
      "| explained_variance | -0.00157 |\n",
      "| fps                | 543      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 4.13e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 135      |\n",
      "| ep_reward_mean     | -19.1    |\n",
      "| explained_variance | 0.000373 |\n",
      "| fps                | 552      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 2.89e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 140       |\n",
      "| ep_reward_mean     | -19.4     |\n",
      "| explained_variance | -1.16e-05 |\n",
      "| fps                | 561       |\n",
      "| nupdates           | 1400      |\n",
      "| policy_entropy     | 1.25      |\n",
      "| total_timesteps    | 7000      |\n",
      "| value_loss         | 95.9      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 139      |\n",
      "| ep_reward_mean     | -19.3    |\n",
      "| explained_variance | 0.0095   |\n",
      "| fps                | 568      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 1.58e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 141      |\n",
      "| ep_reward_mean     | -19.5    |\n",
      "| explained_variance | 0.00797  |\n",
      "| fps                | 576      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 1.57e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 142      |\n",
      "| ep_reward_mean     | -19.5    |\n",
      "| explained_variance | -0.0619  |\n",
      "| fps                | 582      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.18     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 96.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 145      |\n",
      "| ep_reward_mean     | -19.7    |\n",
      "| explained_variance | -0.0881  |\n",
      "| fps                | 595      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 5.93e-09 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 150      |\n",
      "| ep_reward_mean     | -20.1    |\n",
      "| explained_variance | -0.263   |\n",
      "| fps                | 600      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 3.2e-06  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 151      |\n",
      "| ep_reward_mean     | -20.2    |\n",
      "| explained_variance | -0.0615  |\n",
      "| fps                | 604      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 95.2     |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1670\n",
      "---------------------------------\n",
      "| ep_len_mean        | 151      |\n",
      "| ep_reward_mean     | -20.2    |\n",
      "| explained_variance | 0.415    |\n",
      "| fps                | 876      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 2.85e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 153      |\n",
      "| ep_reward_mean     | -20.3    |\n",
      "| explained_variance | -403     |\n",
      "| fps                | 969      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 1.54e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 158      |\n",
      "| ep_reward_mean     | -20.7    |\n",
      "| explained_variance | -0.223   |\n",
      "| fps                | 809      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 1.1e-05  |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 163       |\n",
      "| ep_reward_mean     | -21       |\n",
      "| explained_variance | -1.56e-05 |\n",
      "| fps                | 768       |\n",
      "| nupdates           | 300       |\n",
      "| policy_entropy     | 1.33      |\n",
      "| total_timesteps    | 1500      |\n",
      "| value_loss         | 94.1      |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 165      |\n",
      "| ep_reward_mean     | -21.1    |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 809      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 7.47e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 165      |\n",
      "| ep_reward_mean     | -21.1    |\n",
      "| explained_variance | -0.00437 |\n",
      "| fps                | 784      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 2.83e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 169      |\n",
      "| ep_reward_mean     | -21.3    |\n",
      "| explained_variance | 2.98e-07 |\n",
      "| fps                | 768      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 94.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 171      |\n",
      "| ep_reward_mean     | -21.5    |\n",
      "| explained_variance | -0.00289 |\n",
      "| fps                | 791      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 2e-07    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 174      |\n",
      "| ep_reward_mean     | -21.7    |\n",
      "| explained_variance | -32.8    |\n",
      "| fps                | 778      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 1.93e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 174      |\n",
      "| ep_reward_mean     | -21.7    |\n",
      "| explained_variance | -0.0591  |\n",
      "| fps                | 768      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.15     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 95.7     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 174       |\n",
      "| ep_reward_mean     | -21.7     |\n",
      "| explained_variance | -0.000279 |\n",
      "| fps                | 784       |\n",
      "| nupdates           | 1000      |\n",
      "| policy_entropy     | 1.22      |\n",
      "| total_timesteps    | 5000      |\n",
      "| value_loss         | 2.14e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 177      |\n",
      "| ep_reward_mean     | -21.9    |\n",
      "| explained_variance | 0.377    |\n",
      "| fps                | 775      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 4.02e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 181      |\n",
      "| ep_reward_mean     | -22.1    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 767      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.19     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 184      |\n",
      "| ep_reward_mean     | -22.3    |\n",
      "| explained_variance | -0.0262  |\n",
      "| fps                | 777      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 0.000502 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 188      |\n",
      "| ep_reward_mean     | -22.7    |\n",
      "| explained_variance | 8.34e-07 |\n",
      "| fps                | 770      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 2.16e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 192      |\n",
      "| ep_reward_mean     | -22.9    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 765      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 95.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 195      |\n",
      "| ep_reward_mean     | -23.2    |\n",
      "| explained_variance | -96.7    |\n",
      "| fps                | 774      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 3.18e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 200      |\n",
      "| ep_reward_mean     | -23.5    |\n",
      "| explained_variance | 0.00246  |\n",
      "| fps                | 741      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 2.29e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 205       |\n",
      "| ep_reward_mean     | -23.8     |\n",
      "| explained_variance | -5.72e-06 |\n",
      "| fps                | 739       |\n",
      "| nupdates           | 1800      |\n",
      "| policy_entropy     | 1.36      |\n",
      "| total_timesteps    | 9000      |\n",
      "| value_loss         | 94.7      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 208      |\n",
      "| ep_reward_mean     | -24      |\n",
      "| explained_variance | -104     |\n",
      "| fps                | 749      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 1.31e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 214      |\n",
      "| ep_reward_mean     | -24.4    |\n",
      "| explained_variance | 0.000325 |\n",
      "| fps                | 747      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 1.53e-05 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1705\n",
      "---------------------------------\n",
      "| ep_len_mean        | 214      |\n",
      "| ep_reward_mean     | -24.4    |\n",
      "| explained_variance | -22.1    |\n",
      "| fps                | 1165     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000101 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 219      |\n",
      "| ep_reward_mean     | -24.8    |\n",
      "| explained_variance | 2.98e-07 |\n",
      "| fps                | 719      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 94.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 221      |\n",
      "| ep_reward_mean     | -25      |\n",
      "| explained_variance | 0.0245   |\n",
      "| fps                | 836      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 9.74e-08 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 225       |\n",
      "| ep_reward_mean     | -25.2     |\n",
      "| explained_variance | -0.000342 |\n",
      "| fps                | 791       |\n",
      "| nupdates           | 300       |\n",
      "| policy_entropy     | 1.22      |\n",
      "| total_timesteps    | 1500      |\n",
      "| value_loss         | 5.57e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 229      |\n",
      "| ep_reward_mean     | -25.5    |\n",
      "| explained_variance | 6.08e-06 |\n",
      "| fps                | 769      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 95.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 231      |\n",
      "| ep_reward_mean     | -25.6    |\n",
      "| explained_variance | -0.00234 |\n",
      "| fps                | 799      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 3e-07    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 234      |\n",
      "| ep_reward_mean     | -25.9    |\n",
      "| explained_variance | 0.00102  |\n",
      "| fps                | 783      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 1.41e-05 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 238      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | -0.00652 |\n",
      "| fps                | 738      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 240      |\n",
      "| ep_reward_mean     | -26.3    |\n",
      "| explained_variance | -0.00165 |\n",
      "| fps                | 761      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 3.37e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 240      |\n",
      "| ep_reward_mean     | -26.3    |\n",
      "| explained_variance | -31.7    |\n",
      "| fps                | 754      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 2.38e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 243      |\n",
      "| ep_reward_mean     | -26.5    |\n",
      "| explained_variance | 2.74e-05 |\n",
      "| fps                | 747      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 95.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 244      |\n",
      "| ep_reward_mean     | -26.5    |\n",
      "| explained_variance | -33.3    |\n",
      "| fps                | 765      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.18     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 3.86e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 246      |\n",
      "| ep_reward_mean     | -26.7    |\n",
      "| explained_variance | -0.289   |\n",
      "| fps                | 739      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 5.46e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 247      |\n",
      "| ep_reward_mean     | -26.7    |\n",
      "| explained_variance | 0.00412  |\n",
      "| fps                | 688      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 248      |\n",
      "| ep_reward_mean     | -26.8    |\n",
      "| explained_variance | -484     |\n",
      "| fps                | 648      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 4.48e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 243       |\n",
      "| ep_reward_mean     | -26.5     |\n",
      "| explained_variance | -1.21e+04 |\n",
      "| fps                | 598       |\n",
      "| nupdates           | 1500      |\n",
      "| policy_entropy     | 1.35      |\n",
      "| total_timesteps    | 7500      |\n",
      "| value_loss         | 0.000136  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 237      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | 0.024    |\n",
      "| fps                | 585      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 237      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | 0.562    |\n",
      "| fps                | 590      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 7.05e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 240      |\n",
      "| ep_reward_mean     | -26.3    |\n",
      "| explained_variance | 0.00833  |\n",
      "| fps                | 595      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 8.27e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 237      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | 0.0083   |\n",
      "| fps                | 591      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 237      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | -0.0085  |\n",
      "| fps                | 603      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 2.08e-07 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1756\n",
      "---------------------------------\n",
      "| ep_len_mean        | 237      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | 0.0088   |\n",
      "| fps                | 1193     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 1.82e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 237      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | -32.4    |\n",
      "| fps                | 710      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 6.43e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 237       |\n",
      "| ep_reward_mean     | -26.1     |\n",
      "| explained_variance | -1.55e-05 |\n",
      "| fps                | 703       |\n",
      "| nupdates           | 200       |\n",
      "| policy_entropy     | 1.34      |\n",
      "| total_timesteps    | 1000      |\n",
      "| value_loss         | 94.7      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 237      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | -17.3    |\n",
      "| fps                | 700      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.16     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 0.000246 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 228      |\n",
      "| ep_reward_mean     | -25.5    |\n",
      "| explained_variance | -2.45    |\n",
      "| fps                | 576      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 1.5e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 225      |\n",
      "| ep_reward_mean     | -25.2    |\n",
      "| explained_variance | 0.021    |\n",
      "| fps                | 571      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 214       |\n",
      "| ep_reward_mean     | -24.5     |\n",
      "| explained_variance | -3.99e+03 |\n",
      "| fps                | 525       |\n",
      "| nupdates           | 600       |\n",
      "| policy_entropy     | 1.25      |\n",
      "| total_timesteps    | 3000      |\n",
      "| value_loss         | 0.000253  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 192      |\n",
      "| ep_reward_mean     | -23      |\n",
      "| explained_variance | -2.57    |\n",
      "| fps                | 445      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 6.51e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 192      |\n",
      "| ep_reward_mean     | -23      |\n",
      "| explained_variance | 6.08e-06 |\n",
      "| fps                | 468      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 96.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 192      |\n",
      "| ep_reward_mean     | -23      |\n",
      "| explained_variance | -7.29    |\n",
      "| fps                | 497      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 1.18e-05 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 186      |\n",
      "| ep_reward_mean     | -22.6    |\n",
      "| explained_variance | -1.68    |\n",
      "| fps                | 492      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 4.94e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 183      |\n",
      "| ep_reward_mean     | -22.4    |\n",
      "| explained_variance | 0.0038   |\n",
      "| fps                | 497      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 95.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 180      |\n",
      "| ep_reward_mean     | -22.2    |\n",
      "| explained_variance | -36.1    |\n",
      "| fps                | 510      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 1.27e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 181      |\n",
      "| ep_reward_mean     | -22.2    |\n",
      "| explained_variance | 0.745    |\n",
      "| fps                | 522      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 5.04e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 177      |\n",
      "| ep_reward_mean     | -22      |\n",
      "| explained_variance | -0.0081  |\n",
      "| fps                | 509      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 96.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 172      |\n",
      "| ep_reward_mean     | -21.7    |\n",
      "| explained_variance | 5.13e-06 |\n",
      "| fps                | 510      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.19     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 6.39e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 165      |\n",
      "| ep_reward_mean     | -21.3    |\n",
      "| explained_variance | -5.71    |\n",
      "| fps                | 506      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 1.16e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 159      |\n",
      "| ep_reward_mean     | -20.8    |\n",
      "| explained_variance | 0.0234   |\n",
      "| fps                | 502      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 97.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 156      |\n",
      "| ep_reward_mean     | -20.6    |\n",
      "| explained_variance | 2.38e-07 |\n",
      "| fps                | 510      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 1.96e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 159      |\n",
      "| ep_reward_mean     | -20.8    |\n",
      "| explained_variance | -0.00421 |\n",
      "| fps                | 516      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 1.47e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 159      |\n",
      "| ep_reward_mean     | -20.8    |\n",
      "| explained_variance | 2.55e-05 |\n",
      "| fps                | 523      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1820\n",
      "---------------------------------\n",
      "| ep_len_mean        | 159      |\n",
      "| ep_reward_mean     | -20.8    |\n",
      "| explained_variance | -8.68    |\n",
      "| fps                | 764      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.000199 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 159      |\n",
      "| ep_reward_mean     | -20.8    |\n",
      "| explained_variance | -971     |\n",
      "| fps                | 1046     |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 0.000276 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 159      |\n",
      "| ep_reward_mean     | -20.8    |\n",
      "| explained_variance | -4.29    |\n",
      "| fps                | 866      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 1.73e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 156      |\n",
      "| ep_reward_mean     | -20.6    |\n",
      "| explained_variance | -0.00197 |\n",
      "| fps                | 662      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 156      |\n",
      "| ep_reward_mean     | -20.6    |\n",
      "| explained_variance | -0.00708 |\n",
      "| fps                | 674      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 1.28e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 159      |\n",
      "| ep_reward_mean     | -20.8    |\n",
      "| explained_variance | -0.00188 |\n",
      "| fps                | 643      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 1.15e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 161      |\n",
      "| ep_reward_mean     | -20.9    |\n",
      "| explained_variance | 1.57e-05 |\n",
      "| fps                | 651      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 94       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 164      |\n",
      "| ep_reward_mean     | -21.1    |\n",
      "| explained_variance | 0.0147   |\n",
      "| fps                | 658      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 1.5e-07  |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 169       |\n",
      "| ep_reward_mean     | -21.4     |\n",
      "| explained_variance | -1.68e+03 |\n",
      "| fps                | 664       |\n",
      "| nupdates           | 800       |\n",
      "| policy_entropy     | 1.23      |\n",
      "| total_timesteps    | 4000      |\n",
      "| value_loss         | 3.47e-05  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 174       |\n",
      "| ep_reward_mean     | -21.8     |\n",
      "| explained_variance | -3.81e-06 |\n",
      "| fps                | 667       |\n",
      "| nupdates           | 900       |\n",
      "| policy_entropy     | 1.22      |\n",
      "| total_timesteps    | 4500      |\n",
      "| value_loss         | 95.5      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 177      |\n",
      "| ep_reward_mean     | -22      |\n",
      "| explained_variance | -0.0797  |\n",
      "| fps                | 688      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 2.28e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 180      |\n",
      "| ep_reward_mean     | -22.2    |\n",
      "| explained_variance | 0.0283   |\n",
      "| fps                | 688      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 6.95e-09 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 184      |\n",
      "| ep_reward_mean     | -22.4    |\n",
      "| explained_variance | 2.15e-06 |\n",
      "| fps                | 688      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 97.1     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 186      |\n",
      "| ep_reward_mean     | -22.7    |\n",
      "| explained_variance | 0.0406   |\n",
      "| fps                | 704      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 7.6e-08  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 189      |\n",
      "| ep_reward_mean     | -22.9    |\n",
      "| explained_variance | 0.00101  |\n",
      "| fps                | 702      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 9.98e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 192       |\n",
      "| ep_reward_mean     | -23.1     |\n",
      "| explained_variance | -3.58e-06 |\n",
      "| fps                | 702       |\n",
      "| nupdates           | 1500      |\n",
      "| policy_entropy     | 1.25      |\n",
      "| total_timesteps    | 7500      |\n",
      "| value_loss         | 96.3      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 192      |\n",
      "| ep_reward_mean     | -23.1    |\n",
      "| explained_variance | -0.00558 |\n",
      "| fps                | 714      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 1.31e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 192      |\n",
      "| ep_reward_mean     | -23.1    |\n",
      "| explained_variance | -0.0374  |\n",
      "| fps                | 711      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 4.67e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 195      |\n",
      "| ep_reward_mean     | -23.3    |\n",
      "| explained_variance | 2.15e-06 |\n",
      "| fps                | 711      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 195      |\n",
      "| ep_reward_mean     | -23.3    |\n",
      "| explained_variance | 0.00536  |\n",
      "| fps                | 720      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 2.7e-07  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 195      |\n",
      "| ep_reward_mean     | -23.3    |\n",
      "| explained_variance | 0.331    |\n",
      "| fps                | 719      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 6.64e-05 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1858\n",
      "---------------------------------\n",
      "| ep_len_mean        | 195      |\n",
      "| ep_reward_mean     | -23.3    |\n",
      "| explained_variance | -0.424   |\n",
      "| fps                | 1183     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 9.56e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 195      |\n",
      "| ep_reward_mean     | -23.3    |\n",
      "| explained_variance | 0.00213  |\n",
      "| fps                | 693      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 196      |\n",
      "| ep_reward_mean     | -23.3    |\n",
      "| explained_variance | -0.0417  |\n",
      "| fps                | 807      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 0.0224   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 196      |\n",
      "| ep_reward_mean     | -23.3    |\n",
      "| explained_variance | -991     |\n",
      "| fps                | 585      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 0.000407 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 198      |\n",
      "| ep_reward_mean     | -23.5    |\n",
      "| explained_variance | 2.98e-07 |\n",
      "| fps                | 578      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 95.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 198      |\n",
      "| ep_reward_mean     | -23.5    |\n",
      "| explained_variance | -0.0216  |\n",
      "| fps                | 634      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 1.36e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 203      |\n",
      "| ep_reward_mean     | -23.8    |\n",
      "| explained_variance | 0.647    |\n",
      "| fps                | 648      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 2.22e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 207      |\n",
      "| ep_reward_mean     | -24.1    |\n",
      "| explained_variance | -0.0527  |\n",
      "| fps                | 659      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 95.8     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 208       |\n",
      "| ep_reward_mean     | -24.1     |\n",
      "| explained_variance | -0.000407 |\n",
      "| fps                | 664       |\n",
      "| nupdates           | 800       |\n",
      "| policy_entropy     | 1.26      |\n",
      "| total_timesteps    | 4000      |\n",
      "| value_loss         | 1.37e-07  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 214      |\n",
      "| ep_reward_mean     | -24.4    |\n",
      "| explained_variance | -6.82    |\n",
      "| fps                | 666      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 1.73e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 219      |\n",
      "| ep_reward_mean     | -24.9    |\n",
      "| explained_variance | 8.94e-07 |\n",
      "| fps                | 669      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 93.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 221      |\n",
      "| ep_reward_mean     | -25      |\n",
      "| explained_variance | -0.00355 |\n",
      "| fps                | 689      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 5.91e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 222      |\n",
      "| ep_reward_mean     | -25.1    |\n",
      "| explained_variance | -0.00784 |\n",
      "| fps                | 658      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 7.14e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 222      |\n",
      "| ep_reward_mean     | -25.1    |\n",
      "| explained_variance | 0.0105   |\n",
      "| fps                | 662      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 95.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 223      |\n",
      "| ep_reward_mean     | -25.1    |\n",
      "| explained_variance | -7.93    |\n",
      "| fps                | 679      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 7.05e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 228      |\n",
      "| ep_reward_mean     | -25.5    |\n",
      "| explained_variance | -0.00945 |\n",
      "| fps                | 681      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 6.78e-06 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 228      |\n",
      "| ep_reward_mean     | -25.5    |\n",
      "| explained_variance | -0.047   |\n",
      "| fps                | 683      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 95.4     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 229      |\n",
      "| ep_reward_mean     | -25.5    |\n",
      "| explained_variance | -0.833   |\n",
      "| fps                | 695      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 8.08e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 233      |\n",
      "| ep_reward_mean     | -25.8    |\n",
      "| explained_variance | -0.0369  |\n",
      "| fps                | 695      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 6.85e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 234      |\n",
      "| ep_reward_mean     | -26      |\n",
      "| explained_variance | 0.000224 |\n",
      "| fps                | 694      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 95.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 232      |\n",
      "| ep_reward_mean     | -25.7    |\n",
      "| explained_variance | 0.0431   |\n",
      "| fps                | 695      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 1.17e-06 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1899\n",
      "----------------------------------\n",
      "| ep_len_mean        | 232       |\n",
      "| ep_reward_mean     | -25.7     |\n",
      "| explained_variance | -0.000393 |\n",
      "| fps                | 1489      |\n",
      "| nupdates           | 1         |\n",
      "| policy_entropy     | 1.28      |\n",
      "| total_timesteps    | 5         |\n",
      "| value_loss         | 1.06e-06  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 237      |\n",
      "| ep_reward_mean     | -26.1    |\n",
      "| explained_variance | -0.0581  |\n",
      "| fps                | 699      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 2.68e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 240      |\n",
      "| ep_reward_mean     | -26.4    |\n",
      "| explained_variance | 2.84e-05 |\n",
      "| fps                | 697      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 96       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 240      |\n",
      "| ep_reward_mean     | -26.3    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 768      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 1.73e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 245       |\n",
      "| ep_reward_mean     | -26.6     |\n",
      "| explained_variance | -0.000221 |\n",
      "| fps                | 746       |\n",
      "| nupdates           | 400       |\n",
      "| policy_entropy     | 1.35      |\n",
      "| total_timesteps    | 2000      |\n",
      "| value_loss         | 8.29e-06  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 249       |\n",
      "| ep_reward_mean     | -26.8     |\n",
      "| explained_variance | -4.29e-06 |\n",
      "| fps                | 737       |\n",
      "| nupdates           | 500       |\n",
      "| policy_entropy     | 1.27      |\n",
      "| total_timesteps    | 2500      |\n",
      "| value_loss         | 94.7      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 252      |\n",
      "| ep_reward_mean     | -27      |\n",
      "| explained_variance | 0.0216   |\n",
      "| fps                | 767      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 3.38e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 253      |\n",
      "| ep_reward_mean     | -27.1    |\n",
      "| explained_variance | -11.9    |\n",
      "| fps                | 755      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 0.00012  |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 258       |\n",
      "| ep_reward_mean     | -27.5     |\n",
      "| explained_variance | -3.47e-05 |\n",
      "| fps                | 747       |\n",
      "| nupdates           | 800       |\n",
      "| policy_entropy     | 1.26      |\n",
      "| total_timesteps    | 4000      |\n",
      "| value_loss         | 94.7      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 258      |\n",
      "| ep_reward_mean     | -27.5    |\n",
      "| explained_variance | -5.99    |\n",
      "| fps                | 767      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 3.31e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 261       |\n",
      "| ep_reward_mean     | -27.7     |\n",
      "| explained_variance | -1.95e+03 |\n",
      "| fps                | 759       |\n",
      "| nupdates           | 1000      |\n",
      "| policy_entropy     | 1.27      |\n",
      "| total_timesteps    | 5000      |\n",
      "| value_loss         | 0.000182  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 261      |\n",
      "| ep_reward_mean     | -27.7    |\n",
      "| explained_variance | 2.98e-07 |\n",
      "| fps                | 753      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.16     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 261      |\n",
      "| ep_reward_mean     | -27.7    |\n",
      "| explained_variance | -1.1e+03 |\n",
      "| fps                | 768      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 1.57e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 261      |\n",
      "| ep_reward_mean     | -27.7    |\n",
      "| explained_variance | 7.15e-07 |\n",
      "| fps                | 762      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 2.68e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 261      |\n",
      "| ep_reward_mean     | -27.7    |\n",
      "| explained_variance | -0.0105  |\n",
      "| fps                | 756      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 95.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 262      |\n",
      "| ep_reward_mean     | -27.7    |\n",
      "| explained_variance | -38.9    |\n",
      "| fps                | 767      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.2      |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 0.000636 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 267       |\n",
      "| ep_reward_mean     | -28.1     |\n",
      "| explained_variance | -8.25e-05 |\n",
      "| fps                | 762       |\n",
      "| nupdates           | 1600      |\n",
      "| policy_entropy     | 1.3       |\n",
      "| total_timesteps    | 8000      |\n",
      "| value_loss         | 6.96e-06  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 269       |\n",
      "| ep_reward_mean     | -28.2     |\n",
      "| explained_variance | -0.000221 |\n",
      "| fps                | 758       |\n",
      "| nupdates           | 1700      |\n",
      "| policy_entropy     | 1.32      |\n",
      "| total_timesteps    | 8500      |\n",
      "| value_loss         | 93.8      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 270      |\n",
      "| ep_reward_mean     | -28.3    |\n",
      "| explained_variance | -0.169   |\n",
      "| fps                | 767      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.31     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 5.68e-07 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 273      |\n",
      "| ep_reward_mean     | -28.5    |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 763      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 2.16e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 273      |\n",
      "| ep_reward_mean     | -28.5    |\n",
      "| explained_variance | 0.0116   |\n",
      "| fps                | 758      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 94.5     |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1933\n",
      "---------------------------------\n",
      "| ep_len_mean        | 273      |\n",
      "| ep_reward_mean     | -28.5    |\n",
      "| explained_variance | -3.18    |\n",
      "| fps                | 879      |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 2.96e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 273      |\n",
      "| ep_reward_mean     | -28.5    |\n",
      "| explained_variance | -96.3    |\n",
      "| fps                | 968      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 6.48e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 276      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | 4.12e-05 |\n",
      "| fps                | 776      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 4.38e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 276      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | -3.7e-06 |\n",
      "| fps                | 719      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 276      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | -3.7e+04 |\n",
      "| fps                | 755      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.37     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 8.91e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 276      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | -28.5    |\n",
      "| fps                | 743      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 7.52e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 276      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | -0.00417 |\n",
      "| fps                | 736      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 94.2     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 276      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | -6.71    |\n",
      "| fps                | 762      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 7.83e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 276      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | 0.000228 |\n",
      "| fps                | 753      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 7.89e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 276      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | 0.0639   |\n",
      "| fps                | 746      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.36     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 276      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | -246     |\n",
      "| fps                | 764      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 3.53e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 276      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | 0.229    |\n",
      "| fps                | 757      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 6.23e-08 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 276      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | 0.0121   |\n",
      "| fps                | 752      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.27     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 95.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 276      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | -8.11    |\n",
      "| fps                | 765      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.32     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 2.57e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 276      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | -75      |\n",
      "| fps                | 759      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 7.93e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 276      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | 0.00145  |\n",
      "| fps                | 755      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 96.1     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 276      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | -0.00254 |\n",
      "| fps                | 765      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.21     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 2.34e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 276      |\n",
      "| ep_reward_mean     | -28.7    |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 761      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 5.44e-06 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 279       |\n",
      "| ep_reward_mean     | -28.9     |\n",
      "| explained_variance | -7.19e-05 |\n",
      "| fps                | 757       |\n",
      "| nupdates           | 1800      |\n",
      "| policy_entropy     | 1.32      |\n",
      "| total_timesteps    | 9000      |\n",
      "| value_loss         | 94.1      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 279      |\n",
      "| ep_reward_mean     | -28.9    |\n",
      "| explained_variance | 0.00705  |\n",
      "| fps                | 766      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 1.61e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 284      |\n",
      "| ep_reward_mean     | -29.3    |\n",
      "| explained_variance | -37.6    |\n",
      "| fps                | 763      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.24     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 0.000195 |\n",
      "---------------------------------\n",
      "Length of Rewards for A2C: 1966\n",
      "---------------------------------\n",
      "| ep_len_mean        | 284      |\n",
      "| ep_reward_mean     | -29.3    |\n",
      "| explained_variance | -23.3    |\n",
      "| fps                | 1248     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 1.84e-05 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| ep_len_mean        | 288       |\n",
      "| ep_reward_mean     | -29.6     |\n",
      "| explained_variance | -9.91e-05 |\n",
      "| fps                | 686       |\n",
      "| nupdates           | 100       |\n",
      "| policy_entropy     | 1.25      |\n",
      "| total_timesteps    | 500       |\n",
      "| value_loss         | 95.5      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.6    |\n",
      "| explained_variance | -13.4    |\n",
      "| fps                | 809      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 9.87e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -29.4    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 698      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 3.34e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 285      |\n",
      "| ep_reward_mean     | -29.4    |\n",
      "| explained_variance | 0.000367 |\n",
      "| fps                | 699      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.25     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 95.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.5    |\n",
      "| explained_variance | -168     |\n",
      "| fps                | 741      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 5.01e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.6    |\n",
      "| explained_variance | 0.00053  |\n",
      "| fps                | 733      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.29     |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 1.3e-05  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.6    |\n",
      "| explained_variance | 0.0583   |\n",
      "| fps                | 726      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.3      |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 94.3     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 288      |\n",
      "| ep_reward_mean     | -29.6    |\n",
      "| explained_variance | -13.6    |\n",
      "| fps                | 748      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 4.48e-05 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 288       |\n",
      "| ep_reward_mean     | -29.6     |\n",
      "| explained_variance | -2.05e+03 |\n",
      "| fps                | 742       |\n",
      "| nupdates           | 900       |\n",
      "| policy_entropy     | 1.18      |\n",
      "| total_timesteps    | 4500      |\n",
      "| value_loss         | 6.47e-05  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.7    |\n",
      "| explained_variance | 0.0299   |\n",
      "| fps                | 737      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 93.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | 0.0349   |\n",
      "| fps                | 733      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 5.03e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | -0.213   |\n",
      "| fps                | 731      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.23     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 6.06e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | 0.00551  |\n",
      "| fps                | 729      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 1.26     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 94.1     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 291       |\n",
      "| ep_reward_mean     | -29.8     |\n",
      "| explained_variance | -0.000195 |\n",
      "| fps                | 741       |\n",
      "| nupdates           | 1400      |\n",
      "| policy_entropy     | 1.29      |\n",
      "| total_timesteps    | 7000      |\n",
      "| value_loss         | 1.38e-06  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | -1.28    |\n",
      "| fps                | 737      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 1.28     |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 1.28e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | -0.00308 |\n",
      "| fps                | 734      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 1.34     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 93.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | -0.0094  |\n",
      "| fps                | 745      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 1.33     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 1.36e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | -0.019   |\n",
      "| fps                | 730      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 6.28e-07 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | 1.79e-07 |\n",
      "| fps                | 729      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 1.22     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 94.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 291      |\n",
      "| ep_reward_mean     | -29.8    |\n",
      "| explained_variance | -59.3    |\n",
      "| fps                | 738      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 1.35     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 6.08e-05 |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "while (len(rewards) < 2000):\n",
    "    print(\"Length of Rewards for DQN: {}\".format(len(rewards)))\n",
    "    model.learn(total_timesteps=10000)\n",
    "    rewards = env.get_episode_rewards()\n",
    "\n",
    "while (len(rewards2) < 2000):\n",
    "    print(\"Length of Rewards for A2C: {}\".format(len(rewards2)))\n",
    "    model2.learn(total_timesteps=10000)\n",
    "    rewards2 = env2.get_episode_rewards()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = rewards[:2000]\n",
    "rewards2 = rewards2[:2000]\n",
    "episodes = len(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.title(\"Task {}\".format(i+1))\n",
    "plt.plot(list(range(episodes)),rewards, label='DQN')\n",
    "plt.plot(list(range(episodes)),rewards2, label='A2C')\n",
    "plt.legend()\n",
    "plt.savefig(\"Task 3 A4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.savefig(\"Task 3 A4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.title(\"Task {}\".format(i+1))\n",
    "plt.plot(list(range(episodes)[1900:]),rewards[1900:], label='DQN')\n",
    "plt.plot(list(range(episodes)[1900:]),rewards2[1900:], label='A2C')\n",
    "plt.ylim(bottom=-40,top=0)\n",
    "plt.legend()\n",
    "plt.savefig(\"Task 3 A4 Last 100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.1\n",
      "-0.1\n"
     ]
    }
   ],
   "source": [
    "print(max(rewards))\n",
    "print(max(rewards2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.95277900000102\n",
      "9.013691000000176\n"
     ]
    }
   ],
   "source": [
    "print(np.var(rewards[1900:]))\n",
    "print(np.var(rewards2[1900:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
